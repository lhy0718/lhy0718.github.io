---
title: "[논문리뷰] ALYMPICS- LLM Agents Meet Game Theory (COLING 2025)"
date: 2025-05-25 21:52:26 +0900
categories:
  - Paper Review
tags:
  - COLING 2025
  - LLM in Game Theory
---

본 논문은 대규모 언어 모델(LLM) 에이전트를 활용한 게임 이론 연구를 위한 체계적 플랫폼 'Alympics'를 제안하며, 이를 통해 복잡한 전략적 상호작용을 시뮬레이션하고 분석하는 방법을 제시한다.

---

# 1 Introduction

- 게임 이론은 합리적인 행위자들 간의 전략적 상호작용을 연구하는 수학의 한 분야임.
- 경제학, 사회과학, 컴퓨터 과학, 생물학 등 다양한 분야에 응용되고 있음.
- 그러나 실제 게임 이론 연구는 단순 이론적 추론으로 해결하기 어려운 문제들이 많아 실제 실험이 요구됨.
  - 실험은 비용이 많이 들고 시간 소모가 크며, 인간 참여자 관련 윤리적 문제도 존재함.
- 최근 대형 언어 모델(LLM)과 LLM 기반 에이전트의 발전으로 AI를 활용해 복잡한 게임 이론 문제를 연구할 수 있는 새로운 기회가 생김.
- 일부 연구들은 게임 이론 문제의 벤치마크를 만들어 LLM의 추론 성능을 평가하고 있음.
- LLM 에이전트 시스템은 스타일, 어조, 성격, 감정, 협력과 경쟁 행동 등 다양한 인간 행동을 모사하는 방향으로 발전 중임.
- 예를 들어, Xu et al. (2023b,c)는 마피아 게임(Werewolf)을 통해 LLM 내에서 신뢰, 대립, 위장, 리더십 등 비프로그래밍의 전략적 행동이 나타남을 보여줌.
- 본 연구에서는 LLM 에이전트를 활용한 게임 이론 연구를 확장하고자 다음의 연구 질문(RQs)을 제시함:
  1. 인간의 전략적 상호작용을 통합, 제어 가능하며 효율적으로 시뮬레이션할 수 있는 통합 프레임워크를 구축할 수 있는가?
  2. LLM 에이전트 프레임워크를 활용해 게임 이론 연구를 수행할 수 있는 방법은 무엇인가?
  3. LLM 에이전트가 인간과 유사한 전략적 행동을 보이며, 어떤 수준의 합리적 전략 추론을 수행할 수 있는가?
- 첫 번째 RQ에 대해, LLM이 게임 이론 시나리오에 참여하는 합리적 행위자를 구현할 수 있으며, 전략적 상호작용의 역학과 결과에 대한 실증적 통찰을 제공할 수 있다고 주장함.
- 이에 Alympics(Agents용 올림픽)라는 새로운 게임 이론 프레임워크를 제안함.
  - Alympics는 Sandbox Playground, Agent Players, 선택적 Human Players로 구성되어 현실적이고 동적인 합리적 상호작용 모델을 구축함.
  - LLM 에이전트의 능력을 활용하여 연구자에게 통제 가능하고 확장 가능하며 재현 가능한 게임 시나리오 탐색 플랫폼을 제공함.
- 두 번째 RQ에 대해, 제한된 자원을 두고 불평등한 경쟁을 다루는 파일럿 연구를 제시함.
  - 이는 경매, 동적 게임, 불평등 경쟁 등 고전 게임 이론 문제를 축소한 형태임.
  - 자원 가용성과 에이전트 성격을 조절하여 게임 결과에 영향을 미치는 요인을 분석함.
  - Alympics에서 시뮬레이션한 결과를 경매 이론의 예측 결과들과 비교한 결과 높은 일관성을 보임.
- 세 번째 RQ에 대해, 인간 평가를 수행하여 에이전트의 게임 내 성능이 인간 평가자들의 자기평가와 유사함을 발견함.
  - 이는 Alympics 및 유사 AI 에이전트 환경에서 게임 이론 실험을 진행할 때 중요한 판단 근거임.
- 본 논문의 주요 기여는 다음과 같음:
  1. 게임 이론 연구를 촉진하는 체계적인 LLM 에이전트 기반 프레임워크 제안.
  2. 고전 게임 이론 문제들에서 영감을 받은 게임 환경 개발 및 질적·양적 분석을 통한 Alympics의 강점 시연.
  3. 전략 시나리오에서 LLM 에이전트의 성능에 대한 포괄적 주관 평가를 수행하여, LLM이 사회경제적 맥락에서 복잡한 인간 전략 행동을 모방할 수 있음을 밝힘.

---

# 2 Alympics: An LLM Agent-based Game Theory Playground

- Alympics는 게임 이론 연구를 위해 LLM 에이전트를 활용하는 체계적이고 오픈소스 프레임워크임.
- 주요 구성 요소는 다음과 같음:
  - Sandbox Playground
  - Agent Players (에이전트 플레이어)
  - 선택적으로 Human Players (인간 플레이어)
- 그림 1에 나타난 바와 같이, Agent Players와 Human Players 모두 Sandbox Playground 내에서 게임에 참여함.
- 기본 클래스 설계는 부록 A에 포함되어 있음.
- 예시 게임인 "Water Allocation Challenge"에서는 에이전트 플레이어들이 20일 동안 생존을 위해 물 자원을 매일 경매 방식으로 전략적으로 확보해야 함.
- 경매 절차 예:
  - 자원 공지: "Day N Water Supply Announcement"
  - 결과 집계 및 공지: "Day N Results Announcement"
  - 입찰 제출: "Submit Bids..."
    - 예: “For today's auction, I will bid $$100. Because ...”
- 게임 참여자 예시: Alex, Bob, Cindy, David, Eric
- 게임 목표는 각 플레이어가 제한된 자원을 어떻게 분배하고 입찰하는지를 통해 생존 전략을 연구하는 것임.

---

# 2.1 Sandbox Playground

- Sandbox Playground는 게임 실행을 위한 환경으로, 에이전트 상호작용에 대해 다재다능하고 통제된 설정을 제공함.
- 세 가지 주요 구성 요소로 이루어짐:
  - **환경 코드(Environment codes)**: 
    - 게임의 규칙을 설정하여 실험을 위한 일관되고 신뢰할 수 있는 프레임워크를 보장함.
  - **기록 보관소(Historical records)**:
    - 다중 라운드 설정에서 과거 게임의 상세 기록을 유지함.
    - 게임 진행에 따른 에이전트 전략 평가와 철저한 분석을 지원함.
  - **게임 설정(Game settings)**:
    - 연구자가 매개변수를 정확하게 맞춤 설정할 수 있도록 하여,
    - 다양한 시나리오에 유연하게 대응할 수 있게 함.

---

# 2.2 Agent Players

- Agent Players는 Sandbox Playground 내에서 전략 게임에 참여하는 LLM 기반의 에이전트들임.
- 각 Agent Player는 다음 구성 요소로 이루어져 있음:
  - **Agent Codes**: 의사결정 및 전략 수립을 담당하는 알고리즘.
  - **Player Status**: 에이전트의 현재 상태를 정의.
  - **Large Language Model**: 에이전트의 인지 능력을 강화하고 자연어 상호작용을 가능하게 하는 핵심 엔진.
  - **Memory Cache**: 게임과 관련된 역사적 데이터를 저장하는 시스템 (Shinn et al., 2023; Hu et al., 2023; Hou et al., 2024; Huang et al., 2023; Zhao et al., 2024; Hou et al., 2024).
  - **Reasoning Plugin**: 복잡한 의사결정 과정을 위한 특화된 논리 모듈 (Wei et al., 2022; Yao et al., 2023; Zhang et al., 2024; Gandhi et al., 2023).
  - **Persona Setting**: 에이전트의 행동 프로필과 전략적 선호도를 정의 (Liu et al., 2022; Wang et al., 2023c; Xu et al., 2023a; Shao et al., 2023).
  - **기타 구성 요소**: 도구 활용 (Cai et al., 2023; Shen et al., 2023; Liang et al., 2023; Qin et al., 2023) 및 증강과 같은 특정 연구 요구를 반영한 추가 요소들.

- 수식 예시: 에이전트의 의사결정 함수는 다음과 같이 표현 가능함  
  $$  
  Decision = \arg\max_{a \in A} Q(s, a)  
  $$  
  여기서 $$s$$는 현재 상태, $$A$$는 가능한 행동의 집합, $$Q$$는 가치 함수임.

---

# 3 Pilot Demonstration: Water Allocation Challenge

- Alympics는 복잡한 게임 이론 문제에 대한 실험을 수행할 수 있는 연구 플랫폼을 제공함.
- 파일럿 시연으로 "Water Allocation Challenge"라는 게임을 도입함.
- 이 게임은 경매 이론(auction theory), 자원 할당(resource allocation), 생존 전략(survival strategy), 반복 게임(repeated games), 내시 균형(Nash equilibrium), 공정성(fairness), 위험 관리(risk management) 등의 개념을 통합함.
- 명확하게 정의된 환경에 초점을 맞춤으로써, 이 플랫폼이 게임 이론 모델의 실증적 연구에 어떻게 사용될 수 있는지 보여줌.

---

# 3.1 Settings

- W 마을은 희귀한 가뭄을 겪고 있습니다.
- 주민들은 20일 동안 생존을 위해 물 자원을 확보해야 하는 임무를 맡았습니다.
- 120은 실험 중 조절할 수 있는 하이퍼파라미터입니다.
- 각 플레이어는 매일 실시되는 경매에 참여하여 개인의 물 수요를 충족하기 위한 입찰을 합니다.

- **목표:** 모든 주민의 공통 목표는 20일 기간이 끝날 때까지 생존하는 것입니다.
- **플레이어 정보:** 각 플레이어는 고유한 물 수요와 서로 다른 급여를 가지고 있습니다. 자세한 내용은 그림 3을 참고하세요.
- **체력(Health Points):**
  - 최대 체력은 10점이며, 시작 시 8점입니다.
  - 체력이 $$\leq 0$$가 되면 해당 플레이어는 게임에서 제거됩니다.
- **일상 루틴:**
  - 매일 모든 플레이어는 자신의 물 수요를 충족하기 위해 경매에 입찰합니다.
  - 만약 플레이어가 연속해서 $$k$$일 동안 물을 확보하지 못하면 ('No-Water Days'), 그 날 체력은 $$k$$만큼 감소합니다.
  - 물 수요가 충족되면 체력이 2점 증가하고, No-Water Days 카운트는 0으로 초기화됩니다.
- **공급:** 
  - 매일 물 공급량은 변화하지만, 전체 수요보다 항상 적습니다.
  - 공급량은 매일 경매 전에 발표됩니다.
- **경매 규칙:**
  - 물 자원 할당은 매일 비공개 입찰 방식으로 진행됩니다.
  - 정부는 최고 입찰자 순서에 따라 물 자원을 할당하며, 남은 물이 아무 플레이어의 요구를 충족할 수 없을 때까지 계속합니다.
  - 동점일 경우, 요구량이 적은 주민에게 우선권이 주어집니다.

---

# 3.2 Formulation

- 각 플레이어는 생존과 물 확보에 소요되는 비용에 따라 기대 효용을 극대화한다고 가정함.
- 기본 효용 함수는 다음과 같이 정의됨:

  $$
  U_i(b_i) = V_i(h_i) - C_i(b_i) \quad (1)
  $$

  - $$U_i(b_i)$$: 플레이어 $$i$$가 입찰 $$b_i$$일 때의 효용
  - $$V_i(h_i)$$: 건강 상태 $$h_i$$에 따른 가치 함수
    - $$h_i$$는 건강 점수에 비례하여 증가하고 무수일수에 따라 감소함.
    - $$V_i(h_i) \propto \frac{1}{h_i}$$
    - $$h_i$$가 감소할수록 물 확보 가치가 증가함.
  - $$C_i(b_i)$$: 입찰 $$b_i$$에 소요된 비용(예: 금액)
- 플레이어는 $$U_i(b_i)$$를 최대화하는 $$b_i$$를 선택하려 함.

- 게임은 여러 날에 걸친 동적 게임으로 모델링됨.
- 플레이어의 당일 $$t$$ 전략은 현재 상태와 미래 경매에 대한 기대에 의존함.
- 플레이어 $$i$$의 당일 $$t$$ 가치 함수 $$V^t_i$$는 다음을 만족:

  $$
  V^t_i = \max_{b^t_i} \left[ U^t_i(b^t_i) + \delta V^{t+1}_i \right] \quad (2)
  $$

  - $$\delta$$: 미래 효용의 현재 가치에 대한 할인 계수

- 각 경매에서 플레이어는 타인의 입찰을 알지 못한 상태에서 동시에 입찰함.
- 내쉬 균형은 자기 입찰만 변경해도 효용을 개선할 수 없을 때 성립함.
- 내쉬 균형 입찰 $$b^*_i$$는 다음 조건을 만족:

  $$
  U_i(b^*_i, b^*_{-i}) \geq U_i(b_i, b^*_{-i}) \quad \text{모든 가능한 } b_i \quad (3)
  $$

- 입찰 추세에 관한 모델:
  - $$p_t$$: $$t$$일의 최소 성공 입찰가
  - $$p_t$$의 변화는 차분 방정식으로 모델링됨:

  $$
  p_t = f(p_{t-1}, \text{supply}_t, H, W, d) \quad (4)
  $$

  - $$\text{supply}_t$$: $$t$$일의 자원 공급량
  - $$H$$: 플레이어들의 건강 상태(전체 건강 또는 잔류 인원 수)
  - $$W$$: 플레이어들의 부유 상태(전체 부의 축적)
  - $$d$$: 생존 플레이어들의 평균 수요
  - $$f$$: 이 요소들이 입찰 행동 변화에 미치는 영향을 나타내는 함수

---

# 4.1 Implementation

- 구현에는 GPT-4가 활용되었으며, 각 에이전트 플레이어는 별도의 GPT-4 인스턴스를 사용함.
- 시스템 메시지는 Azure의 2GPT-4-32k, 모델 버전: 2023-07-01preview 2849로 설정됨.
- 각 플레이어별 정보는 이름, 일일 급여, 요구 단위량을 포함하며, 직업, 성격, 배경은 비교 실험에서만 사용됨.

- 대표적인 플레이어 페르소나 예시:
  - Alex: 낮은 지능과 감성 지능, 어려운 개념 이해, 부정적이고 반사회적 경향.
  - Bob: 평균 IQ, 높은 감성 지능, 이해심 많고 의사소통 능력이 뛰어난 교사.
  - Cindy: 높은 IQ와 EQ, 공감 능력 우수한 심리학자.
  - David: 매우 높은 IQ와 분석력, 사회적 상호작용에서 어려움 있는 수학자.
  - Eric: 평균 이상의 IQ와 EQ, 카리스마 있고 사람을 잘 다루는 마케팅 전문가.

- 게임 세팅 S (선택적 페르소나 포함)와 라운드별 입찰 결과 B = [b_1, b_2, ..., b_{20}], 
  여기서 b_n 은 n번째 라운드의 입찰 요약을 나타냄.

- i번째 플레이어의 입찰 결과는 R_i = [r_1^i, r_2^i, ..., r_{20}^i]로 표현,
  여기서 r_n^i 는 n번째 라운드에서 i번째 플레이어가 응답한 내용임.

- 참가자 정보는 I = [i_1, i_2, ..., i_{20}]로 나타내며,
  여기서 i_n 은 n번째 라운드의 모든 참가자 정보(체력, 잔여 예산, 연속 무수분 일수 등)를 포함함.

- i번째 플레이어의 n번째 라운드 응답 r_n^i 는 다음 식(식 5)으로 산출됨:

  $$
  r_n^i = GPT4(S, r_1^i, b_1, i_1, \ldots, r_{n-1}^i, b_{n-1}, i_{n-1})
  $$

---

# 4.2 Variables

- **자원 풍부도 (Resource Abundance)**
  - 자원 풍부도를 세 가지 수준으로 분류: Low, Medium, High
  - 총 물 수요는 모든 에이전트의 합산으로 50 단위
  - 일일 공급량은 각 수준별로 균등 분포:
    - Low: 10 ~ 20 단위
    - Medium: 15 ~ 25 단위
    - High: 20 ~ 30 단위
  - 자원 만족율(Resource Satisfaction Rate, RSR) 정의:
    - 생존 플레이어들의 총 수요 대비 자원의 기대 만족 비율로 수학적 기댓값을 의미
    - 수식:
      $$
      RSR = \frac{E(\text{resources})}{\sum_{i \in survivors} \text{requirement}_i}
      $$
  - RSR 값 해석:
    - 0에 가까울수록 경쟁이 심함
    - 1 이상이면 모든 수요가 충족되어 경쟁 없음
  - 실제 실험 설정에서 각 자원 풍부도에 따른 RSR 값:
    - Low: 0.3
    - Medium: 0.4
    - High: 0.5

- **플레이어 페르소나 (Player Persona)**
  - 두 가지 시나리오 비교:
    1. 페르소나 미부여: 에이전트가 GPT-4 모델을 직접 사용
    2. 페르소나 부여: 에이전트에게 직업, 성격, 배경 등의 다양한 페르소나 할당
  - 목적: 에이전트 간 이질성 증가 및 페르소라가 생존 전략과 결과에 미치는 영향 분석
  - 자세한 페르소나 설정은 Fig. 3에서 확인 가능

- **실험 설정 요약 (표 1)**

  | Group | ID | Resource Abundance | Persona |
  |-------|----|--------------------|---------|
  | a     | 1  | Low                | x       |
  | a     | 2  | Medium             | x       |
  | a     | 3  | High               | x       |
  | b     | 4  | Low                | v       |
  | b     | 5  | Medium             | v       |
  | b     | 6  | High               | v       |

---

# 4.3 Experimental Settings

- 연구는 총 6가지 실험 설정으로 구성되어 있으며, 자세한 내용은 Table 1에 제시됨.
- 실험 그룹 (a):
  - 설정 1~3 포함.
  - 에이전트에 페르소나(persona) 할당 없이 수행.
  - 각각 낮음, 중간, 높음 자원 풍부도 수준 적용.
- 실험 그룹 (b):
  - 설정 4~6 포함.
  - 에이전트에 페르소나를 할당 (Fig. 3 참고).
  - 해당 페르소나에 맞는 자원 수준 적용.
- 이 구성은 자원 풍부도와 페르소나 할당이 플레이어 전략, 생존, 게임 결과에 미치는 영향을 분석하는 데 목적.
- 각 실험 설정은 10회 반복 수행됨.
- 종합적인 게임 기록 예시는 부록 C.1에 제공됨.

---

# 4.4 Indicators

- 자원 할당 동향과 플레이어 생존 전략을 이해하기 위해 여러 지표를 관찰함.
- RSRS와 RSRE는 각각 게임 시작 시점과 종료 시점의 자원 만족률(Resource Satisfaction Rates)을 나타냄.
  - 이 두 값을 비교하여 1인당 자원 할당 변화 및 게임 후 자원 풍부도를 평가할 수 있음.
- 생존자 수는 $$ N_{survivor} $$로 측정하며, 개별 플레이어의 생존률도 추적함.
  - 예를 들어, $$ SRA $$는 특정 조건 하에서 10라운드 동안 플레이어 A의 생존률을 의미함.
- 각 라운드에서 최소 성공 입찰 가격 $$ p $$를 조사하며, $$ p_n $$은 n번째 라운드의 가격임.
  - $$ p_n $$의 변동을 분석하여 플레이어들의 입찰 전략과 경향을 파악함.
- 경매 효율성(auction efficiency)은 입찰된 자원 대비 플레이어 만족도가 얼마나 충족되는지를 나타냄 (Milgrom, 2004; Ausubel et al., 2014).
- 효율성 지표 $$ \epsilon $$는 아래 식으로 정의됨:
  $$
  \epsilon = \frac{\sum_{i=1}^N u_i}{\sum_{i=1}^N b_i}, \quad u_i = \min \left( 1, \frac{w_i}{d_i} \right)
  $$
  - 여기서 $$ u_i $$는 플레이어 i의 만족도를 나타내는 효용 함수이며,
  - $$ w_i $$는 받은 물의 양, $$ d_i $$는 필요한 물의 양을 뜻함.
  - $$ u_i $$는 받은 자원 대비 필요 자원의 비율로 정의되어 최대 1로 제한됨.

---

# 5.1 Survival Rates and Auction Efficiency

- 표 2는 자원이 풍부한 환경에서 높은 생존율을 보여주며, 이는 경매 메커니즘을 통해 대부분의 플레이어의 요구를 충족하는 효율적인 자원 분배가 이루어짐을 나타냄.
- 반면, 자원이 부족한 환경에서는 생존율이 낮아 경매 방식이 재정적 능력이 제한되거나 필요가 더 큰 개인들에게 불리하게 작용하는 잠재적 비효율성을 반영함.
- 또한, 표는 경매 효율성($$\epsilon$$)과 자원 풍부도의 긍정적 상관관계를 보여줌.
- 이는 자원이 제한된 상황에서 동일한 효용을 얻기 위한 입찰 비용이 증가하여, 지출 단위당 만족도가 낮아짐을 시사함.
- 이러한 결과는 희소성 조건에서 원하는 결과를 확보하는 데 더 큰 어려움과 비용이 따른다는 것을 의미함.

---

# 5.2 Influence of Individual Differences on Outcomes

- **경제적 및 수요 요인**
  - 높은 소득이나 낮은 일일 물 수요를 가진 플레이어가 특히 자원이 부족한 환경에서 일반적으로 더 나은 성과를 보임.
  - 이는 경매 이론(Krishna, 2009)과 일치하며, 금융 능력과 평가가 입찰력과 결과에 영향을 미침.
  - 설정 1~3의 비교 실험에서 Cindy, David, Eric의 생존율이 Alex와 Bob보다 유의미하게 높았으며, 설정 1에서 Alex와 Bob의 생존율은 약 10%에 불과함.

- **페르소나 효과**
  - 페르소나는 플레이어 전략에 영향을 미치며, 이질적인 위험 선호, 생존 전략, 그리고 입찰 행동에서 합리성 또는 비합리성 수준의 차이를 도입함.
  - 표 5에 따르면 페르소나가 부여되었을 때 낮은 자원 조건에서 평균 생존율은 증가하나 중간 자원 조건에서는 감소함.
  - 특정 플레이어의 생존율 변화도 관찰되었으며, 예를 들어 Eric의 생존율은 크게 향상됨.
  - 부록 C.5에 에이전트 플레이어의 입찰 시 진술에서 생성된 워드 클라우드가 포함되어 있어 입찰 스타일의 차이를 확인 가능.
  - 페르소나 도입 후 관찰 지표가 변화했으나, 유의성 검사(표 4) 결과에 따르면 차이는 통계적으로 유의하지 않음.
  - 단순히 시스템 메시지에 페르소나를 추가하는 것만으로는 유의미한 차이를 유발하지 않는 것으로 추정됨.

---

# 5.3 Influence of Resource Abundance on Bidding Behavior

- **희소성은 높은 입찰가를 유발함**  
  - 자원이 부족한 환경(설정 1과 4)에서는 게임 초기에 입찰가가 상당히 높게 형성됨.  
  - 이는 생존에 필수적인 자원을 확보하기 위해 플레이어들이 치열하게 경쟁하기 때문이며, 제한된 재화에 대한 경쟁이 가격을 올린다는 경매 이론(Krishna, 2009)과 일치함.  
  - 초기 입찰가 급등 후 감소하는 현상은 플레이어들이 자원 확보에 필요한 입찰가를 과대평가하고 있음을 시사하며, 이는 경쟁자의 행동에 대한 불확실성 때문으로 해석됨.  
  - 게임 진행 중 경쟁자의 전략 파악이 진행되면서 입찰가가 안정되거나 감소함.  

- **풍부한 자원은 입찰 강도를 낮춤**  
  - 자원이 풍부한 환경(설정 3과 6)에서는 최소 성공 입찰가 $$p$$가 감소함.  
  - 자원이 충분한 조건에서는 생존이 상대적으로 보장되어, 플레이어들이 경쟁에 지출하는 금액이 줄어듦.  
  - 이는 자원을 확보해야 하는 압박감이 줄어들면서, 플레이어들이 지출하려는 금액도 줄어든다는 수요와 공급의 경제 원리에 부합함.  
  - 또한, 자원이 풍부한 환경에서는 시간이 지남에 따라 입찰가가 점진적으로 상승하는 경향이 나타남.  
  - 플레이어들이 부를 축적하고 생존에 대한 즉각적인 압박 없이 건강 포인트를 향상시키기 위해 입찰액을 늘려갈 수 있기 때문임.

---

# 5.4 Winner’s Curse

- 치열한 경매(tightly contested auctions)에서 승자는 자원 확보를 위해 과도한 금액을 지불하는 경향이 있으며, 이는 장기 생존 가능성을 저해하는 'Winner’s Curse'를 발생시킨다 (Bazerman and Samuelson, 1983).
- 설정 1(치열한 경매) 하에서 각 라운드에서 성공적으로 입찰한 플레이어의 생존율을 관찰한 결과, 첫 라운드에서 성공한 플레이어의 생존율은 40%에 불과했으나 두 번째 라운드에서 성공한 플레이어는 80%의 생존율을 보였다.
- 자세한 결과는 Appendix C.4에서 확인할 수 있다.
- 이는 초기 입찰 성공이 반드시 궁극적인 생존 가능성을 높이지 않는다는 것을 의미한다.
- 게임 초반에는 높은 체력(Health Points)과 적은 무음일수(No-Drink Days)로 인해, 다음 식들에 따라 가치 함수 $$V_i(H_i)$$는 플레이어의 과대평가된 가치 $$\hat{V}_i$$보다 낮고, 비용 $$b_i$$는 최적 입찰가 $$b_i^*$$보다 높게 나타난다.
- 이로 인해 효용 $$U_i(b_i)$$는 감소하게 되며, 이는 경매 이론의 Winner’s Curse 현상과 일치한다.

---

# 6 Subjective Evaluation

- 현재 LLM 에이전트를 통해 인간 행동을 시뮬레이션하는 연구가 많지만, 이러한 시뮬레이션이 진정한 합리적 추론 및 전략적 행동을 보이는지는 불확실함.
- 이에 10명의 인간 평가자를 초청하여 “Water Allocation Challenge” 게임에서 LLM 에이전트를 체계적으로 평가함.
  - 평가자들은 게임을 직접 플레이해보며 에이전트를 평가할 이해도를 높였고, 자기 자신에 대한 평가도 수행하여 에이전트와의 비교 기준을 설정함.
- 총 60회의 실험 중 에이전트가 페르소나를 가진 경우와 그렇지 않은 경우 각각 15개씩 총 30개의 기록을 무작위로 선정함.
  - 각각의 기록은 5명의 평가자가 평가함.
- 평가 항목: 
  - 정보 활용도 (Information Utilization, IU)
  - 논리적 추론 (Logical Reasoning, LR)
  - 전략적 효율성 (Strategic Effectiveness, SE)
  - 적응력 및 전략 진화 (Adaptability and Strategic Evolution, AD)
  - 장기 계획 (Long-term Planning, LP)
  - 페르소나 적용 시 추가로 정체성 일치도 (Identity Alignment, IA)를 평가함.
- 평가 점수는 1점부터 5점까지이며, 각 평가자는 점수에 대한 근거를 제시함 (평가기준 및 주석은 Appendix D.2 참고).
- 평가 결과(표 3 및 그림 10):
  - LLM 에이전트의 전반적인 수행능력은 인간의 자기 평가와 비교해 대체로 유사함.
  - 특히 장기 계획(LP) 영역에서는 에이전트가 인간보다 우수한 성과를 보임.
  - 반면, 적응력 및 정보 활용도(AD, IU)는 에이전트가 인간에 비해 부족한 모습을 보임.
- 평가 노트에 따르면:
  - 에이전트는 장기 생존을 위한 자금 보유 등 장기적 계획을 자주 세우는 반면,
  - 인간은 당장의 입찰 성공에 좀 더 집중하는 경향이 있음.
  - 이는 LLM이 장기적 결과를 고려할 수 있으나 적응력 측면에서 개선이 필요함을 시사함.
- 페르소나가 부여된 에이전트의 경우에도 정체성 일치도 평가 점수는 낮고 변동성이 큼.
  - 이는 단순히 페르소나 정보를 추가하는 것만으로는 특정 인격이나 전문 플레이어의 미묘한 특성을 효과적으로 시뮬레이션하지 못함을 의미함.
- 이에 대한 상세 분석은 Appendix E.1에 수록되어 있음.

- 평가 점수 통계 (요약):
  - 예를 들어, 에이전트 플레이어의 각 평가 항목별 중앙값은 최소 3점, 최대 5점 사이이며 평균은 대략 3.3~3.9점 사이임.
  - 인간 자기 평가의 평균은 비슷하거나 다소 낮으며 표준편차는 대체로 에이전트보다 작음.

- 수식으로 표현되는 핵심 평가 항목 점수 집계 예시:
  $$
  \text{Median Scores} = 
  \begin{cases} 
    IU: 3.00 \sim 4.00 \\
    LR: 3.00 \sim 4.00 \\
    SE: 3.00 \sim 4.75 \\
    AD: 3.00 \sim 4.00 \\
    LP: 3.00 \sim 5.00 \\
    IA: \text{(페르소나 적용 시 평가)} \\
  \end{cases}
  $$

- 도표로는 각 설정별 입찰 가격의 최소 성공 입찰가 분포 및 중앙값 추세가 제시되어, 입찰 가격의 절대값과 경향을 잘 보여줌.

---

# 7 Conclusions

- 본 논문은 복잡한 게임 이론 문제를 해결하기 위해 LLM 에이전트를 활용하는 혁신적인 Alympics 프레임워크를 소개함.
- 이 프레임워크는 게임 이론의 실증 연구에서 중요한 진전을 이루며, 정교한 시나리오의 분석과 모델링을 가능하게 함.
- 다양한 요인이 게임 결과에 미치는 영향을 조사함으로써, Alympics는 통제 가능하고 확장 가능하며 재현 가능한 환경 내에서 현실적인 행동을 시뮬레이션하는 능력을 입증함.
- 이 플랫폼은 게임 이론 연구를 촉진할 뿐만 아니라, 의사결정 연구를 전통적인 공리적 접근법에서 행동적 및 언어적 차원을 포함하는 방향으로 전환하는 데 기여함.
- 주요 수식 및 개념들은 다음과 같음:
  - 게임 결과는 다양한 요인에 의해 영향을 받으며, 이를 수식으로 표현하면 $$U_i = f(S, A, \vert E_i \vert)$$ 와 같이 나타낼 수 있음.
  - 여기서 $$U_i$$는 플레이어 $$i$$의 유틸리티, $$S$$는 상태 공간, $$A$$는 행동 집합, $$E_i$$는 플레이어 $$i$$의 경험 및 언어적 요소를 포함한 요인들을 의미함.

---

# Limitations

- 본 논문은 공간 제약과 중심 주제에 집중하기 위해 모든 관련 주제를 포괄적으로 다루지 못함.
  - 예를 들어, 그림 1의 구성 요소들 중 추론 플러그인과 메모리 캐시 증강 등에 대한 상세한 논의는 포함되지 않음.
  - 그러나, 제시된 시스템 아키텍처는 이들 모듈에 유연한 인터페이스를 제공하여 연구자들이 연구를 재현하고 확장할 수 있도록 함.

- 본 논문에서는 한 가지 게임에 대한 상세한 시연만을 제시함.
  - 하지만 제안된 플랫폼은 다양한 게임에 적용 가능하며,
  - 이후 공개된 소스 프레임워크를 기반으로 케인즈 미인 대회(Keynes’ Beauty Contest) 및 협상(negotiation) 연구(참고: Zhang et al., 2024) 등 다양한 주제로 확장되고 있음.

- 실험은 각기 10회씩 반복 수행됨.
  - “큰 수의 법칙(Law of Large Numbers)”에 따르면 더 많은 샘플 수가 기대값에 가까운 결과를 낼 수 있지만,
  - 주요 지표에 대한 유의성 분석 결과, 10회의 실험은 제안하는 결론에 대해 신뢰할 만한 초기 시연임을 보여줌.