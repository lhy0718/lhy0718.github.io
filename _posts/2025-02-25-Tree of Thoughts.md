---
title: "[논문리뷰] Tree of Thoughts: Deliberate Problem Solving with Large Language Models (NeurIPS 2023)"
date: 2025-02-25 00:00:00 +0900
categories:
  - LLM
tags:
  - Reasoning
  - LLM
  - NLP
  - ToT
  - NeurIPS 2023
---

요약: Chain-of-Thought(CoT) 접근법을 확장하여, LLM이 체계적인 문제 해결을 수행하도록 하는 Tree of Thoughts(ToT) 프레임워크를 제안한다.

# 1. Introduction

<img width="712" alt="image" src="https://github.com/user-attachments/assets/acb989e7-b1c0-4d34-b609-58de8d1f05db" />

- 기존의 대규모 언어 모델(LLM)은 일반적인 문제 해결을 수행할 수 있지만, 여전히 **토큰 단위의 좌→우 순차적 결정 과정**에 제한되며, **탐색, 전략적 예측(lookahead), 초기 결정의 중요성**이 요구되는 문제에서 한계를 보인다.

- 이를 해결하기 위해, 논문에서는 **Tree of Thoughts(ToT)**라는 새로운 프레임워크를 제안한다. ToT는 기존 **Chain of Thought(CoT)** 방식을 일반화하여, 문제 해결 과정에서 여러 개의 **중간 사고(thoughts)**를 탐색하고, 서로 다른 경로를 고려하며, 스스로 평가하여 최적의 결정을 내리도록 한다.

- 이 프레임워크를 통해 LLM은 다음과 같은 능력을 갖추게 된다:
  1. **여러 개의 사고 경로를 탐색**하여 최적의 문제 해결 방법을 찾는다.
  2. **자체 평가(self-evaluation)를 수행**하며 최상의 선택을 결정한다.
  3. **필요 시 되돌아가거나(Backtracking) 미래를 예측**하여(global decision-making) 더 나은 결정을 내린다.

- 실험 결과, ToT는 **수학 퍼즐(Game of 24), 창의적 글쓰기(Creative Writing), 미니 낱말 퍼즐(Mini Crosswords)** 등의 복잡한 문제 해결에서 기존 CoT 기반 방법보다 훨씬 높은 성능을 보인다.  
  - 예를 들어, **Game of 24**에서는 기존 GPT-4의 CoT 프롬프트가 4%의 성공률을 기록한 반면, ToT 방식은 **74%의 성공률**을 달성한다.

- ToT는 LLM이 단순한 패턴 인식에 그치지 않고 **체계적 탐색과 계획을 수행할 수 있도록 지원**하여, **보다 강력한 문제 해결 능력을 갖춘 AI 시스템**을 구축하는 데 기여할 수 있다.

# 2. Background

- 기존의 대규모 언어 모델(LLM)은 다양한 문제 해결을 수행할 수 있지만, 여전히 **토큰 단위의 좌→우 순차적 생성 방식**에 의존하여 **체계적인 탐색, 전략적 예측, 되돌아가기(backtracking)** 등의 능력이 부족하다.

- 인간의 인지과학 연구에서는 사람들이 **빠르고 자동적인 직관적 사고(System 1)**와 **느리고 신중한 논리적 사고(System 2)**를 조합하여 문제를 해결한다고 본다.  
  - 현재 LLM은 주로 **System 1** 방식에 가깝지만, **System 2** 방식의 **계획(plan), 탐색(search), 평가(evaluation)** 기능이 추가되면 더욱 강력한 문제 해결 능력을 갖출 수 있다.

- 기존의 LLM 기반 문제 해결 방식은 다음과 같다:
  1. **Input-Output (IO) Prompting**  
     - 단순히 입력을 받아 출력을 생성하는 방식으로, 문제 해결 과정이 명시적으로 드러나지 않는다.
  2. **Chain of Thought (CoT) Prompting**  
     - 문제 해결 과정을 여러 단계의 **중간 사고(thoughts)**로 분해하여 논리적 추론을 강화한다.
  3. **Self-Consistency with CoT (CoT-SC)**  
     - 동일한 문제에 대해 여러 개의 CoT 경로를 생성하고, 가장 자주 등장하는 답변을 선택하여 신뢰도를 높인다.

- 하지만, 기존 방법들은 다음과 같은 한계를 가진다:
  - **CoT는 단일 경로로만 사고를 전개**하며, 여러 가지 가능한 해결 방법을 탐색하지 않는다.
  - **CoT-SC는 최종 답변에서만 다수결을 활용**할 뿐, **개별 사고 과정에서의 탐색 및 최적화가 부족**하다.
  - **계획, 되돌아가기, 평가를 수행하는 체계적인 탐색(search) 메커니즘이 필요**하다.

# 3. Tree of Thoughts: Deliberate Problem Solving with LM

- **Tree of Thoughts(ToT)**는 기존 LLM이 가진 한계를 극복하기 위해 설계된 새로운 문제 해결 프레임워크이다.  
  - 기존 **CoT 방식은 단일 경로만 탐색**하며, 중간 사고(thoughts)를 생성할 때 다양한 대안을 고려하지 않는다.  
  - 반면, **ToT는 여러 개의 사고 경로를 탐색**하고, 스스로 평가하며 최적의 경로를 선택하는 **계획적 문제 해결 방식**을 제공한다.

## 3.1 ToT의 핵심 아이디어

- 문제 해결을 **탐색(search) 과정으로 프레임화**하고, LLM이 여러 가지 해결 방법을 실험할 수 있도록 한다.  
- 기존 AI 및 인지과학 연구에서 영감을 받아, **"문제를 해결하는 과정은 다양한 경로를 탐색하는 트리(tree) 구조"**와 같다고 가정한다.  
- **ToT는 각 사고(thought)를 트리의 노드로 간주**하고, 다양한 사고 경로를 탐색하면서 최적의 해결책을 찾아간다.

## 3.2 ToT의 주요 구성 요소

1. **사고 단계(thought steps)의 분해**  
   - CoT는 사고를 하나의 연속적인 텍스트로 생성하지만, ToT는 **작업의 특성에 맞게 사고 단계를 명확히 분해**하여 탐색 가능성을 높인다.

2. **사고 생성(Thought Generation, G)**  
   - LLM이 주어진 상태에서 여러 개의 대체 사고(thoughts)를 생성할 수 있도록 한다.  
   - 두 가지 방법을 사용:
     - **독립 샘플링(Independent Sampling)**: 서로 독립적인 사고를 여러 개 생성(CoT 기반).
     - **연속적 제안(Sequential Proposing)**: 이전 사고를 기반으로 단계적으로 새로운 사고를 제안.

3. **상태 평가(State Evaluation, V)**  
   - 여러 개의 사고 경로 중 **가장 유망한 경로를 선택**하기 위해, LLM이 스스로 평가를 수행한다.
   - 평가 방법:
     - **개별 평가(Individual Evaluation)**: 각 사고를 독립적으로 평가(예: 점수 부여).
     - **비교 평가(Comparative Voting)**: 여러 사고 중 최적의 것을 선택하는 다중 선택 방식.

4. **탐색 알고리즘(Search Algorithm)**  
   - 트리 구조를 탐색하는 방법으로, **너비 우선 탐색(BFS)과 깊이 우선 탐색(DFS)**을 활용한다.
   - 문제의 특성에 따라 적절한 탐색 방식을 선택:
     - **BFS (너비 우선 탐색)**: 여러 경로를 동시에 탐색하며 최적의 경로를 찾는다.
     - **DFS (깊이 우선 탐색)**: 하나의 유망한 경로를 깊게 탐색하되, 필요할 경우 가지치기를 수행하여 비효율적인 경로를 제거.

<img width="712" alt="image" src="https://github.com/user-attachments/assets/0432cc84-f329-44e4-9a72-478a3795140d" />

## 3.3 ToT의 장점

- **일반성(Generality)**  
  - 기존 **IO Prompting, CoT, CoT-SC, Self-Refinement** 등의 접근법을 포괄하는 개념이다.
- **모듈성(Modularity)**  
  - 사고의 분해, 생성, 평가, 탐색 알고리즘을 독립적으로 조합하여 사용할 수 있다.
- **적응성(Adaptability)**  
  - 다양한 문제 유형에 맞춰 탐색 및 평가 전략을 변경할 수 있다.
- **편의성(Convenience)**  
  - 추가적인 학습 없이 **사전 학습된 LLM을 프롬프트만으로 활용**할 수 있다.

- ToT는 **LLM이 더욱 강력한 문제 해결 능력을 가질 수 있도록 설계된 프레임워크**이며, 이후 실험을 통해 다양한 문제에서 기존 방법보다 우수한 성능을 보인다는 점을 입증한다&#8203;:contentReference[oaicite:0]{index=0}.

# 4. Experiments

<img width="712" alt="image" src="https://github.com/user-attachments/assets/8d883e2a-c550-4e9b-bb44-71adb7eb671f" />

- 논문에서는 **Tree of Thoughts(ToT)**가 기존 방법보다 뛰어난 문제 해결 능력을 갖추었음을 입증하기 위해 세 가지 복잡한 문제를 실험한다.
- 실험 대상 문제:
  1. **Game of 24** (수학적 추론)
  2. **Creative Writing** (창의적 글쓰기)
  3. **Mini Crosswords** (단어 퍼즐)

## 4.1 Game of 24 (수학적 문제 해결)

<img width="712" alt="image" src="https://github.com/user-attachments/assets/2809ef6c-5ec2-4dda-b5ff-b1614b87c61d" />

- **문제 설명**  
  - 주어진 네 개의 숫자(예: 4, 9, 10, 13)를 **사칙연산을 활용해 24를 만드는 방정식을 찾는 문제**이다.

- **실험 설정**  
  - 난이도가 높은 문제 100개를 선택하여 테스트.  
  - 기존 방법들과 비교:
    - **IO Prompting**: 입력을 받고 바로 정답을 출력하는 방식.
    - **CoT Prompting**: 중간 사고 단계를 포함하여 문제 해결.
    - **CoT-SC (Self-Consistency)**: 여러 개의 CoT 답안을 생성한 후 다수결 선택.
    - **IO + Refine**: 잘못된 답안을 수정하면서 점진적으로 개선.

- **ToT 적용 방법**  
  - 문제 해결을 **트리 탐색 문제로 변환**하여 해결.  
  - 각 단계에서 여러 개의 연산을 탐색하고, **가장 가능성 높은 경로를 선택**하여 진행.

- **결과 비교**  
  | 방법 | 성공률 |
  |------|------|
  | IO Prompting | 7.3% |
  | CoT Prompting | 4.0% |
  | CoT-SC (k=100) | 9.0% |
  | ToT (b=1) | 45% |
  | ToT (b=5) | 74% |
  | IO + Refine (k=10) | 27% |
  | IO (best of 100) | 33% |
  | CoT (best of 100) | 49% |

  - **ToT(b=5)는 74% 성공률을 기록**, 기존 방법보다 월등히 높은 성능을 보임.

---

## 4.2 Creative Writing (창의적 글쓰기)

<img width="712" alt="image" src="https://github.com/user-attachments/assets/04b65615-7240-4313-9631-7e9c4fef06cf" />

- **문제 설명**  
  - 주어진 **4개의 문장**을 포함하는 **일관성 있는 4단락 글쓰기**를 수행하는 문제.

- **실험 설정**  
  - 100개의 무작위 문장을 사용하여 테스트.  
  - 평가 기준:
    - GPT-4를 활용한 자동 평가(1~10점)  
    - 사람을 대상으로 한 블라인드 비교 평가

- **ToT 적용 방법**  
  - ToT는 **우선적으로 글의 구조를 계획한 후 본문을 작성**하는 방식을 사용.  
  - **두 단계 트리 탐색**
    1. 여러 개의 글쓰기 계획(5개) 생성 후 **투표로 최적의 계획 선택**  
    2. 선택된 계획을 바탕으로 여러 개의 본문(5개) 작성 후 **투표로 최적의 본문 선택**

- **결과 비교**  
  | 방법 | GPT-4 평가 (1~10점) | 인간 평가 비교 |
  |------|------|------|
  | IO Prompting | 6.19 | - |
  | CoT Prompting | 6.93 | 21% 우세 |
  | ToT | 7.56 | 41% 우세 |

  - **ToT 방식이 가장 높은 평가(7.56점)를 받으며, 인간 평가에서도 가장 선호됨.**

---

## 4.3 Mini Crosswords (단어 퍼즐)

<img width="712" alt="image" src="https://github.com/user-attachments/assets/cad40a56-01c0-4e05-b18d-3f51f5e93e19" />

- **문제 설명**  
  - 5×5 낱말 퍼즐을 풀어 **주어진 단어 힌트에 맞는 정답을 채우는 문제**.

- **실험 설정**  
  - 주어진 힌트에 맞춰 정답을 완성하는 정확도를 측정.

- **ToT 적용 방법**  
  - 각 단어를 채울 때, **가능한 여러 개의 후보를 생성하고, 가장 적절한 단어를 선택하는 방식**을 사용.  
  - 기존 방법(CoT)보다 다양한 정답 가능성을 평가하는 것이 특징.

- **결과 비교**  
  - ToT는 **기존 GPT-4보다 정답률이 높고, 단어 배열의 일관성이 우수함**을 보임.

---

## 4.4 결론

- ToT는 **체계적인 탐색 및 평가 전략을 적용하여** 기존 방법보다 훨씬 높은 성능을 기록한다.
- 특히 **수학적 추론(Game of 24)**과 **창의적 문제 해결(Creative Writing, Mini Crosswords)**에서 **기존 CoT보다 우수한 결과**를 보인다.
- **기존 LLM 접근법(IO, CoT, CoT-SC 등)과 달리, ToT는 트리 탐색을 통해 다양한 해결 경로를 고려하며 최적의 해결책을 찾는다**.
