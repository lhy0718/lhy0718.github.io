---
title: "[논문리뷰] SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations (EMNLP 2023 Findings)"
date: 2025-03-15 00:00:00 +0900
categories:
  - Paper Review
tags:
  - EMNLP 2023 Findings
  - Empathetic Dialogue Systems
---

요약: 대용량 언어 모델(LLM)이 심리 상담 분야에 적용될 때, 사용자에게 공감과 신뢰를 제공하는 것이 중요하다는 점을 강조하며, 이를 위해 다중 회차 공감 대화 데이터셋을 구축하고, 실험을 통해 LLM의 공감 능력을 향상시킬 수 있음을 보여주었다.

---

# 1 Introduction

- BERT와 GPT의 출현 이후, 대형 언어 모델(LLMs)은 빠른 발전을 이루었음.
- 2022년 11월, OpenAI가 ChatGPT를 출시하였고, 이는 인간의 피드백을 통한 강화 학습(RLHF)으로 세부 조정됨.
- ChatGPT가 정신 건강이나 정서적 지원 대화에 적용될 때 나타나는 주요 문제점:
  - **반복적이고 표준화된 응답**:
    - ChatGPT는 종종 사용자 질문에 대해 템플릿 기반으로 응답하기 때문에 나른함이 발생함. 예: "나는 미안합니다... {xxx}는... 다음과 같은 몇 가지 제안이 있습니다: ..."
  - **질문보다는 제안 제공**:
    - 사용자의 문제 해결에 eager하며 일반적인 제안을 길게 하는 경향이 있음. 그러나 전문 심리 상담사는 상담 과정에서 구체적인 제안을 rarely 제공함.
  - **감정적 지원 부족**:
    - 사용자가 듣기와 위로를 필요로 할 때, ChatGPT는 합리적인 "직선적 사람"처럼 행동함.
- 타 LLM에서도 유사한 문제 발생: ChatGLM, SparkDesk 등.
- 큰 규모의 다중 턴 공감 대화 데이터셋 부족이 문제 원인 중 하나로, 특히 중국 정신 건강 분야에서 심각함.
- 기존의 영어 공감 대화 데이터셋(EMPATHETIC DIALOGUES, ESConv)과 중국어 LLM을 위한 데이터셋 부족.
- **정신 건강 관련 데이터셋**:
  - efaqa: 20,000 대화 포함, 복잡한 다자간 대화 관계를 가지고 있어서 질 낮은 응답 많음.
  - PsyQA: 22,346 개 질문과 56,063 개의 단일 턴 심리 상담 대화 포함.
- Qiu et al.(2023)은 SMILE 접근법을 제안하여 단일 턴 대화를 다중 턴 대화로 변환.
- SoulChatCorpus: 2,300,248 샘플을 포함하는 다중 턴 공감 대화 데이터셋을 구축함.
- ChatGLM-6B 모델을 사용하여 SoulChatCorpus로 파인튜닝 실험을 진행하고, LLM의 공감 및 위로 능력이 크게 향상됨.

---

# 2.1 SoulChatCorpus Collection

- 일대일 심리 상담 대화 설정을 고려함
- 사용자와 심리 상담사가 다수의 대화를 진행
- 상담 데이터는 개인정보 보호 및 윤리 기준으로 인해 공개되지 않음
- 질 높은 다중 턴 공감 대화 데이터셋 구성하기 위해:
  - 12개의 상담 주제 선정
  - 215,813개의 긴 질문과 619,725개의 긴 답변 생성 (크라우드소싱을 통해)
- 주제 분포는 도표로 제시됨 (Figure 3)
- ChatGPT 사용:
  - 99%는 gpt-3.5-turbo API, 1%는 gpt-4 API
  - 단일 턴 심리 상담 대화를 다중 턴 공감 대화로 변환
  - 형식: "用户: <user_utt>\n心理咨询师: <psy_utt>"
  - "心理咨询师"의 응답은 공감, 경청, 위로 등의 인간 중심 표현 반영 요구
- 수동 교정 후 저품질 샘플 105,134개 제거
- 최종적으로 2,300,248개의 샘플 확보
- Figure 4에서 심리 상담사의 발화 표현을 보여주는 워드 클라우드 맵:
  - 리워팅 된 다중 턴 공감 대화는 높은 공감 수준을 나타냄

---

# 2.2 SoulChat Model

- **모델 기초**: SoulChat은 ChatGLM-6B (Du et al., 2022; Zeng et al., 2023)를 기반으로 개발됨.
- **ChatGLM-6B 특징**:
  - 오픈 소스의 이중 언어 LLM.
  - General Language Model (GLM) 프레임워크 기반.
  - 62억 개의 파라미터를 가짐.
- **모델 입력 정의**:
  - 입력은 다음과 같이 정의됨: 
  $$input = uu_1 +'\n'+ up_1 + ... + uu_N +'\n'+ up_N$$
  - 여기서:
    - 사용자의 발화: $$uu_i = '用户：(User:)' + utterance_u_i$$
    - 심리 상담사의 발화: $$up_i = '心理咨询师：(Psychologist:)' + utterance_p_i$$ (단, $$i < N$$).
    - $$up_N = '心理咨询师：(Psychologist:)'$$.
    - $$N$$은 대화 턴의 수를 나타냄.
- **평가 결과**: SoulChat은 다양한 지표에서 우수한 성능을 보임.
  - 자동 및 수동 평가 결과가 표에 나타나 있음.
  - SoulChat의 성능은 다른 모델들과 비교하여 개선됨.

---

# 3.1 Baselines

- SoulChat과 비교되는 벤치마크 모델은 아래와 같음:
  1. **ChatGLM-6B4** (Du et al., 2022; Zeng et al., 2023)
     - SoulChat의 기본 모델로 사용됨.
  2. **ChatGPT** (OpenAI, 2022; Ouyang et al., 2022)
     - 감독 학습 및 인간 피드백으로부터의 강화 학습(RLHF)을 통해 훈련된 LLM.
  3. **MeChat** (Qiu et al., 2023)
     - SMILECHAT 데이터셋에 대해 낮은 순위 적응(LoRA) (Hu et al., 2022)을 사용하여 미세 조정된 LLM.
     - SMILECHAT 데이터셋은 ChatGPT가 PsyQA를 기반으로 생성한 것임.

---

# 3.2 Implementation details

- SoulChat은 제안된 SoulChat-Corpus로 세부 조정됨
- 배치 크기: 80
- 전체 훈련 단계: 30,000
- 학습률 조정기: WarmupDecayLR 사용
  - warmup\_steps: 1,000
  - warmup\_max\_lr: $$5 \times 10^{-5}$$
- 최대 입력 토큰 길이: 1,536
- 최대 출력 토큰 길이: 512
- 추론 단계에서의 디코딩 알고리즘:
  - Top-p 샘플링 사용
  - $$p = 0.75$$
  - 온도 $$\tau = 0.95$$

---

# 3.3 Results and Analysis

- 10,000개의 샘플을 SoulChatCorpus와 SMILECHAT에서 무작위로 선택하여 자동 평가를 위한 테스트 세트를 구성하고, 100개의 샘플은 수동 평가에 사용.
- 각 샘플에 대해 각 모델이 평가를 위한 응답 생성.
- 자동 평가를 위해 7개의 평가 지표 사용:
  - **BLEU:** B-1, B-2, B-3, B-4 (Papineni et al., 2002)
  - **ROUGE:** R-1, R-2, R-L (Lin, 2004)
- 심리학 전공 3명의 전문가가 생성된 응답을 평가:
  - 평가 항목: 내용 자연스러움(Con.), 공감 수준(Emp.), 유용성(Hel.), 안전성(Saf.)
  - Con., Emp., Hel.의 평가 척도: (0, 1, 2) / Saf.: (0, 1)
  - 높은 점수가 더 좋은 평가를 의미.
- SoulChatCorpus와 SMILECHAT의 100개의 대화 샘플을 무작위로 선택하여 수동 평가 진행.
- Fleiss’ κ 지수:
  - Con.: 0.489 (보통 수준의 동의성)
  - Emp.: 0.472 (보통 수준의 동의성)
  - Hel.: 0.532 (보통 수준의 동의성)
  - Saf.: κ = 1 (완벽한 동의성)
- 평가 결과는 표 1에 제시됨.
- 일반적으로 SoulChat은 SoulChatCorpus와 SMILECHAT의 테스트 세트에서 자동 평가 지표와 Emp. 지표 모두에서 ChatGLM-6B, ChatGPT, MeChat보다 우수한 성능을 보임.
- SMILECHAT의 결과는 정신 건강 분야에서 SoulChat의 우수한 제로-샷 성능을 보여줌.

---

# 4 Conclusion and Future Work

- 본 논문에서는 LLM을 더 인간 중심적으로 만드는 방법을 탐구함.
- 이를 위해 12개의 공감 주제와 200만 개 이상의 샘플로 구성된 중국어 대규모 다중 턴 공감 대화 데이터셋인 SoulChatCorpus를 구축함.
- 실험 결과, 이 데이터셋을 사용하여 LLM을 파인튜닝함으로써 사용자가 LLM으로부터 감정적 지원을 받을 때 높은 수준의 공감 능력을 보임.
- 향후 연구는 성격, 성별 등과 같은 사용자 속성을 더욱 고려하여 각 개인에 맞춘 공감 응답을 LLM이 생성할 수 있도록 해야 함.

---

# Limitations
- 제안된 SoulChat 모델은 뛰어난 공감 능력을 갖추었지만, 몇 가지 한계점이 존재함.
- 공감 메커니즘은 복잡하며, 사용자의 기대치가 모델의 출력에 따라 다름.
- 예를 들어, 긴장된 감정에 대해 성인과 청소년이 기대하는 해결책에 상당한 차이가 존재함.
- 따라서, 인간 중심의 LLM은 사용자의 성격, 정체성 등의 특성을 더욱 고려하여 사용자의 필요에 보다 적합한 답변을 생성하는 데 도움을 줄 필요가 있음.

---

# Ethics Statement

- **데이터 수집**
  - 개인정보 보호를 위해 엄격한 수작업 교정 프로세스를 채택하여 데이터셋을 구성.
  - "我是(I am)", "自杀(suicide)", "跳楼(jumping off a building)" 등의 특별 문자열이 포함된 샘플 필터링.
  - 개인정보와 관련된 텍스트는 수정하거나 삭제.
  - 사용자, 타인 또는 사회에 해를 끼칠 수 있는 대화는 완전히 제거.
  - 이 과정에서 ChatGPT가 생성한 다중 턴 대화 샘플 105,134개 삭제.

- **모델의 잠재적 위험**
  - 모델의 출력에 대한 안전성 평가를 수동 평가 단계에서 수행.
  - 모델 미세 조정 단계에서 인간 피드백 부족으로 인해 사용자에게 해를 끼칠 수 있는 답변 발생 가능성 존재.
  - 향후 연구에서는 RLHF를 결합하여 모델 생성 콘텐츠의 안전성 향상 필요.
  - 모델 사용 시, 사용자가 보고 있는 답변이 AI 모델에 의해 생성된 것임을 사전에 알려야 하며 참고용으로만 사용해야 함.

- **주석자 보상**
  - 심리학 전공의 전문가를 초청하여 모델 출력의 CEHS 평가 수행.
  - 각 샘플 평가에 약 3분 소요, 이때 주당 $$0.418의 급여를 받을 수 있음.
  - 주석자의 시간당 급여는 $$8.36으로, 미국 최저 임금 $$7.12보다 높음.