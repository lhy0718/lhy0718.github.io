---
title: "[논문리뷰] MISC- A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation (ACL 2022)"
date: 2025-03-15 15:30:00 +0900
categories:
  - Paper Review
tags:
  - ACL 2022
  - Empathetic Dialogue Systems
---

요약: 이 논문에서는 감정 지원 대화에서 기존 방법의 한계를 극복하기 위해 사용자의 세밀한 감정 상태를 추론하고, 다양한 전략을 혼합하여 응답하는 새로운 모델 MISC를 제안하며, 실험 결과 이 방법의 효과성을 입증하였다.

---

# 1 Introduction

- 공감(empathy)은 타인의 감정을 인식하고, 그들의 입장에서 사고하며, 적절히 반응하는 능력이다.
- 기계에 공감 능력을 부여하기 위한 다양한 응용 시나리오가 존재한다:
  - 자동 심리 치료사
  - 지능형 고객 서비스
  - 공감하는 대화 에이전트 등 (Fitzpatrick et al., 2017; Shin et al., 2019; Ma et al., 2020).
  
- 본 연구는 인간-컴퓨터 간의 특별한 공감 대화 형태인 감정 지원 대화(emotional support conversation)에 집중한다 (Liu et al., 2021).
  
- 감정 지원 대화는 탐색자(seeker)와 지원자(supporter) 간의 대화로, 지원자는 대화 진행에 따라 탐색자의 고통을 점차 줄이는 것을 목표로 한다.
  
- 기존 접근 방식의 부적합 이유:
  1. **정서 예측의 제한성**: 기존의 감정 대화 연구는 대화 수준의 정서 레이블을 사용해 사용자 감정을 예측하는데, 이는 정서가 복잡하고 대화 도중 감정의 강도가 변하는 사실을 반영하지 못한다 (Rashkin et al., 2019; Lin et al., 2019c; Li et al., 2020a).
  
  2. **감정 문제 해결 부족**: 대다수의 공감 챗봇은 예측된 정서 클래스에 따라 정서적으로 반응하도록 훈련되었으나, 탐색자의 감정 문제를 해결하는 데는 부족하다 (De Graaf et al., 2012; Majumder et al., 2020; Xie and Park, 2021).
  
- **제안하는 방법**: MISC (MIxed Srategy-aware model) 
  - COMET라는 사전 훈련된 생성적인 상식 추론 모델을 도입하여, 정서 이해를 위한 주의 메커니즘을 활용한다.
  - 다양한 COMET 지식 튜플을 사용하여 탐색자의 즉각적인 정신 상태를 포착한다.
  
- 응답 생성 시 반응 전략을 고려하여 믹스드 전략을 기반으로 모델링한다.
- MISC는 COMET으로 향상된 정신 정보와 분산된 전략 표현을 바탕으로 지원 응답을 생성한다.
  
- 실험은 ESConv 벤치마크에서 수행하고, 5개의 최신 공감 챗봇과 비교한다.
- MISC 모델의 응답이 더 적절하고 공감적임을 보인다.
  
- 기여 내용:
  1. 공감 지원 대화에 상식 지식과 혼합 반응 전략을 통합한 Seq2Seq 모델 MISC 제안.
  2. ESConv 데이터셋에 대한 실험 진행 및 SOTA 방법과의 비교를 통해 MISC의 효과성 입증.
  3. 전략 모델링의 다양한 방법 구현 및 전략 인지형 감정 지원 대화에 대한 힌트 제공.

---

# 2.1 Emotion-aware Response Generation

- 감정 인식 대화 시스템은 Liu et al. (2021)에 따라 세 가지 종류로 분류됨:
  - 감정적 채팅
  - 공감적 응답
  - 정서적 지원 대화
- 초기 연구는 감정적 채팅을 목표로 하였으며, 감정 신호에 의존함 (Li et al., 2017; Zhou et al., 2018a; Wei et al., 2019; Zhou and Wang, 2018; Song et al., 2019).
- 이후 연구자들은 사용자의 특정 감정을 유도하는 것으로 초점을 전환함 (Lubis et al., 2018; Li et al., 2020b).
- 최근 연구는 더 깊은 감정 이해와 공감적 응답을 위해 추가 정보를 통합하기 시작함 (Lin et al., 2020; Li et al., 2020a; Roller et al., 2021).
- Li et al. (2021a)와 Zhong et al. (2021)은 응답 생성을 위한 감정 추론을 개선하기 위해 ConceptNet을 활용함.
- 본 연구는 이러한 접근과 달리 생성적 상식 모델인 COMET (Bosselut et al., 2019b)를 활용하여:
  - 사용자의 정신 상태를 포착하고
  - 정서적 지원 대화에서 전략 예측을 용이하게 함.

---

# 2.2 Commonsense Knowledge for NLP

- 최근 다양한 NLP 작업에 상식 지식을 적용한 연구가 활발하게 진행되고 있음
  - 포함되는 작업:
    - 분류 (Chen et al., 2019; Paul and Frank, 2019)
    - 질문 응답 (Mihaylov and Frank, 2018; Bauer et al., 2018; Lin et al., 2019a)
    - 이야기 생성 및 언어 생성 (Guan et al., 2019; Ji et al., 2020)
    - 대화 시스템 (Zhou et al., 2018b; Zhang et al., 2020; Li et al., 2021a; Zhong et al., 2021)

- 대화 시스템은 종종 ConceptNet (Speer et al., 2017)을 활용하여 물리적 지식으로 대화 발화를 보완
- ConceptNet과 구별되는 ATOMIC (Sap et al., 2019)은 사회적 지식, 사건 중심의 원인 및 결과, 개인 관련 심리 상태를 다룸
  - ATOMIC은 감정 이해에 유익하고 응답의 공감에 기여할 것으로 기대됨

- 해당 연구에서는 ATOMIC을 기반으로 학습된 상식 추론 모델인 COMET (Bosselut et al., 2019b)를 활용하여 감정 지원 대화에 적용함

---

# 2.3 Strategy-aware Conversation Modeling

- 대화 전략은 다양한 관점에서 여러 가지 개념으로 정의될 수 있음.
- 연구의 대부분은 대화 행동(dialog acts) 개념 아래 진행됨.
  - 다양한 대화 행동 체계가 개발됨 (Mezza et al., 2018; Paul et al., 2019; Yu and Yu, 2021).
  - 대화 행동은 과업 지향 대화 시스템 및 개방형 소셜 챗봇에서 실증적으로 유용함 (Zhao et al., 2017; Xu et al., 2018; Peng et al., 2020; Li et al., 2020c).
- 공감 대화의 경우, 대화 전략은 반응 의도(response intention) 또는 커뮤니케이션 전략(communication strategy)으로 정의됨.
  - 이는 심리학 및 신경과학의 공감 이론에서 영감을 받음 (Lubis et al., 2019; Li et al., 2021b).
- Welivita와 Pu (2020)는 사람들이 타인에 대해 공감할 때 사용하는 15가지 반응 의도의 분류법을 정의함.
- Liu et al. (2021)은 타인의 정서적 고통을 줄이기 위해 사람들이 사용하는 8가지 지원 전략을 정의함.
- 이러한 연구는 반응 전략이 복잡함을 부분적으로 드러내며, 이는 지원 반응을 생성할 때 다양한 전략의 혼합에 의존하도록 동기를 부여함.

---

# 3.1 ESConv Dataset

- 본 문서에서는 감정 지원 대화 데이터셋인 ESConv(Liu et al., 2021)를 사용함.
- 대화가 시작되기 전에, 도움을 요청하는 사람(어드바이저)은 자신의 감정 유형을 결정하고, 지원자에게 다루고 있는 상황을 전달해야 함.
- 각 지원자의 발화 전략이 표시되어 있으며, 이는 본 연구에서 가장 중요함.
- 총 8가지 전략이 있으며, 이들은 거의 고르게 분포되어 있음.
- 자세한 내용은 부록에 제공됨.

---

# 3.2 Problem Formulation

- 일반적인 대화 응답 생성의 목표:
  - 데이터셋 $$D = \{c(i), r(i)\}^N_{i=1}$$의 확률 분포 $$p(r \vert c)$$ 추정
  - 여기서 $$c(i) = (u(i)_1, u(i)_2, \ldots, u(i)_{n_i})$$는 대화 이력의 $$n_i$$ 발화 시퀀스
  - $$r(i)$$는 타겟 응답

- 예제를 설명할 때는 편의를 위해 인덱스 (i)를 생략함.

- 정서적 지원 대화의 설정에서:
  - 탐색자의 상황 $$s$$는 추가 입력으로 고려됨.
  - $$s$$는 탐색자의 문제를 자유 형식의 텍스트로 설명.
  - 탐색자의 마지막 발화는 $$x$$로 표기.

- 따라서, 목표는 확률 분포 $$p(r \vert c, s, x)$$ 추정.

---

# 4 Model: MISC

- MISC 모델은 다음 세 가지 주요 구성 요소로 구성됨:
  1. **정신 상태 강화 인코더**: Bosselut et al. (2019a)에 기반.
  2. **혼합 전략 학습 모듈**.
  3. **다중 요인 인식 디코더**.

- MISC는 blenderbot-small (Roller et al., 2021)을 기반으로 함.

- 모델의 구성 요소들은 정신 상태 반영 및 다양한 전략을 학습하여 전반적인 성능을 향상시키는 데 기여함.

---

# 4.1 Mental State-Enhanced Encoder

- 대화의 맥락을 표현하기 위해 인코더 $E$를 사용하여 다음과 같이 정의:  
  $$C = E(CLS, u_1, EOS, u_2, \ldots, u_n)$$  
  - 여기서 $$CLS$$는 시작 토큰, $$EOS$$는 두 발화 간의 분리 토큰임.

- 대화의 맥락을 더 잘 이해하기 위해 COMET (Bosselut et al., 2019a)를 활용하여 대화와 관련된 정신 상태 정보를 생성함.  
  - 상황 $s$를 이벤트로 취급하고, 다양한 관계를 COMET에 입력:  
  $$B_s = \sum_{j=1}^{N_r} COMET(rel_j, s)$$  
  - $N_r$는 COMET의 사전에 정의된 관계의 수, $rel_j$는 $j$번째 특정 관계.

- 각 이벤트-관계 쌍에 대해 COMET은 다수의 자유 형식 정신 상태 정보 "tail"을 생성함.  
  - 집합 $B_s$는 $N_s$개의 정신 상태 블록으로 구성:  
  $$B_s = \{ bs_j \}_{j=1}^{N_s}$$

- 유사하게, 구자의 마지막 게시물 $x$를 사용하여 정신 상태 블록 집합 $B_x$를 얻음.

- 모든 자유 형식 블록은 인코더 $E$를 사용하여 밀집 벡터로 변환됨:  
  $$\hat{H}_s = [h_{s_{1,1}}, h_{s_{2,1}}, \ldots, h_{s_{N_s,1}}]$$  
  - 각 블록의 첫 번째 토큰의 숨겨진 상태가 해당 블록을 나타냄.

- COMET 블록의 노이즈로 인해 많은 블록이 맥락과 무관함.  
  - 강한 관련 블록을 정제하기 위해 주의(attention) 기법을 사용:  
  $$Z = softmax( \hat{H}_s \cdot C^T) \cdot C$$  
  $$H_s = LN( \hat{H}_s + Z)$$  
  - 여기서 $LN$은 LayerNorm 모듈.

- 마지막으로, 동일한 방법을 사용하여 대화 수준 및 발화 수준의 구자의 정신 상태 표현인 $H_s$와 $H_x$를 얻음.  
  - 이 표현들은 상식 정보로 향상됨.

---

# 4.2 Mixed Strategy Learning Module

- 반응 전략 예측 방법:
  - CLS 상태를 기반으로 분류기를 훈련하여 반응 전략을 예측.
  - 수식: $$pg = MLP(C1)$$ 
    - 여기서 MLP는 다층 퍼셉트론.
    - $$pg$$는 사용될 각 전략의 확률 기록.

- 반응 전략의 복잡성 모델링:
  - 확률 분포 $pg$를 활용하여 혼합 전략 모델링 제안.
  - VQ-VAE의 코드북 아이디어를 적용.
  - 전략 코드북 $$T \in \mathbb{R}^{m \times d}$$는 $$m$$개의 전략 잠재 벡터를 나타냄 (여기서 $$m = 8$$, 차원 크기 $$d$$).

- 전략 표현 생성:
  - 확률 $$pg$$를 사용하여 코드북 $T$를 가중 평균하여 반응 전략 표현 $$hg$$ 생성.
  - 수식: $$hg = pg \cdot T$$ 

- 코드북 기반 방법의 장점:
  1. 긴 반응이 필요한 경우(감정적 지원 대화에서 흔함)에 구혼의 고통을 효과적으로 줄이는 데 유리함.
  2. 유연한 학습 가능.
     - $pg$의 확률이 높을수록 대화 가이드에 더 큰 영향을 미침.
     - 극단적인 경우에는 명확한 분포를 통해 단일 전략이 전체 제어를 차지할 수 있음.

---

# 4.3 Multi-Factor-Aware Decoder

- 추론된 정신 상태와 전략 표현을 적절히 활용하는 것이 중요함.
- 디코더에 이러한 정보를 전달하기 위해, 다음과 같이 백본의 크로스 어텐션 모듈을 수정함:
  - $$A_c = \text{CROSS-ATT}(O, H)$$
  - $$A_s = \text{CROSS-ATT}(O, H_s)$$
  - $$A_x = \text{CROSS-ATT}(O, H_x)$$
  - $$A_g = \text{CROSS-ATT}(O, h_g)$$
  - $$O' = \text{LN}(A_c + A_s + A_x + A_g + O)$$
  
- 여기서, $\text{CROSS-ATT}$는 백본의 크로스 어텐션 모듈을 의미하며, $O$는 디코더의 숨겨진 상태로 멀티 팩터와 상호작용하여 최종 응답을 생성함.
- blenderbot-small (Roller et al., 2021)를 기반으로 모델을 공동 훈련하여 전략을 예측하고 응답을 생성함:
  - $$L_r = -\sum_{t=1}^{n_r} \log(p(r_t \mid r_{j<t}, c, s, x))$$
  - $$L_g = -\log(p(g \mid c, s, x))$$
  - $$L = L_r + L_g$$
  
- 여기서, $$n_r$$는 응답의 길이, $$g$$는 실제 전략 레이블, $$L_g$$는 전략 예측 손실, $$L_r$$는 응답 예측 손실, $L$은 최소화해야 할 결합 목표임.

---

# 5.1 Experimental Setups

- 실험 데이터셋: ESConv (Liu et al., 2021) 사용
- 전처리 과정:
  - 대화 예시를 10개의 발화마다 잘라냄
  - 데이터셋을 훈련, 검증, 테스트로 랜덤 분할 (비율: 8:1:1)
- 통계 정보 (표 1 참조):
  - 훈련 대화 수: 14117
  - 검증 대화 수: 1764
  - 테스트 대화 수: 1764
  
  - 평균 발화당 단어 수: 
    - 훈련: 17.25
    - 검증: 17.09
    - 테스트: 17.11

  - 평균 대화당 턴 수: 
    - 훈련: 7.61
    - 검증: 7.58
    - 테스트: 7.49

  - 평균 대화당 단어 수: 
    - 훈련: 148.46
    - 검증: 146.66
    - 테스트: 145.17

---

# 5.2 Evaluation Metrics

- 평가를 위해 자동화 및 인간 평가 지표 세트를 채택함.
  
## 자동 지표
1. **예측 정확도 (ACC)** 
   - 전략 예측 정확도를 중요한 지표로 사용.
   - 높은 ACC는 모델이 응답 전략을 선택하는 능력이 뛰어남을 나타냄.
  
2. **전통적 지표** 
   - PPL (perplexity), B-2 (BLEU-2), B-4 (BLEU-4) 등 사용 (Papineni et al., 2002).
   - R-L (ROUGE-L) (Lin, 2004) 및 M (Meteor) (Denkowski and Lavie, 2014) 지표로 생성된 응답의 어휘 및 의미적 측면을 평가.
  
3. **응답 다양성** 
   - D-1 (Distinct-1) 및 D-2 (Distinct-2) 수치를 보고, 생성된 응답에서 고유 n-그램의 비율을 평가함 (Li et al., 2016).

## 인간 평가
- See et al. (2019)를 따르며, 언어 및 심리학 배경을 가진 3명의 전문 주석가를 모집.
- 생성된 응답을 유창성, 지식 및 공감 측면에서 {0,1,2} 수준으로 평가하도록 요청.
- 공정한 비교를 위해 주석가는 응답이 어떤 모델에서 나온 것인지 모르게 평가.
- 3명의 주석가는 보수를 받고, 결과는 또 다른 1명이 검증함.

---

# 5.3 Compared Models

- **Transformer**
  - 기본 Seq2Seq 모델로, 최대 우도 추정(MLE) 손실에 의해 훈련됨. (Vaswani et al., 2017)

- **MT Transformer**
  - 다중 작업(Multi-Task) 트랜스포머로, 감정 예측을 추가 학습 과제로 고려함. (Rashkin et al., 2018)
  - ESConv에서 제공하는 대화 수준의 감정 레이블을 사용하여 감정 예측 학습.

- **MoEL**
  - 여러 리스너(디코더)로부터 출력 상태를 부드럽게 결합하여 다양한 감정에 대한 응답 공감을 향상시킴. (Lin et al., 2019b)

- **MIME**
  - 감정 기반 군집과 감정 모방을 고려하여 공감 응답 생성을 진행함. (Majumder et al., 2020)

- **BlenderBot-Joint**
  - ESConv 데이터셋에서 최고 성능(SOTA) 모델로, 응답 발화 앞에 특별 전략 토큰을 추가함. (Liu et al., 2021)

---

# 5.4 Implementation Details

- 본 연구에서는 blenderbot-small (Roller et al., 2021)을 기반으로 구현
- 기본적인 어휘 및 숨겨진 상태 크기를 사용
- 마지막 게시물 $x$와 상황 $s$에 대해:
  - 최대 검색 COMET 블록 수: 30 (게시물) 및 20 (상황)
  - 인퍼된 COMET 블록은 최대 10개의 단어로 인코더에 전송
- Liu et al. (2021)와의 비교를 위해:
  - 90M 파라미터 크기의 blenderbot-small을 기반으로 MISC를 미세 조정
  - 사용된 GPU: Tesla-V100
  - 학습 배치 크기: 20
  - 평가 배치 크기: 50
- 학습률 초기화: $$2 \times 10^{-5}$$, 
  - 학습 중 선형 웜업 사용 (웜업 스텝: 120)
- 옵티마이저: AdamW (Loshchilov and Hutter, 2018) 
  - 파라미터: $$\beta_1 = 0.9$$, $$\beta_2 = 0.999$$, $$\epsilon = 1 \times 10^{-8}$$
- 8 에포크 후, 검증 세트에서 최소의 당혹도를 가진 체크포인트 선택
- 디코딩 알고리즘:
  - Top-p 및 Top-k 샘플링 사용 
  - 파라미터: $$p = 0.3$, $k = 30$$, 온도 $$\tau = 0.7$$, 반복 패널티: 1.03
- 소스 코드를 공개하여 향후 연구를 지원할 계획

---

# 5.5 Experimental Results

- **모델 성능 비교**
  - 기본 Transformer는 상대적으로 낮은 PPL, BLEU-n, distinct-n 점수로 인해 가장 낮은 성능을 보임.
  - MT Transformer, MoEL, MIME도 성능이 실망스러움.
    - 이 세 모델 모두 감정 예측 및 듣는 사람의 집합과 같은 공감 목표를 가진다면도, 대화 수준의 정적 감정 레이블에 기반하여 세밀한 감정 이해에 부족함.
    - 공감 대화 설정에서 요청자에게 전략적으로 위로하는 능력이 부족함.

- **MISC 모델의 효과**
  - SOTA 모델인 BlenderBot-Joint와 비교 시 MISC 모델이 더 효과적임.
    - BlenderBot-Joint는 첫 번째 디코딩 단계에서 단일 전략만을 예측하지만, MISC는 혼합된 응답 전략을 모델링하고 디코더가 부드러운 전이를 학습하도록 허용함.
    - 이는 감정 지원 대화에서 응답 전략을 추가 작업으로 예측하는 것이 유익함을 시사.

- **인간 평가 결과**
  - 자동 평가 결과와 일치함.
  - MISC는 유창성(Fituenicy) 측면에서 다른 모델들을 크게 능가함.
    - MISC는 가장 높은 지식(Knowledge) 점수를 기록, 이는 제안된 응답이 맥락 관련 정보가 더 풍부함을 나타냄.
    - 다요인 인식 디코더가 COMET의 정신 상태 지식을 성공적으로 활용함을 추측.

- **결론**
  - MISC는 거의 모든 지표에서 최상의 성능을 보임.
  - 이는 제안된 접근 방식의 효과성과 세밀한 정신 상태 모델링 및 혼합 응답 전략 통합의 중요성을 강조함.

---

# 6 Analysis

- MISC 방법은 두 가지 혁신적인 설계를 포함함:
  - 세밀한 정신 상태를 고려함
  - 다양한 응답 전략을 통합함
  
- 추가 실험을 통해 더 많은 정보 수집
- 분석 결과는 더 나은 감정 지원 대화형 에이전트를 개발하는 데 도움이 되는 힌트를 제공함

---

# 6.1 Ablation Study

- 각 추가 파트(g, s, x)에서 가져오는 개선을 검증하기 위해 MISC에서 이 세 부분을 제거하고 성능 변화를 확인함.
- 실험 결과:
  - $g$를 제거했을 때 모든 메트릭의 점수가 극적으로 감소함.
  - 전략 주의(attention)가 응답의 의미를 안내하는 데 매우 중요하다고 추정됨.
  - 상황 $s$와 탐색자의 마지막 쿼리 $x$를 제거할 때도 점수가 감소함.
- 결론: MISC의 각 주요 부분이 효과적임을 입증함.
- 성능 평가 결과 (표 4):
  - MISC: D-1 4.41, B-2 7.31, R-L 17.91, M(%) 11.05
  - $g$ 제거: D-1 3.85, B-2 7.09, R-L 16.75, M(%) 9.85
  - $s$ 제거: D-1 4.39, B-2 6.35, R-L 17.05, M(%) 10.06
  - $x$ 제거: D-1 4.27, B-2 6.49, R-L 17.03, M(%) 10.09

---

# 6.2 Case Study

- 표 5에서는 MISC와 다른 모델들이 생성한 응답을 비교한 예시를 제시
- 비교된 모델들은 다음과 같은 다양한 문제점을 나타냄:
  - 불일치성 (inconsistency)
  - 반복 (repetition)
  - 모순 (contradiction)
- 직관적으로 MISC 모델이 가장 우수한 성능을 달성
- 그림 4에서는 MISC가 COMET 블록과 전략의 혼합 효과에 따라 응답을 조직하는 방식을 시각화하여 설명

---

# 6.3 Fine-grained Emotion Understanding

- 이전 접근 방식의 한계:
  - 대화 수준의 감정 레이블에만 의존하여 챗봇이 전략적으로 대응하지 못함.
  - 감정적인 대화의 건강한 진행을 돕지 못함.

- 해결 방안:
  - COMET을 활용하여 사용자의 정신 상태에 대한 세분화된 정보를 보완.
  - MISE (Mixed-Strategy-aware model integrating Emotion) 모델 변형을 구현하여 추가적인 감정 분류 목표 설정.

- 비교 결과:
  - MISC 모델과 MISE 변형 간의 성능 비교.
  - 세분화된 정신 상태 정보를 제공할 때 성능 지표가 향상됨.

- COMET 블록 시각화:
  - MISC 챗봇은 세분화된 감정 이해에 유익한 지식에 주목.
  - 예시에서의 xReact와 xAttr 블록이 챗봇의 응답에 긍정적인 결과를 유도.

- s (상황 정보)와 x (이전 게시물)의 상호 보완성:
  - 두 가지 정보는 감정 지원 대화에서 유용하며 중요함.

- 응답 전략의 혼합:
  - 여러 응답 전략의 혼합이 감정 지원 대화에서 중요함.
  - MISC 모델이 사용자 감정에 따라 다양한 전략(예: 자기 공감, 느낌 반영)을 효과적으로 사용하여 응답 생성.

- 혼합 전략의 이점:
  - 단일 전략보다 혼합 전략이 감정 지원 대화에서 더 효과적임.
  - 단일 전략 모델과 비교 시 혼합 전략 모델이 훨씬 더 우수한 결과 도출.

- ESC 프레임워크와의 적합성:
  - 대화에서의 전략 흐름은 특정 순서에 따라 진행됨.
  - MISC 모델이 실제 데이터의 전략 분포와 잘 유사함을 입증.

---

# 6.4 Mixed-Strategy-Aware Empathetic Responding

- **배경**
  - 기존의 대화 모델들은 대화 수준의 감정 라벨에만 의존하는 경향이 있어, 챗봇이 전략적으로 응답하도록 돕는 데 한계가 있음.
  - 이를 보완하기 위해 COMET라는 상식 지식 생성기를 활용하여 사용자의 세부적인 정신 상태 정보를 보충함.

- **MISE 모델 소개**
  - MISE는 MIxed-Strategy-aware model integrating Emotion의 약자로, 감정 분류 목표를 메인 아키텍처에 추가한 변형 모델임.
  - 결과에 따르면, 세부적으로 나뉜 정신 정보가 없는 경우 메트릭이 감소함.

- **응답 전략의 중요성**
  - **힌트 1:** 혼합 전략은 부드러운 감정 지원에 기여.
    - 모델은 사용자 상황을 이해한 후, 유사한 경험을 공유하며 감정적으로 반응함.
    - 정보 제공 등의 전략을 통해 대화를 자연스럽게 전개함.
  - **힌트 2:** 혼합 전략이 단일 전략보다 더 효과적임.
    - MISC 모델이 단일 전략 모델보다 언어적 및 의미론적 점수에서 우수함을 나타냄.
  - **힌트 3:** 혼합 전략은 ESC 프레임워크에 적합함.
    - 감정 지원 대화는 일정한 전략 흐름을 따르며, MISC는 실제 데이터와 비슷한 전략 분포를 보임.

- **모델의 성과**
  - 실험을 통해 MISC가 기존 모델들보다 우수함을 입증하며, 더 나은 지원 응답을 생성함.
  - 차후에는 동적인 방식으로 혼합 응답 전략을 학습할 계획임.

---

# 7 Conclusions

- 본 논문에서는 MISC라는 새로운 감정 지원 대화 프레임워크를 제안함.
- COMET를 도입하여 사용자의 즉각적인 정신 상태를 포착.
- 혼합 전략 인식 디코더를 개발하여 지원하는 응답을 생성.
- 광범위한 실험을 통해 모델의 우수성과 합리성을 입증.
- 향후 동적인 방식으로 혼합 응답 전략을 학습할 계획.

---

# 8 Ethical Considerations

- ESConv 데이터셋은 공개적으로 이용 가능한 잘 확립된 감정 지원 대화의 기준점임.
- 개인정보 보호: 원 제공자는 개인 식별 가능한 정보와 같은 민감한 정보를 필터링하였음 (Liu et al., 2021).
- 그러나 필터링 범위의 한계로 인해 여전히 감정적으로 유발할 수 있는 언어가 포함될 수 있음.
- 우리의 작업은 감정 지원 대화 에이전트를 구축하는 것에 중점을 두며, 자해 관련 대화와 같은 위험한 상황에서 치료나 진단을 주장하지 않음.

---

# 독자 의견

- 