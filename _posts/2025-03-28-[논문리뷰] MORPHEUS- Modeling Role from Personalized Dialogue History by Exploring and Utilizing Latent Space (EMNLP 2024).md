---
title: "[논문리뷰] MORPHEUS- Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space (EMNLP 2024)"
date: 2025-03-28 18:00:00 +0900
categories:
  - Paper Review
tags:
  - EMNLP 2024
  - Persona-based Dialogue
---

개인화된 대화 생성(PDG)은 외부 역할 데이터 의존성을 줄이고 대화 기록에서 역할 정보를 추출하여 일반화된 역할 모델링을 가능하게 합니다. MORPHEUS는 잠재 공간에서 역할을 표현해 대화 기록 기반으로 개인화된 응답을 생성하며, 실험 결과 외부 데이터 없이도 효과적인 역할 정보 추출 및 응답 생성이 가능함을 보여줍니다.

---


# 1 Introduction

- PDG (Personalized Dialogue Generation)는 사용자의 감정과 선호를 반영하여 대화에서 개별화된 응답을 생성하는 방법입니다.
- 주어진 역할 또는 페르소나에 따라 역할 기반 모델링을 목표로 하며, 사용자 개인의 요구를 충족시키는 응답을 생성합니다.
- 외부 역할 데이터를 프롬프트에 포함하고 대화와 역할 사이의 직접적인 연관성을 포착하는 방법들이 존재합니다.
- 기존 방법들은 부족한 외부 역할 지식 기반에 의존하거나, 짧은 텍스트 페르소나 설명에 의존합니다.
- 이러한 외부 데이터는 종종 부족하며 프라이버시 문제를 일으킬 수 있습니다.
- 그래서 연구자들은 대화 기록에 표시된 역할 정보를 활용하려고 합니다.
- MSP는 코퍼스에서 관련 개인화된 대화를 검색하여 토큰을 추출하고 응답 생성을 위한 프롬프트로 사용합니다.
- 그러나 여러 역할의 내재적 연관성을 간과하는 경향이 있습니다.
- CLV는 역할을 잠재 공간에서 모델링하려고 시도하고 있으며, PersonaPKL은 역할 인지 능력을 특정 역할로 전이합니다.
- 그러나 이러한 방법들은 지역적 역할 특징들 간의 연관성에만 초점을 맞추어 보지 못한 역할에 대한 개인화된 응답 생성에 어려움을 겪습니다.
- MORPHEUS는 개인화된 대화 기록에서 역할을 모델링하는 새로운 프레임워크를 도입하여 해결하려고 합니다.
- 페르소나 정보와 대화 기록 간의 관계를 설정하기 위해 페르소나 데이터를 기반으로 개인화된 응답을 생성하도록 모델을 학습시킵니다.
- 잠재 공간에서 역할을 압축적으로 표현하기 위해 페르소나 코드북을 작성하고, 명시적인 페르소나를 사용하여 코드북의 페르소나 정보를 예측합니다.
- 이를 통해 모든 역할의 표현을 일반화하는 코드북을 만들어냅니다.
- MORPHEUS는 대화 기록에서 자동으로 코드를 추론하고, 이를 사용하여 대화를 생성할 수 있습니다.
- 주요 기여 사항:
  1. 신규 역할에 대한 개인화된 대화 생성을 고려하는 체계적인 연구입니다.
  2. MORPHEUS는 잠재 공간에서 역할을 글로벌하게 모델링하여 외부 역할 데이터가 없는 상황에서도 역할 일반화 능력을 향상시킵니다.
  3. MORPHEUS를 적용하여 대화 생성에서 개인화가 크게 개선되었음을 실험을 통해 확인하였습니다.


---


# 2 Related Work

- **개인화된 대화 생성:**
  - 성격 특성을 대화 생성에 통합하는 것은 대화 시스템 개인화에 중요 (Chen et al., 2024a).
  - 명시적 퍼소나 데이터를 최대한 활용하는 방법이 중요한 연구 주제.
  - 데이터 종류:
    - 사실적 역할 설명 (Qian et al., 2018; Zheng et al., 2020; Song et al., 2021): 예) "수영을 즐깁니다."
    - 성격 특성: 예) 내성적
    - 지식 기반 (Zhang et al., 2018a; Song et al., 2019a; Wolf et al., 2019; Liu et al., 2020; Song et al., 2021): 예) 성별: 남성
    - 화법 스타일 (Lu et al., 2023): 예) 흥분된
  - 이러한 데이터는 풍부한 퍼소나 정보를 포함하여 대화에서 정보를 효율적으로 추출 가능.

- **대화 이력 기반 성격 모델링:**
  - 명시적 데이터에 비해 대화 이력은 대규모로 수집 가능하고 풍부한 정보를 제공.
  - 대화 이력에서 성격 모델링은 도전적이지만 개인정보 문제를 피하는 등 이점 제공.
  - DHAP (Ma et al., 2021), MSP (Zhong et al., 2022) 등 과거 연구에서는 전체 말뭉치에서 관련 대화를 명시적으로 검색해 성격 모델링을 강화.
  - 검색 기반 방법의 한계: 말뭉치 크기 및 비효율성.

- **잠재 공간을 활용한 연구:**
  - PersonaWAE (Chan et al., 2019): 응답자의 성격을 고려하지 않고 사용자 측에서 개인화를 모델링.
  - PersonalPKT (Han et al., 2023): 표출적 퍼소나 데이터로 두 단계 효율적 미세 조정하여 명시적 데이터 없이 목표 역할 대화 추론.
  - CLV (Tang et al., 2023): 명시적 퍼소나 설명이 특정 각도 정보를 숨긴다고 주장.
  - MORPHEUS 모델: 잠재 변수 공간에서 퍼소나 정보를 클러스터링하고 CA VE (Zhao et al., 2017)를 통해 대화 이력에서만 정보 획득.
  - 모든 퍼소나 정보를 일반화를 위해 더 큰 잠재 공간에 압축 가능, 대화 생성 시 활용.


---

# 3 Methodology



## 3.1 Overview

- 개인화된 대화 생성 문제를 명시적 인물 데이터가 마스킹된 상태로 형식화하고, 제안하는 프레임워크 개요를 제시.
- 역할 집합 $$U$$가 주어지면, 각 역할 $$u_i$$에 대해 해당 역할에 대한 텍스트 인물 데이터를 $$P$$로 제공.
- 이후, $$u_i$$와 $$u_j$$ 사이에 여러 턴의 대화 역사 $$C$$가 존재하며, 현재 턴에서 $$u_i$$의 응답을 기다림.
- 목표: 대화 역사 $$C$$에 대한 $$u_i$$에 맞는 개인화된 응답 $$R$$ 생성.
- 이전에 언급한 바와 같이, 대화 역사로부터 직접 인물 또는 역할 프로필을 모델링함으로써, 추론 시 외부 데이터 $$P_{ui}$$가 필요하지 않음.
- 대신 $$C$$ 내에 암시된 인물 정보 $$P$$에 기반하여 활용:

  $$P(R|C) = \sum_P P(R|C, P) \cdot P(P|C).$$

- 제안된 프레임워크는 세 가지 주요 훈련 단계로 나뉨:
  1. **Role Awareness**  
     - 일반적인 디코더는 광범위한 코퍼스에서 훈련되어, 대화 및 인물 정보에 대한 특정 인식 능력이 부족.
     - 이 단계의 목표는 모델을 미세 조정하여 인물 및 대화와 인물 간 관계에 대한 인식을 향상.
  2. **Persona Codebook(PC) Initialization**  
     - 모델이 대화 역사 및 PC로부터 직접 역할을 모델링할 것이므로, 기존 코드북은 인물들의 인코딩 표현과 맞지 않을 수 있음.
     - 다양한 초기화 방법을 탐색했으며, 특정 인물 인코딩 표현에서 일반화된 PC가 임의 초기화보다 효과적으로 뛰어남을 발견. 
  3. **Joint Training**  
     - 모델이 대화 역사를 입력으로 받아, 대화 내의 암시된 인물 정보 기반으로 PC에서 PC 표현 샘플링을 통해 개인화된 응답을 생성.


---


## 3.2 Role Awareness

- 디코더 전용 아키텍처 모델에서는 페르소나와 대화 기록을 연결하고, 자동회귀 방식으로 응답을 생성하는 것이 일반적입니다.
- 역할 데이터의 숨겨진 표현도 초기 모델에서 과거 키와 값의 형태로 직접 연결할 수 있습니다.
- Han et al. (2023)의 연구에 따르면, 대화 기록을 기반으로 하여, 역할 데이터의 숨겨진 상태 형태로 조건화된 응답 생성을 강제하면, 페르소나 정보와 대화 기록의 공동 지각 능력이 향상될 수 있습니다.
- 이러한 접근법을 따라, 역할에 대한 페르소나 세그먼트를 인코딩하여 '인코딩 표현 $$p_i$$'이라고 하고, 키와 값만 모델의 최전방에 연결합니다.
- 이후 모델을 미세 조정합니다: $$LR = l\sum j \log P(\hat{R_i}|P,C,R<j).$$


---


## 3.3 Initialization of the Persona Codebook

- **Persona Codebook(PC) 정의**: $$e \in \mathbb{R}^{N \times d}$$, 여기서 $$N$$은 잠재 공간의 크기, $$d$$는 숨겨진 크기.
- **PC 초기화 중요성**: 랜덤 초기화는 PC의 향상을 어렵게 하며, 공동 학습 실패를 초래할 수 있음. 잘 초기화된 PC는 3.4절의 공동 학습을 원활히 함.

### 초기화 방법
1. **순차 초기화**: 현재 배치의 페르소나 데이터 인코딩 $$p_i$$로 초기화되지 않은 PC 부분 채움.
2. **평균 초기화**: 배치의 $$p_i$$에 대해 추가 평균 연산 수행.
3. **EM 초기화**: 개별적으로 작동, 페르소나 정보의 $$p_i$$가 여러 정규 분포에서 샘플링되었다고 가정.

#### EM 알고리즘 단계
- **Expectation 단계**:
  - $$N$$개의 정규 분포 설정, 전체 페르소나 데이터 인코딩 $$|D|$$ 사용.
  - 각 인코딩 $$p_i$$에 대해 후행 확률 $$P(z_i = k|p_i)$$ 계산:
    $$P(z_i = k|p_i) = \frac{P(p_i|z_i = k)P(z_i = k)}{\sum^N_{j=1} P(p_i|z_i = j)P(z_i = j)}$$

- **Maximization 단계**:
  - 파라미터 ($$\mu_k$$와 $$\sigma^2_k$$) 업데이트:
    $$\mu_k = \frac{\sum_{i=1}^{|D|} P(z_i = k|p_i)p_i}{\sum_{i=1}^{|D|} P(z_i = k|p_i)}$$
    $$\sigma^2_k = \frac{\sum_{i=1}^{|D|} P(z_i = k|p_i)(p_i - \mu_k)^2}{\sum_{i=1}^{|D|} P(z_i = k|p_i)}$$

  - 분모는 모든 인코딩 $$p_i$$가 분포 $$k$$에 속하는 가중치의 합을 의미, 각 샘플의 코드 $$z$$ 속성에 대한 불확실성을 고려한 "유효" 샘플 크기.

- **결과**: 이 방법으로 얻은 평균 $$\mu_k$$를 $$z_k$$의 초기값 $$e_k$$로 사용.


---


## 3.4 Joint Training

- 모델은 대화 이력에 포함된 암묵적인 페르소나 정보를 기반으로 코드를 예측하는 학습을 시작하며, 페르소나 코드북(PC)에서 PC 표현 $$e_k$$를 추출하여 개인화된 응답을 생성함.
- 공동 학습 체계는 두 개의 동시 단계로 나뉨: 
  1. 코드 인덱스 예측 
  2. PC 훈련

- PC의 훈련 단계에서 VQ-VAE 방법(van den Oord et al., 2017)을 따라, 페르소나의 인코딩 표현 $$p_i$$와 가장 근접한 $$e_k$$를 식별함: 
  $$k= \arg \min_k \|p_i − e_k\|^2$$ . (8)

- PC 표현의 근접 최적화를 위해 다음 손실 함수 최소화:
  $$L_V = \|sg[p_i] − e_k\|^2_2 + \beta\|sg[e_k] − p_i\|^2_2$$ , (9)
  - 여기에서 $$sg$$는 그래디언트 중단 연산자를 나타내어, 순방향 계산 중에는 항등 연산이나 부분 도함수가 0이 되므로 피연산자를 업데이트되지 않는 상수로 만듦.
  - 인코더는 마지막 손실 항을 최적화하고 임베딩은 첫 번째 손실 항을 최적화함.

- 알고리즘은 $$\beta$$에 민감하며, 이는 인코더의 매개변수 양이 중간 프로세스보다 상당히 크기 때문임.
- 모든 실험에서는 $$\beta = 0.05$$를 사용함.

- 이후 인코딩된 표현은 키와 값으로서 자가 회귀적 대화 생성에 참여하며, 손실 함수는 다음과 같음:
  $$p_G = \text{concat}(p_1,p_2,...,p_M)$$ , (10)
  $$L_G = − \sum_l {\log P(R_j|p_G,C,R_{<j})}$$ , (11)

- 코드 인덱스 예측에서, $$p_i$$에 가장 근접한 코드 인덱스 $$k$$를 레이블로 사용함.
- 대화 이력의 은닉 상태 $$c$$가 입력으로, 멀티레이어 MLP를 분류기로 사용:
  $$c= \text{Decoder}(C)$$ , (12)
  $$L_D = -\log P(y= k|c)$$ , (13)

- PC가 충분한 다양성과 일반화 능력을 갖추도록, 코드북 내 각각의 잠재 변수와 관련된 대조 학습(Gao et al., 2021) 손실을 도입:
  $$L_C = -\log \frac{e^{\text{sim}(p_i,e_k)/\tau}}{\sum_{j=1}^N e^{\text{sim}(p_i,e_j)/\tau}}$$ , (14)
  - 여기서 $$\tau$$는 온도 하이퍼파라미터이고 $$\text{sim}(p_i,e_i)$$는 코사인 유사도를 나타냄.

- 데이터셋 통계:
  - ConvAI2: Train 43,410, Valid 4,213, Test 2,138
  - Baidu PersonaChat: Train 376,016, Valid 19,923, Test 4,456


---

# 4 Experiments



## 4.1 Datasets

- ConvAI2 (Dinan et al., 2019)는 특정 역할 프로필에서 파생된 개인화된 대화에 중점을 둔 영어 데이터셋입니다.
- 이 데이터셋은 원래의 PersonaChat(Zhang et al., 2018b)을 기반으로 하며, 품질과 관련성을 높이기 위해 크라우드 워커에 의해 세심하게 큐레이션되었습니다.
- Baidu PersonaChat1은 ConvAI2와 구조적으로 유사한 중국어 데이터셋으로, 개인화를 강조하고 개인 정보를 활용하여 흥미로운 대화를 이끌어냅니다.
- 표 1에는 두 데이터셋에 대한 통계가 나와 있습니다.
- 우리는 훈련 단계에서만 이러한 퍼소나 설명을 사용합니다.
- (Tang et al., 2023)에서 큐레이션한 데이터셋을 사용하되, 훈련, 검증, 테스트 데이터에 역할 누출이 없도록 보장합니다.


---


## 4.2 Baselines

- 개인화된 대화 생성 모델 연구는 두 가지 주요 접근으로 구분:
  - **명시적 검색 기반 접근:** 
    - 미리 정의된 또는 동적으로 생성된 반응 풀에서 현재 대화 기록에 따라 가장 관련 있는 반응이나 토큰을 검색.
  - **암시적 모델링 기반 접근:** 
    - 명시적으로 정의된 반응 없이 개인화나 역할을 모델 내부에서 직접 학습 및 생성.

- **비개인화 대화 생성 모델의 기준선:**
  - **Seq2Seq 모델:**
    - 주목 메커니즘을 강화한 모델로, 문맥 집중 능력을 가진 중요한 시퀀스 모델링.
  - **사전 훈련된 GPT-2:**
    - 대화 전용 데이터셋으로 미세 조정하여 대화 생성의 초석.

- **명시적 검색 기반 접근:**
  - **DHAP:** 
    - 사용자의 과거 상호작용 데이터를 활용하여 질의 중심의 사용자 프로필 동적으로 생성.
  - **MSP:**
    - 유사한 프로필을 가진 사용자로부터 대화를 식별하고, 토큰 정제를 통해 훈련하여 개인화된 대화 생성의 성능 향상.

- **암시적 모델링 기반 접근:**
  - **PersonaPKT:**
    - 최소한의 추가 매개변수로 페르소나 특성을 임베딩하고, 지속적 벡터를 통해 두 단계에 걸쳐 역할을 모델링.
  - **CLV:**
    - 잠재 공간에서 페르소나 정보를 분류하여 대화 기록을 통한 개인화된 응답 생성 강화.

- **평가 결과 요약:**
  - 표 2는 두 데이터셋에 대한 자동 평가 결과를 정리하고, 최고 성능을 굵게 표시.


---


## 4.3 Evaluation Metrics

- **평가 방법**: 자동 평가와 인간 평가를 사용하여 비교.
  
- **자동 평가**:
  - **범주**: 대화의 다양성, 일관성, 일치를 평가.
  
  - **(1) 일치성**:
    - **BLEU-1/2** 및 **ROUGE-L**: 생성된 응답과 사실 응답 사이의 유사성을 측정하는 전통적인 단어 중복 기반 지표.
    - **BLEU-3/4**: 지나치게 엄격한 요구사항으로 인해 대화의 일치를 반영하지 못해 제외.
  
  - **(2) 다양성**:
    - **Dist-1/2**: 유니그램 또는 바이그램의 고유성을 평가하여 텍스트의 다양성 측정.
    - **self-BLEU (sBLEU)**: 생성된 응답 간의 유사성을 통해 다양성을 평가.
  
  - **(3) 일관성**:
    - **Con.Score** 및 **Coh-Con.Score**: 응답과 페르소나 정보 간의 일관성 평가.
    - **P-Co (Persona Cosine Comparison)**: IDF-weighted words 중복 기반 지표로 모델 응답과 페르소나 간의 의미적 유사성 평가.
  
- **인간 평가**:
  - 자동 평가 기준의 불확실성을 고려하여 인간 평가 수행.
  - 100개의 데이터 포인트 (히스토리, 응답, 역할 데이터) 추출.
  - 세 명의 잘 교육된 평가자가 다양한 모델의 응답을 0에서 1 사이의 점수로 순위 매김.
  - 평가 기준: 가독성, 다양성, 일관성, 일치성 평가. 자세한 기준은 부록 A.2의 그림 4에 명시.
  - **Table 3**: ConvAI2에 대한 인간 평가 결과
    - **DHAP**: 가독성 0.71, 다양성 0.72, 일관성 0.69, 일치성 0.71
    - **MSP**: 가독성 0.70, 다양성 0.73, 일관성 0.69, 일치성 0.80
    - **PersonaPKT**: 가독성 0.63, 다양성 0.65, 일관성 0.61, 일치성 0.69
    - **CLV**: 가독성 0.79, 다양성 0.76, 일관성 0.73, 일치성 0.76
    - **MORPHEUS (Ours)**: 가독성 0.82, 다양성 0.84, 일관성 0.77, 일치성 0.85
    - **Ground-Truth**: 가독성 0.92, 다양성 0.89, 일관성 0.93, 일치성 0.91


---


## 4.4 Experimental Results

- **자동 평가**
  - 표 2는 중국어 및 영어 데이터세트에서 모든 모델의 성능을 세 개의 랜덤 시드를 사용하여 평균값으로 나타냄.
  - **일관성**:
    - BLEU-1, Rouge-L 등과 같은 커버리지 지표나 Coh-Con.Score와 같은 학습 지표에서 MORPHEUS의 성능이 두드러짐.
  - **다양성**:
    - MORPHEUS는 다른 모델들에 비해 다양한 응답을 생성하며, CLV(Tang et al., 2023)처럼 성능 향상을 위해 다양성을 희생하는 문제를 극복함.
    - 이는 모델링 목표에 더 가까워짐을 나타내며, 동일한 의미의 응답이 수렴함.
    - 자세한 분석은 5.1절에서 설명.
  - **일관성**:
    - Con.Score는 페르소나 정보를 통합하여 응답 생성에 반영하는 능력을 가리키며, 특히 외부 페르소나 데이터가 없는 시나리오에서 MORPHEUS의 우수성이 두드러짐.
  - 실험 결과는 제안한 모델이 모든 기준 모델보다 더 개인화된 응답을 생성할 수 있음을 시사.

- **인간 평가**
  - ConvAI2의 인간 평가 결과는 표 3에 제시됨.
  - Fleiss Kappa 계수를 세 명의 평가자 간에 계산하여, 새로운 접근 방식을 통해 순서 등급을 이산적 카테고리로 개념화함.
  - Kappa 값은 0.65로 평가자 간 상당한 합의를 나타냄.
  - 전반적으로 인간 평가 결과는 자동 평가 결과와 일치하며, MORPHEUS의 개인화된 대화 생성 및 기본 가독성의 강점을 보여줌.

- **모델 성능 (실험 결과 요약)**
  - BLEU-1, Dist-1/2, Coh-Con.Score, P-Co의 다양한 조건별 결과.
  - MORPHEUS(Ours): 고유의 성능 수치 제시.
  - w/oPC, w/oCL, w/oRA, i/wRandom, i/wSe., i/wMean 등 다양한 변형 실험 결과 제시.
- **추가 실험**
  - ConvAI2 데이터셋에서 N값의 변화에 따른 실험 (세부 결과는 그래프에서 확인).
  - 가시성을 위해 BLEU-1, ROUGE-L, P-Co는 3배 확대, Dist-1은 10배 확대하여 시각화.


---

# 5 Further Analysis



## 5.1 Ablation Study

- MORPHEUS 모델의 특정 모듈을 제거하여 성능을 분석.
- **모델의 핵심 메커니즘**: 페르소나 코드북(PC)을 제거하면, 모델은 기본 GPT-2로 회귀하며, 성능은 GPT-2와 유사.
- **대조학습 제거**: VQ-V AE 손실 함수는 유지하면서 대조학습만 제거 시, 특히 다양성에서 성능 저하 발생.
  - 이는 인코딩 표현을 PC 표현에 가깝게 하기 위한 대조학습의 효과를 강조.
- **PC 초기화 방법**: EM(우리 기법)이 무작위 초기화, 순차 채우기, 평균 채우기보다 우수.
  - 전역적인 역할 관점이 PC를 최적으로 조정함을 시사.
- **역할 인지 훈련 제거**: 일부 지표에서 성능 저하 발생.
  - 이는 7670 역할 데이터와의 텍스트 대화를 통한 역할 조정이 필수적임을 나타냄.


---


## 5.2 Effects of size of the persona codebook

- MORPHEUS에서 페르소나 정보는 페르소나 코드북 (PC)에 압축됨.
- PC의 크기 $$N$$은 성능에 큰 영향을 미침 (그림 3 참조).
- $$N$$이 작을 때:
  - PC에 압축된 정보는 특정 역할보다 개인화된 대화 생성에 관련된 일반적 정보와 더 밀접하게 연결됨.
- $$N$$이 너무 클 때:
  - 정보 압축의 효과가 감소할 수 있음.
  - 이는 명확하지 않은 페르소나 수가 증가하면서 분산되고, 잡음이 증가하여 PC의 최적화가 어려워짐.
- 최적의 성능은 $$N$$이 100일 때 관찰됨.


---


## 5.3 PEFT

- PC 표현 벡터를 모델의 전면에 결합하는 접근 방식은 프롬프트 튜닝 및 p-튜닝과 유사.
- 본 기술은 효율적인 미세 조정 방법으로 간주.
- 텍스트 생성 책임이 있는 디코더(LLaMA-2)의 파라미터는 고정하고, 훈련 중 PC 내의 파라미터만 최적화.
- LLaMA-2 외에 Mistral-7B-v0.1 모델로도 실험 진행.
- Mistral의 성능 결과는 제안된 MORPHEUS의 견고성을 추가적으로 입증.
- 성능 비교:
  - BLEU, ROUGE, Distinct 메트릭에서 Mistral의 아키텍처가 LLaMA보다 대화 개인화의 일부 영역에서 성능 향상.
- 그러나 LLM에 페르소나 정보를 통합하는 것은 여전히 중요한 과제.
- 최신 모델을 사용하더라도 진정으로 개인화되고 맥락에 맞는 대화를 생성하는 데는 복잡성이 존재.


---


## 5.4 Case Study

- MORPHEUS는 대화 히스토리와 역할을 효과적으로 정렬하여 다른 베이스라인보다 잘 수행합니다.
- **사례 1**: 
  - 질문자가 여행 중일 때, MSP와 CLV는 여행 관련 내용을 언급하지만, 대화 히스토리에서 응답자의 취미를 유추하지 못함.
  - MORPHEUS는 응답자가 외출 준비하고 있음을 정확히 파악하고, "등산을 즐김"이라는 역할 설정에 맞는 응답 생성.
- **사례 2**: 
  - 직업에 대해 질문할 때, MSP와 CLV는 히스토리에 언급된 응답자의 나이를 놓침.
  - MORPHEUS는 히스토리와 일관되며 실제 응답에 가까운 답변 생성.
- **사례 3**: 
  - 혼란스러운 히스토리 때문에 MSP와 CLV는 관련성 있는 응답 생성에 어려움.
  - MORPHEUS는 보다 역할에 가까운 응답을 제공.
- 테스트 세트에서 이전에 보지 못한 역할에 직면하고 외부 역할 데이터 없이, MSP와 CLV는 혼란스러운 히스토리에 쉽게 현혹되어 일관된 응답을 생성하지 못함.
- MORPHEUS는 대화 히스토리를 정확히 활용하여 역할에 대한 합리적인 추론을 수행.


---


# 6 Conclusion

- 이 작업에서는 개인화된 응답 생성을 위한 MORPHEUS 프레임워크를 소개합니다.
- 기존의 노력과 달리, 역할의 대화 기록에서 역할을 일반화된 방식으로 모델링합니다.
- 다단계 훈련 과정을 통해 역할을 대화와 정렬하여 응답 생성의 개인화를 향상시킵니다.
- 실험 결과, 새로운 역할을 마주하더라도 모델이 매우 개인화된 응답을 생성할 수 있음을 보여줍니다.
- 이는 인물 정보의 효율적 활용과 동시에 프라이버시 침해 위험을 줄여줍니다.


---


# Limitations

- **언어 확장성**: MORPHEUS는 중국어와 영어 데이터셋에서 테스트되었으나, 다른 언어와 방언에 대한 적응성은 향후 연구가 필요함.
- **페르소나 코드북 개선**: 현재의 페르소나 코드북은 역할을 간결하게 표현하지만, 표현 능력의 향상을 위한 추가적인 개선 가능성 존재.
- **사회적 영향 고려 부족**: 연구의 초점이 MORPHEUS의 기술적 개발과 응용에 맞춰져 있어, PDG 기술의 사회적 영향에 대한 심도 있는 분석은 이루어지지 않음.
- **윤리적 고려**: 개인화된 대화 생성 기술의 개발 및 응용에 내재하는 윤리적 고려 사항을 인정하고 있음. MORPHEUS는 외부 역할 데이터를 사용하지 않고 대화 생성을 개인화하여 프라이버시 문제를 완화하려고 하지만, 잘못된 정보 생성 가능성을 염두에 두어야 함.
- **윤리적 프레임워크**: 개인화된 대화 기술이 더욱 발전하고 널리 보급됨에 따라, 오용을 방지하기 위한 강력한 윤리적 프레임워크 개발이 중요해질 것임.
