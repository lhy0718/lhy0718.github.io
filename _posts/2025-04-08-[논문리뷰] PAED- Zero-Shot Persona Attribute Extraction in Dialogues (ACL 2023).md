---
title: "[논문리뷰] PAED: Zero-Shot Persona Attribute Extraction in Dialogues (ACL 2023)"
date: 2025-04-08 00:00:00 +0900
categories:
  - Paper Review
tags:
  - ACL 2023
  - Persona-based Dialogue
---

퍼소나 속성 추출은 개인화된 인간-컴퓨터 상호작용에 중요하며, 대화는 퍼소나 정보를 전달하는 주요 매체입니다. 본 연구는 신뢰할 수 있는 텍스트-레이블 매칭 기준을 활용하여 고품질 데이터를 생성하고, 대조 학습 및 생성 기반 모델을 통해 제로샷 퍼소나 속성 추출을 개선합니다. 결과적으로 우리의 모델은 최첨단 기준과 비교해 뛰어난 정확도를 보여주며, 샘플링 전략은 다른 방법들보다 큰 성과를 나타냅니다.

---

# 1 Introduction

- **대화에 대한 페르소나 속성 추출 (PAED)**: 
  - 페르소나 기반 대화 시스템에 중요한 작업.
  - 대화에서 페르소나 속성 정보를 추출하여 개인화된 응답 생성에 활용.

- **이전 연구**:
  - PAED를 문장 수준 또는 발화 수준 분류 작업으로 정의.
  - 텍스트 내 페르소나 정보 포함 여부를 분류함.

- **현재 문제점**:
  - 발견된 텍스트는 구조적이지 않아 하위 대화 시스템에서 유용성 낮음.
  - 예: 동일 페르소나 속성에 대한 서로 다른 표현과 관련 없는 맥락.

- **PAED의 새로운 정의**:
  - 삼중항 추출 작업으로 정의.
  - 발화에서 주어, 객체, 관계를 추출해야 함.
  - 추출된 속성은 $$(s, r, o)$$ 형식의 삼중항으로 표현되며, $$r$$은 주어 $$s$$와 객체 $$o$$ 사이의 페르소나 속성 유형을 나타냄.

- **기존 RTE와의 차별점**:
  - 기존 관계 삼중항 추출 작업은 문서에서 사실이나 지식을 설명하는 텍스트 기반.
  - 대화에서는 다양한 관계가 존재하여 샘플 문제 발생.

- **데이터셋 문제점**:
  - Wu et al. (2020)가 제안한 데이터셋은 레이블이 잘 정의되지 않음.
  - 부정적인 표현 조합이 한 종류의 관계로 묶여 오류 발생.

- **새로운 데이터셋 PersonaExt 개발**:
  - Dialogue NLI와 PersonaChat 데이터셋에서 데이터 수집.
  - 이전 데이터셋의 1896개 삼중항 레이블을 수동으로 수정하여 구체성 향상.
  - BERT 및 TF-IDF를 활용하여 신뢰성 높은 레이블 할당.

- **평가 결과**:
  - PersonaExt가 레이블 구체성과 주석 정확도에서 개선된 성과를 보임.

- **GZSL을 통한 PAED 정의**:
  - 훈련 발화가 모든 관계 유형을 포함하지 않을 수 있어 GZSL 태스크로 정의.
  - 어려운 샘플 문제가 더욱 심각해짐.

- **새로운 프레임워크 제안**:
  - 제너레이션 기반 프레임워크와 하드 네거티브 샘플링(HNS) 전략 도입.
  - Meta-V AE 샘플러와 대조적 구조 제약(CSC)을 결합하여 모델 성능 향상.

- **주요 기여**:
  1. 1,896개의 재주석된 삼중항을 포함하는 PAED 데이터셋 PersonaExt 개발.
  2. 제로샷 PAED를 위한 제너레이션 기반 프레임워크 제안.
  3. 제로샷 PAED 및 부정 샘플링에서 강력한 기준선보다 우수한 성과 유지.

---

# 2.1 Persona Extraction

- **초기 정의**: 페르소나 추출은 사용자의 속성을 예측하는 분류 작업으로 시작됨
  - 성별 (Ciot et al., 2013)
  - 나이 (Alekseev and Nikolenko, 2016)
  - 의견 (Li et al., 2023)
  - 직업 (Preo¸ tiuc-Pietro et al., 2015)
  - 선호도 (Cambria et al., 2022)

- **언어 추론으로의 재정의**: Welleck et al. (2020)은 발화와 페르소나 설명 간의 관계를 학습하여 자연어 추론 작업으로 정의

- **생성 작업으로의 재정의**: 
  - Wu et al. (2020)은 페르소나 추출을 생성 작업으로 형식화
  - 두 단계 추출기를 통해 대화에서 구조적이고 사용하기 쉬운 사용자 속성 추출
  - 그러나 이 추출기는 제로샷 설정을 위해 설계되지 않음

- **수식 설명 예시**: 
  - 예를 들어, 페르소나 속성 추출을 위해 $$P(X, Y)$$의 관계를 학습할 때, $$X$$는 발화, $$Y$$는 페르소나 속성을 나타냄

---

# 2.2 Relation Triplet Extraction

- RTE(관계 삼중 항 추출)는 관계와 엔티티를 동시에 추출하는 것으로 정의됨 (He et al., 2023; Li and Ji, 2014).
- 많은 기존 모델(Gupta et al., 2016; Zhang et al., 2017; Geng et al., 2021)은 이전에 보지 못한 관계에 일반화할 수 없음.
- 이는 PAED(프롬프트 기반 대화 엔티티 추출)에서 피할 수 없는 문제임.
- Chia et al. (2022)는 제로샷(zero-shot) 환경에서 RTE를 위한 프레임워크 RelationPrompt를 제안함.
- 하지만, 기존의 모델은 문서에 맞춰져 있어 PAED에 직접 사용할 수 없음.
- 대화에서는 주체와 객체가 여러 가능한 관계를 가질 수 있어 더 어려운 샘플이 존재함.
- 제로샷 PAED를 위해 이러한 어려운 샘플을 처리해야 함.

---

# 2.3 Hard Negative Sampling

- 부정 샘플링은 대조 학습(Contrastive Learning)과 심층 메트릭 학습(Deep Metric Learning)의 핵심 요소로 입증됨.
  - 참고 문헌: Robinson et al., 2020; Du et al., 2021; Suh et al., 2019

- 많은 관계 추출 방법(Relation Extraction, RTE)들이 견고한 부정 샘플링 전략의 혜택을 받음.
  - 참고 문헌: Qin et al., 2018; Yuan et al., 2021b; Eberts and Ulges, 2020; Guo et al., 2022; Chen et al., 2022

- 하드 부정 샘플은 피처 공간에서 긍정 샘플과 가까워서 성능에 중요한 영향을 미침.

- 컴퓨터 비전 관련 연구와는 달리, RTE 및 제로샷(zero-shot) 환경에서는 HNS에 대한 연구가 드뭄.
  - 참고 문헌: Shrivastava et al., 2016; Liao and Shao, 2022

- 기존의 공동 RTE 샘플러는 하드 샘플을 위한 설계가 아님.
  - 참고 문헌: Eberts and Ulges, 2020; Yuan et al., 2021a; Zeng et al., 2021

- 본 연구에서는 VAE(변분 오토인코더)를 활용한 HNS 전략을 개발하여 하드 부정 샘플을 선택하고, 추출기의 표현 능력을 향상시킴.

---

# 3 PersonaExt Construction

- **데이터셋 개발**: PersonaExt 데이터셋은 PAED를 위해 개발됨.
  - 다중 회화 데이터셋에서 구성: 예) PersonaChat, Dialogue NLI
  - PersonaChat는 개인 프로필이 포함된 대화 말뭉치로 사용됨.

- **PersonaChat 특징**:
  - 2명의 크라우드 작업자가 사전 정의된 페르소나에 기반하여 대화.
  - 페르소나는 식품 선호, 직업 상태, 교육 등으로 구성됨.
  - 각 페르소나에는 4~6개의 문장이 포함됨.
  - 총 1,155개의 페르소나와 10,907개의 대화가 포함됨.

- **Dialogue NLI 활용**:
  - 대화 발화(u)와 PersonaChat의 페르소나 문장(p)에 대해 (s, r, o) 형식의 트리플로 주석 추가.
  - (p, u) 및 (p, p) 쌍에 대해 함의(entailment), 중립(neutral), 모순(contradiction) 레이블 생성.

- **트리플 레이블 예시**:
  - "I adopted a cat"와 "I have a cat named Alfred"는 트리플 (I, have_pet, cat)로 레이블됨 → 함의.
  - 서로 다른 트리플 가진 문장들은 중립 또는 모순으로 간주됨.

- **레이블 문제**:
  - Dialogue NLI의 많은 발화는 트리플 레이블이 없음.
  - Wu et al. (2020)은 레이블 커버리지를 개선하는 그리디 방법 사용.

- **자동 레이블 할당 전략**:
  - 페르소나 문장(p) 또는 발화(ui)에 트리플 레이블을 할당할 때, 함의 관계가 예측될 경우 사용.
  - 예측 모델: BERT 또는 TF-IDF 분류기.

- **라벨 품질 개선**:
  - Dialogue NLI의 트리플과 Wu et al. (2020)의 데이터셋은 불확실성 및 일관성 문제를 가짐.
  - PersonaExt 구성에서 자동 교차 할당 전략과 수동 속성 트리플 레이블 수정을 사용하여 레이블 품질 향상.

---

# 3.1 Automatic Intersection Assignment

- Greedy 선택 방법(Wu et al., 2020)에서 주어진 모든 트리플 레이블을 수용하지 않음.
- 보수적으로, por ui의 트리플 레이블을 발화 uj에 할당:
  - 조건: BERT와 TF-IDF가 (p, uj) 또는 (ui, uj)가 포함 관계에 있다고 나타내야 함.
- 이 변경 사항은 레이블 신뢰성을 크게 향상시킴.
- 그러나 이 방법은 일부 레이블을 놓칠 가능성이 있음.
- 신뢰할 수 있는 인물 정보를 추출하는 것이 현실적인 응용에 더 적합하다고 봄:
  - 대화 시스템은 잘못된 정보 사용을 피해야 함.
  - 일부 인물 정보는 보수적으로 무시될 수 있음.

---

# 3.2 Attribute Triplet Label Correction

- **재주석 필요성**
  - Dialogue NLI의 관계 유형 및 엔티티에 대한 재주석 필요.
  - 일관성과 구체성 문제 존재.

- **일관성 (Consistency)**
  - 일부 퍼소나 문장 내용이 발화에 나타나지 않음.
  - 예시: 퍼소나 문장 "I have 1 cat and I dislike dogs"에서 triplet (I, dislike, dogs)는 발화 "I usually play with my cat"에 나타나지 않음.
  - 결과적으로, Dialogue NLI에서 과도한 주석됨.

- **구체성 (Specificity)**
  - 관계 유형은 다른 유형과 구별될 수 있도록 구체적이어야 함.
  - 대부분의 부정어(예: never, don’t have)는 Dialogue NLI에서 'other'로 분류됨.
  - 우리는 이들을 never_do와 have_no로 분류할 것을 예상.

- **제안된 방법론**
  - **1단계:** 부정어가 있는 퍼소나 문장을 수집하고 수동으로 재주석.
    - 1,896개의 문장이 수정됨.
  - **2단계:** § 3.1의 방법에 따라 각 발화에 triplet 할당.
  - **3단계:** SnowballStemmer2를 사용해 과도한 주석(중복된 숫자, 근거 없는 부사, 형용사 등)을 제거하여 일관성 유지.
    - 총 6,357개의 문장이 처리됨.

- **주석 프로세스**
  - 퍼소나 문장 1,896개에 대해 전문가를 초청하여 수동 주석 진행.
  - 일관성을 보장하기 위해 단일 주석자를 초대함.
  - 주석자 간 카파값: 0.72.
  - 82.8%의 주석이 두 부주석자에 의해 지지됨.

- **신규 생성된 triplet 평가**
  - 두 영어 사용 대학원생이 무작위로 선택된 150개의 발화를 점수화.
  - 점수 기준: 일관성 (cns.) 및 구체성 (spec.) 
  - 평균 점수 결과:
    - PersonaExt가 Wu et al. (2020) 데이터셋을 크게 발전시킴.

---

# 4 Generalized Zero-Shot PAED

- 제안된 프레임워크는 일반화된 제로샷 학습(GZSL) 설정에서 PAED를 위한 것임.
- 프레임워크는 두 가지 주요 구성 요소로 이루어져 있음:
  - **Persona Attribute Generator (PAG)**:
    - 개인 특성을 포함한 대화 발화를 생성하도록 훈련됨.
  - **Persona Attribute Extractor (PAE)**:
    - 합성 데이터에서 훈련되며, 보이지 않는 대상 데이터의 특성 삼중항을 추출함.
    - PAE는 사전 훈련된 언어 모델(PLM)을 기반으로 하며, 제안된 MetaV AE 샘플러와 CSC 손실로 강화됨.

---

# 4.1 Task Definition

- PAED 데이터셋은 $$D = (U, Y)$$로 표현됨.
  - $$U$$: 입력 대화 발화 세트
  - $$Y$$: 페르소나 속성 세트
- 속성 삼중항은 $$y = (s, r, o) \in Y$$로 정의됨.
  - $$s$$: 주체 (subject)
  - $$r$$: 관계 유형 (relation type)
  - $$o$$: 객체 (object)
- 일반화된 제로샷 PAED의 목표:
  - 모델을 보이는 데이터 $$D_s$$로 학습하고 보이지 않는 테스트 데이터 $$D_t$$에 일반화.
- 학습 중:
  - $$D_s$$와 테스트 관계 $$R_t$$가 사용 가능 (Verma et al., 2018).
- 테스트 시:
  - 훈련된 모델의 관계 탐색 공간은 $$R_s \cup R_t$$로 구성되며, 생성 기반 PAE의 특성으로 인해 더욱 확장됨.
  - $$R_s \cap R_t = \emptyset$$.
- 테스트 발화는 훈련 관계 $$r_s$$ 또는 테스트 관계 $$r_t$$에 할당 가능.
  - 조건: $$r_s \in R_s$$, $$r_t \in R_t$$ (Xian et al., 2018).

---

# 4.2 Persona Attribute Generator

- **프롬프트 튜닝(Prompt tuning)**:
  - 제로샷 학습에서 **PLMs(Pre-trained Language Models)**의 일반화 향상 입증 (Lester et al., 2021)
  - 사전 훈련 작업과 하류 작업 간의 간극을 메꿈 (Mao et al., 2023)

- **PAG(페르소나 속성 생성기)**:
  - 훈련 데이터 $$D_s$$에서 훈련 후, 관계 $$r_t$$를 사용하여 합성 데이터 $$D_{syn}$$ 생성
  - Verma et al. (2018)의 연구 방법 따름

- **테스트 단계**:
  - 프롬프트 “RELATION : r” 제공
  - PAG는 “CONTEXT : u, SUBJECT : s, OBJECT : o” 형태의 구조적 출력 생성

- **훈련 방법**:
  - 인과 언어 모델링 목표에 따라 훈련
  - 다음 단어 예측: 
    $$p(x_i \vert x_{<i}; t_p) = PAG(x_{<i})$$
    - 여기서 $$x_i$$는 입력 토큰 “RELATION : r, CONTEXT : u, SUBJECT : s, OBJECT : o”의 i번째 토큰
  - 손실 함수:
    $$L_g = \sum_{i=1}^{n} \log p(x_i \vert x_{<i}; t_p)$$
  - **온도(t_p)** 조절:
    - 다양성 조정 (Hinton et al., 2015)

---

# 4.3 Persona Attribute Extractor

- PAE(퍼소나 속성 추출기)는 PLM(사전 훈련 언어 모델)을 기반으로 하여 훈련 데이터 $$D_s$$에서 파인튜닝을 수행함.
- 이후, PAG에서 생성된 합성 샘플 $$D_{syn}$$에 대해 추출기를 추가로 조정함.
- PAE는 seq-to-seq 목표를 가지고 훈련됨 (Lewis et al., 2020).
- 프롬프트 “CONTEXT : u”를 주면, 추출기는 구조화된 출력을 예측함:
  - “SUBJECT : s, OBJECT : o, RELATION : r”.
  
- 예시: 
  - 입력: “I enjoy playing with cats” 
  - 출력: $$(I, like\_animal, cats)$$.

- PAE는 대화 발화에서의 관계 유형 구별이 어려워짐:
  - 예: "like"를 "hate"로 변경하는 것으로 의미가 완전히 반대가 될 수 있음.
  
- 이를 해결하기 위해 CSC(대조 구조 제약)와 메타-VAE 샘플러를 제안하고, 각각 § 4.5 및 § 4.4에서 소개됨.

---

# 4.4 Meta-V AE Sampler

- 모델의 전제는 각 관계 유형에 대해 Meta-V AE가 해당 관계를 가진 모든 발화의 분포를 캡처한다는 것임.
- 발화 $$u_i$$와 $$u_j$$가 각각 관계 $$r_i$$와 $$r_j$$를 가지며, $$r_i$$와 $$r_j$$의 분포 거리가 가까우면 서로 하드 네거티브 샘플로 간주됨.
- 예시: 발화 $$u$$(I enjoy playing with cats)의 triplet $$(s^+, r^+, o^+)$$는 (I, like\_animal, cats)이며, 이는 관계 클래스 like\_animal을 가진 문장임.
- CSC의 긍정 샘플은 다음과 같이 형성됨: 
  - CONTEXT : I enjoy playing with cats 
  - SUBJECT : I 
  - OBJECT : cats 
  - RELATION : like\_animal
- Meta-V AE 샘플러를 통해 relation like\_animal에 가장 가까운 top-k 관계(like\_music, like\_sport, have\_pet)를 검색함.
- 각 검색된 관계 $$r'$$에 대해, 예를 들어 like\_sport, 임의의 발화 $$u$$ (I enjoy playing basketball)를 선택함.
- 선택된 $$k$$개의 발화는 같은 triplet $$(s^+, r^+, o^+)$$로 하드 네거티브 샘플을 생성함.
- 예시의 하드 네거티브 샘플:
  - CONTEXT : I enjoy playing basketball 
  - SUBJECT : I 
  - OBJECT : cats 
  - RELATION : like\_animal
- 추출기는 긍정 샘플과 부정 샘플을 벡터 공간에서 분산시키도록 훈련됨.
- Meta-V AE는 KL 발산과 다음 단어 예측 손실을 기반으로 훈련됨, 이는 식 (Eq. 4)으로 표현됨.

---

# 4.4.1 Meta-V AE

- **V AE 개념**
  - Kingma와 Welling(2014)에 의해 제안됨.
  - 주어진 데이터셋에 대해 잠재 연속 랜덤 변수 $$z$$의 사전 분포 $$p_\theta(z)$$를 근사.
  
- **관계 타입 r에 따른 V AE 훈련**
  - 특정 관계 타입 r에 대해 각 데이터셋에 맞춰 V AE를 훈련.
  - 각 관계 클래스의 수 $$|R|$$에 따라 $$|R|$$개의 서로 다른 V AE 생성.
  - 하지만 파라미터 효율성이 낮음.

- **Meta-V AE 제안**
  - 복잡성 감소를 위해 제안됨.
  - 각 관계 클래스를 관계 임베딩 $$Embr(r)$$로 매핑.
  - 임베딩된 발화 $$Embu(u)$$와 관계 임베딩을 연결하여 V AE에 투입.
  - 연결 기반 조건화는 하이퍼네트워크의 특별한 경우임.
  
- **GRU 활용**
  - Meta-V AE의 인코더 및 디코더로 GRU 사용.
  - GRU의 업데이트 및 리셋 게이트 구조를 고려하여 간소화.
  - 관계 임베딩을 GRU 인코더의 초기 숨겨진 상태로 제공.
  - 이 과정은 덧셈과 연결 주의(attention)와 같음.
  
- **경량화된 식**
  - Eqs. (2)와 (3)에서 관계 임베딩을 게이트 업데이트에 활용:
    - $$ a_j^1 = \sigma(W_a Embu(x_1) + U_a Embr(r))_j $$
    - $$ c_j^1 = \sigma(W_c Embu(x_1) + U_c Embr(r))_j $$
  
- **목표 함수**
  - Meta-V AE의 경험적 목표:
    - $$ L_h(u; \theta, \phi, \tau) = -DKL(q_{\phi,\tau}(z|u) \| p_{\theta,\tau}(z)) + \frac{1}{L} \sum_{l} \log p_{\theta,\tau}(u|z^{(l)}) $$
  - 관계 $$r$$에 대해:
    - 선형 분포 $$z^{(l)} = q_{\phi,\tau}(z|u) \sim N(\mu_\tau, \sigma_\tau^2 I)$$.
    - 생성 분포 $$p_{\theta,\tau}(u|z)$$ 조건부로 데이터 $$u$$ 생성.
  
- **파라미터**
  - $$z^{(l)}$$ 및 분포와 관련하여 파라미터 $$\theta, \phi, \tau$$는 학습 가능함.
  - $$L$$은 샘플 개수를 나타냄.

---

# 4.4.2 Sampling Criteria

- 잠재 변수 모델은 적은 수의 잠재 변수를 통해 변수 분포를 나타낼 수 있음 (Bishop, 1998).
- 잠재 변수 $$z_r$$는 서로 다른 관계 $$r$$를 가진 발화의 분포를 포착.
  
- KL 발산(Kullback and Leibler, 1951):
  - $$z_i$$와 $$z_j$$의 분포 간 거리를 표현.
  - 관계 클래스 $$r_i$$와 $$r_j$$에 대한 잠재 변수 $$z_i$$, $$z_j$$에 대해 가정:
    - $$z \sim N(z; \mu, \Sigma)$$, 모든 구성 요소가 독립적: $$\Sigma_{i,j} = 0$$ (이때 $$i \neq j$$).
  
- KL 발산 공식을 다음과 같이 정의:
  $$ D_{KL}(P_i || P_j) = E_{P_i} \left[ \log \frac{P_i}{P_j} \right] = \frac{1}{2} \left\{ \log \frac{|\Sigma_j|}{|\Sigma_i|} - n + \text{tr}(\Sigma_j^{-1} \Sigma_i) + (\mu_j - \mu_i)^T \Sigma_j^{-1} (\mu_j - \mu_i) \right\} $$
  
- $$\Sigma$$를 대각 행렬로 가정 시, 수식 간소화:
  $$ D_{KL}(P_i || P_j) = \frac{1}{2} \left\{ \text{tr}(\log \Sigma_j - \log \Sigma_i) - n + \text{tr} \left( \frac{\Sigma_i}{\Sigma_j} \right) + (\mu_j - \mu_i)^T \cdots \Sigma_j^{-1} (\mu_j - \mu_i) \right\} $$

- 샘플링 전략:
  - 각 관계 클래스 $$r_i$$에 대해 무작위로 발화 하나 선택.
  - 학습된 Meta-V AE에 입력하여 $$z_i$$ 산출.
  - $$z_i$$와 $$z_j$$의 분포 간 거리 계산: 관계 $$r_i$$와 $$r_j$$ 간 거리.
  - 각 관계 $$r_i$$에 대해 가장 가까운 상위 $$k$$ 관계 선택.
  - 각 상위 $$k$$ 관계에서 무작위로 발화 하나 선택하여 $$k$$개의 어려운 부정 샘플 생성.

- 샘플링 알고리즘의 세부사항은 부록 C에 설명되어 있음.

---

# 4.5 Contrastive Structured Constraint

- 기존의 세대 기반 삼중 추출 방법은 삼중이 입력 발화 $$u$$와 일치해야 한다는 사실에 주목하지 않음 (Ye et al., 2021).
- 일부 대화 발화의 유사한 토큰 분포는 문제를 악화시킴.
  - 예: "$$\text{My mom}$$"에서 고양이에 대한 속성 삼중 "(My mom, have_pet, 1 cat)"을 추출하고 싶지 "(My mom, like_animal, 1 cat)"를 추출하는 것.
- 전자는 고양이가 어머니에게 속함을 명시적으로 전달하지만, 후자는 소유의 속성을 전달하지 않음.
- 이에 따라 삼중 대조 학습을 이진 분류 문제로 변환:
  - 발화 $$u_t$$에 대해 레이블 $$(s^+, r^+, o^+)$$이 주어짐.
  - 메타 변환 샘플러에서 $$k$$개의 하드 샘플 $$(u^{-}_{t,1}, \ldots, u^{-}_{t,k})$$을 추출.
  - 긍정 샘플은 "CONTEXT : $$u_t$$, SUBJECT : $$s^+$$, OBJECT : $$o^+$$, RELATION : $$r^+$$"로 표현.
  - 부정 샘플은 "CONTEXT : $$u^{-}_{t,j}$$, SUBJECT : $$s^+$$, OBJECT : $$o^+$$, RELATION : $$r^+$$"로 표현.
- 마지막 입력 토큰의 숨겨진 상태 $$h^+_i$$ (긍정) 및 $$h^{-}_j$$ (부정)를 PAE에서 추출 후 완전 연결층에 입력하여 분류 로짓 $$l$$을 계산.
- 샘플을 고정된 긍정/부정 극성으로 수렴시키는 대신, CSC를 사용하여 긍정 및 부정 샘플을 재배치하고 서로 멀어지게 함.
- 구조적 대조 손실은 KL 발산을 기반으로 하며, 수식은 다음과 같음:

  $$$$L_c = -D_{KL}(l^+ \vert\vert l^-) - D_{KL}(l^- \vert\vert l^+) = - \sum_{i=1}^{L} \sum_{j=1}^{k} \frac{1}{k}(l^+_i \log \frac{l^+_i}{l^-_j} + l^-_j \log \frac{l^-_j}{l^+_i}).$$$$

- 여기서 $$l^+_i$$는 i번째 긍정 샘플의 로짓, $$l^-_j$$는 j번째 부정 샘플의 로짓.

---

# 5 Experiments

- **모델 실험 대상**: PersonaExt (PerExt) 및 FewRel 데이터셋
- **목적**: 
  - 다중 삼각형 추출 기능 탐색
  - 제로샷 관계 추론(Zero-shot RTE) 가능성 평가
- **데이터셋 통계**:
  - FewRel: 56,000 샘플, 72,964 개체, 80 관계, 평균 길이 24.95
  - PersonaExt: 35,078 샘플, 3,295 개체, 105 관계, 평균 길이 13.44
- **평가 성능 지표**:
  - 다중 삼각형 추출: MicroF1(Paolini et al., 2020), 정밀도(P), 재현율(R)
  - 단일 삼각형 추출: 정확도(Acc.)

---

# 5.1 Datasets

- FewRel 데이터셋은 위키백과와 위키데이터에서 후보 관계 및 인스턴스를 자동으로 추출한 후, 인간 주석을 통해 저품질 관계를 필터링하는 방식으로 구축됨 (Han et al., 2018).
- Chia et al. (2022)의 방법을 따르며, FewRel을 제로샷 RTE에 적합하게 만들기 위해 작업을 수행.
- 두 데이터셋에서는 훈련 중 무작위로 고정된 수의 보이는(label) 및 보이지 않는(unseen) 레이블을 선택.
- 보이지 않는 레이블의 크기(n)는 세 가지 점진적인 설정 {5, 10, 15}으로 설정.
- 일관된 실험 결과를 위해 다섯 가지 서로 다른 무작위 시드를 사용하여 보이는 및 보이지 않는 레이블의 조합을 반복적으로 선택, 다섯 가지 데이터 폴드 생성.
- 각 데이터 폴드는 훈련, 검증 및 테스트 세트로 구성됨.
- 테스트 세트에는 보이지 않는 레이블이 포함된 문장이 포함됨.
- 검증 세트는 하이퍼파라미터 튜닝을 위해 사용되는 다섯 개의 레이블을 포함.
- 남은 문장은 훈련 세트를 구성.
- 이러한 설정을 통해 훈련, 검증 및 테스트 문장이 서로 다른 레이블 세트에서 오도록 보장.

---

# 5.2 Baselines

- **TableSequence (TS)** (Wang and Lu, 2020)
  - 주로_named entity recognition_과_relation extraction_의 공동 학습을 위해 설계됨.

- **RelationPrompt (RP)** (Chia et al., 2022)
  - 제로샷 관계 추출(zero-shot RTE)을 해결하기 위해 첫 번째로 PLM을 프롬프트하여 관계 레이블에 따라 관계 샘플을 합성함.

- **SpERT** (Eberts and Ulges, 2020)
  - 강력한 부정 샘플러를 전이함.
  - 현재 발화의 삼중항(s+, r+, o+)과 다른 발화(s−, r−, o−)를 연결하여 사용.
  - 부정 삼중항은 (s+, r*, o−) 또는 (s−, r*, o+) 형태이며, 여기서 $$r^*$$는 임의의 관계 유형.

- **실험 결과 표** (n=5, 10, 15에 대한 각 모델 성능)
  - TS, RP, OURS 모델의 P, R, F1, Acc. 수치 제시 (요약필요).
  
- **RSAN** (Yuan et al., 2021b)
  - 현재 문장과 다른 여러 관계를 무작위로 선택함.

- **GenTaxo** (Zeng et al., 2021)
  - 무작위로 삼중항(s−, r−, o−)을 선택하고, 그로부터 (s+, r+, o−) 또는 (s−, r+, o+) 형태의 부정 삼중항을 생성함.

---

# 5.3 Setups

- **모델 사용**:
  - PLM GPT-2 (Radford et al., 2019): 124M 파라미터, PAG로 사용
  - BART (Lewis et al., 2020): 140M 파라미터, PAE로 사용
  - MetaV AE 샘플러: 2.4M 파라미터

- **모델 훈련**:
  - 훈련 세트에서 5 에폭동안 파인튜닝
  - 최적 모델 파라미터는 검증 손실 기준으로 선택
  - 옵티마이저: AdamW (Loshchilov 및 Hutter, 2018)

- **하이퍼파라미터 설정**:
  - 배치 사이즈: PAG 128, PAE 32
  - 학습률: PAG 3e-5, PAE 6e-5, Meta-V AE 0.005
  - 워밍업 비율: 0.2

- **문장 합성**:
  - 각 관계에 대해 250개의 문장을 PAG를 이용하여 합성
  - 합성 문장에 대해 PAE 다시 파인튜닝

- **디코딩 전략**:
  - 단일 트리플렛 추출: 탐욕적 디코딩 전략
  - 다중 트리플렛 추출: 트리플렛 검색 디코딩(TSD) 전략 (Chia et al., 2022)

- **추가 정보**: 
  - 세부 구현 사항은 Appendix B에 포함되어 있음.

---

# 5.4 Experimental Results

- **주요 결과**: 
  - 일반화된 제로샷 RTE 및 PAED의 주요 결과는 표 3에 보고됨.
  - 각 $$n \in \{5, 10, 15\}$$에 대해 5개의 서로 다른 데이터 접기(folds)를 3회 실행하고 평균을 구함.
  - 유의 수준은 0.05로 설정.

- **성과 비교**: 
  - 모든 설정에서 OURS가 RP를 평균 1.06% 초과 달성 (PersonaExt).
  - FewRel 데이터셋에서도 대부분의 설정에서 OURS가 RP보다 성능이 우수함.

- **결과 요약**:

  <img width="399" alt="image" src="https://github.com/user-attachments/assets/ebe61d23-fcf9-49a8-b622-0fa10e42f653" />


- **소거 연구**(Ablation study):
  - HNS는 Meta-V AE 샘플러 & CSC를 의미함.
  - 다중 트리플 추출에서 유의미한 개선을 $$3.18\%$$로 평가하며, 이는 훈련 중 어려운 샘플을 도입한 Meta-V AE 샘플러 덕분.
  - OURS는 RP보다 항상 높은 정밀도($$3.22\%$$의 평균)를 기록함.

- **문제점**: 
  - PAED에서 거짓 긍정 문제는 거짓 부정보다 더 심각하며, 화자가 무관심보다 혼란을 더 용인할 가능성이 큼.
  
- **기타**: 
  - 결과는 제로샷 RTE에서의 프레임워크의 일반화 능력을 보여줌.

---

# 5.5 Ablation Study

- PersonaExt 데이터셋에서 ablation study를 수행
- Meta-V AE 샘플러와 여러 기준 샘플러 비교
- 모든 샘플러는 동일한 랜덤 시드 및 CSC 손실 사용
- 세 가지 보지 못한 레이블 설정으로 실행 후 평균 정확도 보고
- 결과:
  - Meta-V AE 샘플러가 평균 2.66% 더 높은 성능 기록
  - 가장 강력한 기준선인 GenTaxo를 1.37% 초과
- Meta-V AE 샘플러의 우수한 성능은 다양한 관계의 분포에 대한 좋은 근사 덕분
- HNS를 제거했을 때 성능이 크게 감소, 그러나 여전히 일부 기준 샘플러보다 우수
- 나쁜 샘플러는 개선보다는 성능하락을 초래할 수 있음
- 따라서 샘플러가 하드 네거티브 샘플을 정확히 식별하는 것이 대조 학습의 성공에 필수적임

---

# 5.6 Revisiting Meta-V AE Sampler with CSC

- **KL 발산 증가**
  - 합성 데이터셋에서 미세 조정 시 양수 샘플과 음수 샘플 간의 KL 발산이 증가함.
  - 이는 CSC 손실을 공식화하는 과정에서 KL 발산을 사용했기 때문임.

- **샘플 분포 분석**
  - 미세 조정 전후의 양수 및 음수 샘플 분포를 연구함 (Fig. 2 참조).
  - PCA(주성분 분석)를 통해 샘플 표현을 분해하여 scatter plot 생성.

- **그룹 분포**
  - **그룹 1 (Fig. 2 (b))**: 다양한 관계 유형에 따라 양수 샘플과 음수 샘플의 분포를 보여줌.
  - **그룹 2 (Fig. 2 (c))**: 유사한 방식으로 다른 관계 유형에서 샘플 분포 확인.
  - **그룹 3 (Fig. 2 (d))**: 모든 그룹에서 샘플들이 긍정적 샘플 주위에 밀집해 있음.

- **결론**
  - Meta-V AE 샘플러는 의미적으로 가장 가까운 어려운 음수 샘플을 찾을 수 있음.
  - CSC 손실은 긍정적 및 부정적 샘플이 의미적 벡터 공간에서 퍼지도록 함.
  - 이는 모델이 샘플들을 더 효과적으로 재배치할 수 있게 함.

---

# 5.7 Case Study

- **사례 설명**:
  - 세 가지 PAED 사례가 그림 3에 제시됨.
  
- **장점과 단점**:
  - 사례 1과 3에서 RP 방법으로 추출된 객체들이 관계와 잘 맞지 않음.
  - RP는 사실과 반대되는 잘못된 관계를 추출 (사례 1과 2)함.
  
- **강점**:
  - 우리의 추출기는 어려운 부정 샘플을 다루는 데 유리하다는 강한 성능을 보임.

- **구체성 문제**:
  - 사례 2의 객체 ‘all’은 구체적이지 않음.
  
- **주석 일관성 문제**:
  - Wu et al. (2020)의 사례 1과 3의 관계 및 객체 주석이 발화와 일치하지 않음.

- **추출 결과 비교**:
  - 사례 1:
    - RP: I, like_general, blond
    - OURS: I, dislike_general, beach
    - Wu et al.: I, employed_by_general, arena
    - PersonaExt: I, dislike_general, beach
  
  - 사례 2:
    - RP: I, dislike_general, cars
    - OURS: I, like_general, cars
    - Wu et al.: I, dislike, all
    - PersonaExt: I, like_general, cars
  
  - 사례 3:
    - RP: I, like_general, exotic
    - OURS: I, favorite_place, jamaica
    - Wu et al.: I, like_activity, traveling
    - PersonaExt: I, favorite_place, jamaica

---

# 5.8 Exploration of Experimental Settings

- **프레임워크의 강건성 탐색**
  - PAE의 디코딩 전략과 PAG에서 생성된 샘플의 데이터 크기가 PersonaExt 데이터셋에 미치는 영향을 분석.
  
- **디코딩 전략 비교**
  - Table 5에서 세 가지 보이지 않는 라벨 설정을 사용하여 정확도 변화 비교.
  - 기본 탐욕적(greedy) 전략과 다른 디코딩 전략 비교.
  - top-k 랜덤 샘플링이 성능을 약화시킴. (Fan et al., 2018)
    - 개방형 생성에서 효과적이지만, PAED에는 부적합.
  
- **TSD 개선 효과**
  - TSD가 PAED 작업에서 단일 트리플 추출의 정확도를 개선.
    - RP의 성능 개선을 위해 제안됨.
  - 비록 정확도가 증가하였으나, 계산 시간이 상당히 증가함.
  
- **실험 결과**
  - RelationExt 데이터셋에서 10개의 보이지 않는 라벨로 실험 진행.
  - 합성 데이터의 크기를 250에서 550으로 변화시키며 강건성 확인.
  - 합성 샘플 수를 1에서 100으로 증가시킬 때, 정확도에 뚜렷한 개선 관찰.
  - 최적 성능은 450개의 합성 샘플에서 달성.
  - 합성 데이터 크기의 추가 증가는 점진적인 정확도 감소로 이어짐.
  
- **Table 5의 결과 요약**
  - top-k 샘플링 사용 시 정확도 변화: 
    - n=5: -3.66
    - n=10: -2.77
    - n=15: -1.66
  - TSD 사용 시 정확도 변화: 
    - n=5: 0.54
    - n=10: 0.60
    - n=15: 0.07
  
- **Figure 4 설명**
  - 합성 샘플 수에 따른 PAED의 정확도 변화를 보여줌.

---

# 6 Conclusion

- **연구 목적**: 본 연구에서는 대화에서 인물 속성 추출(PAED)을 위한 일반화된 제로샷 학습을 조사함.
  
- **데이터셋 구축**: 
  - PersonaChat와 Dialogue NLI를 기반으로 PersonaExt를 구축.
  - 반자동 주석 프레임워크를 통해 일관되고 구체적인 트리플 레이블 생성.

- **모델 제안**: 
  - 효과적이고 해석 가능한 Meta-V AE 샘플러와 CSC 손실을 사용하여 어려운 네거티브 샘플 처리.
  - 이를 PAE에 통합하여 일반화된 제로샷 PAED 작업 수행.

- **실험 결과**: 
  - 제안한 프레임워크가 가장 강력한 기준선보다 훨씬 우수함을 입증.
  - 시각화된 정량적 분석을 통해 Meta-V AE 샘플러 및 CSC의 작동 메커니즘을 상세히 설명.

- **제한 사항**: 
  - 이론적 지원 부족으로 인해 현재 단계의 암묵적 인물 속성에 대한 주석 체계 formalization 어려움.
  - 예를 들어, 문장 “매일, 나는 개인적으로 내 개를 산책시키고 이웃의 털복숭이 친구들을 가끔 산책시키는 것을 도와준다”에서 암묵적인 트리플 (I, like_animal, dogs) 추출 어려움.
  - PersonaExt는 암묵적이거나 여러 인물 속성 트리플 추출 작업과 호환되지 않음.
  - 현재 발화의 맥락에서 보완 정보를 활용하지 않음.

- **모델의 어려움**:
  - 여러 대화 발화가 있는 입력의 경우, 대명사 및 여러 발화자가 존재하여 추출된 인물 트리플을 특정 화자와 일치시키기 어려움.

- **감사의 말씀**: 
  - 이 연구는 과학 기술 연구 기관(A*STAR)의 AME 프로그램 기금 지원을 받음 (프로젝트 #A18A2b0046).

- **윤리적 고지**:
  - 인간 주석은 공격적인 콘텐츠가 없고 개인 식별 정보를 수집하지 않도록 최대한 주의를 기울여 수행됨.
  - 주석자에게 주석의 목적과 적절한 사용에 대한 포괄적 설명 제공, informed consent 확보.
