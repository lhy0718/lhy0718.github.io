---
title: "[논문리뷰] FASTopic- Pretrained Transformer is a Fast, Adaptive, Stable, and Transferable Topic Model (NeurIPS 2024)"
date: 2025-03-07 09:00:00 +0900
categories:
  - Paper Review
tags:
  - NLP
  - NeurIPS 2024
  - Topic Model
---

요약: 이 논문에서는 기존의 효율성, 안정성 및 효과성 문제를 해결하기 위해 빠르고 적응 가능하며 안정적이고 이전 가능성 높은 주제 모델인 FASTopic을 제안합니다. FASTopic은 데이터셋 내에서 문서 임베딩과 주제 및 단어 임베딩 간의 의미적 관계를 직접 모델링하여 잠재적 주제를 발견하는 새로운 패러다임인 이중 의미 관계 재구성(DSR)을 기반으로 합니다.

---

# 1 Introduction

- 주제 모델은 해석 가능성과 비지도 학습 방식으로 다양한 응용 프로그램에서 활용됨.
  - 콘텐츠 추천, 생성, 트렌드 분석 등.
- 초기 전통적인 주제 모델은 확률적 그래픽 모델 또는 비음수 행렬 분해 방식으로 개발됨.
  - 그러나 대규모 데이터 처리에 한계를 가짐.
- 최근에는 신경망 기반 주제 모델들이 주목받고 있으며, VAE 기반 및 클러스터링 기반 모델 포함.
  - 기존 신경망 주제 모델은 효율성, 효과성, 안정성 부족.
    - VAE 기반 모델은 효과적이지만 효율성이 낮아 모델 구조가 복잡해 처리 시간이 길어짐.
    - 클러스터링 기반 모델은 효율적이지만 낮은 효과성을 보여 원하는 다양성을 제공하지 못함.
- 또한, 신경망 주제 모델은 하이퍼파라미터에 민감하여 다양한 데이터 상황에서 안정성이 떨어짐.
- 이러한 문제를 해결하기 위해 FASTopic 모델을 제안.
  - 복잡한 신경망 대신 사전 훈련된 Transformer 기반의 문서 임베딩과 토픽 및 단어 임베딩을 사용하는 새로운 패러다임인 이중 의미 관계 재구성(DSR) 도입.
  - DSR은 문서와 토픽, 토픽과 단어 임베딩 간의 이중 의미 관계를 모델링.
- 새로운 임베딩 전송 계획(ETP) 방법 제안으로 관계 편향 문제를 완화하고 효과적인 주제 모델링 가능.
- FASTopic의 주요 기여:
  - 문서, 토픽, 단어 임베딩 간의 의미 관계를 모델링하는 새로운 주제 모델 제안.
  - 최적 운송 계획으로 의미 관계를 정규화하는 혁신적인 방법 제안.
  - 방대한 실험을 통해 기존 최고 성능 모델 대비 높은 효과성, 효율성, 적응성, 안정성, 이전 가능성 입증.

---

# 2 Related Work

- **전통적인 주제 모델**
  - 두 가지 유형: 확률적 주제 모델 (예: LDA) 및 비음수 행렬 분해 모델.
  - 확률적 주제 모델은 주제를 잠재 변수로 사용하고, Gibbs 샘플링 또는 변분추론으로 파라미터를 추정.
  - 짧은 텍스트, 다국어, 동적 주제 모델링 등 다양한 시나리오로 확장됨.
  - 하지만 모델 특화된 유도 과정이 필요하며, 대규모 데이터셋 처리에 한계가 있음.

- **VAE 기반 신경 주제 모델**
  - 변분 오토인코더(VAE) 프레임워크를 따르고, 파라미터를 최적화하기 위해 그래디언트 역전파 사용.
  - 기존 방식과의 차별점:
    - 전통적인 복잡한 VAE 프레임워크를 따르지 않음.
    - 새로운 임베딩 운반 계획을 이용해 의미 관계를 모델링.
  - 이러한 차별점으로 인해 더 빠른 속도와 높은 주제 모델링 성능을 성취.

- **클러스터링 기반 신경 주제 모델**
  - 사전 훈련된 단어 임베딩을 클러스터링 알고리즘(KMeans 등)을 통해 주제를 생성.
  - 대부분 문서의 주제 분포를 추정하지 못함.
  - BERTopic은 문서 임베딩을 클러스터링하고 각 문서 클러스터와 비교해 주제 분포를 근사.
  - 단순 클러스터링과 다르게, 문서, 주제, 단어 임베딩 간의 복잡한 관계 모델링에 집중해 성능 향상.

- **최근 연구 동향**
  - 대형 언어 모델을 활용하여 주제를 개념적 설명으로 정의.
  - 높은 해석 가능성 달성 가능하지만 두 가지 제한점:
    - 더 많은 자원 필요: 각 문서를 LLM에 프롬프트로 입력해야 하므로 시간과 계산량이 많음.
    - 주제 및 문서의 정확한 분포를 생성하지 못해 다운스트림 작업에 제한적임.

---

# 3 Methodology: FASTopic

- 토픽 모델링 문제 설정을 간략히 재정리함.
- 새로운 패러다임 '듀얼 의미 관계 재구성(Dual Semantic-relation Reconstruction, DSR)' 제안.
- 혁신적인 '임베딩 전송 계획(Embedding Transport Plan, ETP)' 방법 소개.
- 새로운 모델 FASTopic의 개념 설명.

---

# 3.1 Problem Setting and Notations

- 문서 집합 {x(1), ..., x(N)}가 있으며, N개의 문서와 V의 어휘 크기를 포함.
- 주제 모델링은 K개의 잠재 주제를 발견하는 것을 목표로 함.
- LDA를 따르며, Topic#k는 모든 단어에 대한 분포로 정의됨.
  - 이를 topic-word 분포라고 하며, βk ∈ RV로 나타냄.
  - 모든 주제의 topic-word 분포 행렬은 β = (β1, ..., βK) ∈ RV × K로 표현.
- 주제 모델링은 문서의 주제 분포(문서에 포함된 주제)를 추론함.
  - 문서 x(i)의 doc-topic 분포를 θ(i) ∈ ∆K로 표시.
  - 여기서 ∆K는 확률 단순체를 의미.
- 그림에 대한 설명:
  - (a, b): 문서에 대한 주제의 관계 가중치.
  - (c, d): 50개의 주제(K=50) 아래 문서(■)와 주제(▲) 임베딩의 t-SNE 시각화.
  - Parameterized Softmax(a, c)는 편향된 관계를 초래하여 대부분의 주제 임베딩이 함께 모여있음을 보여줌.
  - ETP(b, d)는 정규화된 관계로 모든 주제 임베딩을 분리하여 편향 문제를 피함.

---

# 3.2 Dual Semantic-relation Reconstruction

- **주제**: Dual Semantic-relation Reconstruction (DSR)라는 새로운 주제 모델링 패러다임 제안
- **문서, 주제, 단어의 매개변수화**:
  - 문서, 주제, 단어를 임베딩으로 매개변수화
  - 문서를 미리 학습된 Transformer(fdoc, 예: BERT)로 H차원의 의미 공간에 임베딩
  - 문서 임베딩 D=(d1, ..., dN)로 표현, 여기서 di는 i번째 문서의 임베딩
  - 주제 K개와 단어 V개도 동일한 의미 공간에 임베딩, pretrained 단어 임베딩 사용하지 않음

- **쌍의 의미적 관계를 통한 재구성**:
  - 문서와 주제, 주제와 단어 간의 쌍의 의미적 관계 모델링
  - 문서-주제 분포 및 주제-단어 분포로 해석
  - 기초 모델링:
    - θ(i)k: i번째 문서와 주제 k 간의 관계
    - βjk: 주제 k와 j번째 단어 간의 관계
  - 재구성을 통해 이 관계 학습, 제안된 손실 함수:
    - LDSR = −(1/N)Σ(x(i))⊤ log(βθ(i))
  - 목적: 의미적으로 관련된 문서 및 단어와 가까운 주제 임베딩 학습

- **DSR의 장점**:
  - 기존 VAE 기반 방법보다 간단하고 효율적
  - DSR은 하나의 목표만을 포함하여 주제 모델링 절차의 단순화
  - 이전 클러스터링 기반 방법과 달리 주제-단어 분포 및 문서-주제 분포를 명시적으로 모델링하여 높은 효과성 제공

---

# 3.3 Embedding Transport Plan

- **주제 모델링을 위한 의미적 관계 모델링 분석**
  - 의미적 관계를 모델링하는 것은 간단한 문제가 아님.
  - 일반적으로 파라미터화된 소프트맥스 함수 사용.
  - 관계를 유클리드 거리로 측정하며, 하이퍼파라미터 τ를 포함.

- **관계 편향 문제**
  - 간단한 방법은 비효율적이며, 관계 편향 문제를 초래함.
  - 대부분의 주제 임베딩이 정보가 부족하고 유사한 의미를 갖게 됨.
  - 중복된 주제와 부정확한 문서-주제 분포가 발생함.

- **새로운 해결책: Embedding Transport Plan (ETP)**
  - 관계 편향 문제를 해결하기 위해 효율적인 정규화를 제공하는 ETP 제안.
  - 문서 및 주제 임베딩에 대해 두 개의 이산적 측정 γ1과 ρ1 정의함.
  - 문서 임베딩의 가중치는 1/N, 주제 임베딩의 가중치는 sk로 설정.

- **최적 수송 문제의 정규화**
  - 두 조건을 고려하여 문서 임베딩의 가중치를 주제 임베딩으로 운반하는 수송 계획 π 최적화.
  - 원래의 최적 수송 문제에 엔트로피 정규화 추가.

- **주제 임베딩과 단어 임베딩 간의 수송 계획**
  - 이와 유사하게, 주제와 단어 임베딩 간의 두 개의 이산적 측정 γ2와 ρ2 정의.
  - 단어 임베딩의 가중치는 uj로 설정.
  - 주제와 단어 간의 수송 계획 ϕ를 통해 의미적 관계 모델링.

- **ETP의 목적**
  - 문서 x(i)의 문서-주제 분포 θ(i)를 ETP를 통해 정의.
  - Sinkhorn 알고리즘을 사용하여 수송 계획 π∗의 근사 솔루션을 계산.
  - 주제-단어 분포 행렬 β도 유사한 방식으로 모델링.
  - 최종적으로 ETP의 목적은 근사된 수송 계획에 의해 가중치된 총 수송 비용 최소화.

---

# 3.4 Objective for FASTopic

- FASTopic의 전체 목표는 다음과 같다:
  - 최소화: $$LETP + LDSR$$
  
- 각 항목 설명:
  - **LETP**: 주제 및 단어 임베딩을 정규화된 의미 관계를 사용하여 정제.
  - **LDSR**: 재구성을 통해 이러한 의미 관계를 학습.

- 하이퍼파라미터 수를 줄이기 위해 두 목표의 가중치를 기본적으로 동일하게 설정.

- FASTopic의 장점:
  - 이전 작업에 비해 단순한 목표.
  - 최적화하는 매개변수는 4개: 주제 및 단어 임베딩 $$T, W$$와 가중치 $$s, u$$.
  - 문서 임베딩 $$D$$는 이미 사전 훈련되어 과적합 문제를 피하기 위해 동결.

- FASTopic의 훈련 속도:
  - 이 간단한 목표 덕분에 매우 빠른 훈련 가능.
  - 이전 모델들보다 훨씬 더 적은 하이퍼파라미터 필요.

- 하이퍼파라미터 예시:
  - Sinkhorn 알고리즘의 $$ε1$$ 및 $$ε2$$.
  - VAE 기반 모델들은 인코더, 디코더 설정(차원, 층 수, 드롭아웃)과 사전 분포에 대한 하이퍼파라미터가 필요함.

---

# 3.5 Inferring Doc-Topic distributions for New Documents

- 새로운 문서 x′에 대한 문서 임베딩 d′=fdoc(x′)를 고려.
- 학습 과정(3.3절)을 따르려면 d′와 학습된 주제 임베딩 T 사이의 수송 계획을 계산하여 doc-topic 분포 θ′를 유추.
- 그러나 이 방법은 불가능.
  - 한 문서의 가중치를 모든 주제로 전이하기 때문에, x′에 대해 수송 계획이 항상 학습된 주제 가중치 s가 됨.
  - 이는 불합리한 결과.
- 대신 θ′ 계산 방식:
  - θ′_k = pk / Σ_(k′=1)^(K) pk′
  - pk = exp(−∥tk − d′∥²/τ) / Σ_(i=1)^(N) exp(−∥tk − di∥²/τ)
  - τ는 온도 하이퍼파라미터.
- d′와 tk 간의 관계를 유클리드 거리로 모델링하고, 학습된 주제 가중치를 근사하기 위해 모든 훈련 문서와의 총 관계로 정규화.
- 모든 주제에 대해 정규화하여 θ′_k 계산.
- 주제와 단어 임베딩이 학습 후 정제되었으므로, 새로운 문서에 대해 정확한 doc-topic 분포를 유추 가능.
- 실험 결과는 4.2절과 4.3절에서 확인 가능.

---

# 4 Experiment

- 본 실험에서는 FASTopic의 성능을 검증하기 위해 여러 가지 실험을 진행함.
- 목표: FASTopic이 빠르고, 적응력이 뛰어나며, 안정적이고, 전이 가능함을 증명.

## 표 4: 주제 품질 결과 (CV: 주제 일관성, TD: 주제 다양성)
- 다양한 주제 수(K)에 따른 모델 성능 비교:
  - LDA-Mallet, NMF, BERTopic, CombinedTM, GINopic, ProGBN, HyperMiner, ECRTM, FASTopic 등 여러 모델 비교.
  - FASTopic은 K=75에서 CV 0.465, TD 0.998로 최고 성능 기록.

## 표 5: 문서 클러스터링 결과 (Purity, NMI)
- Purity와 NMI 지표를 통한 다양한 주제 수(K)의 성능 분석:
  - FASTopic은 K=200에서 Purity 0.735, NMI 0.368로 가장 높은 값 기록.
  
- 실험을 통해 FASTopic이 다른 모델에 비해 일관성과 다양성, 클러스터 품질에서 뛰어난 성능을 보임을 입증함.

---

# 4.1 Experiment Setup

- **데이터셋**
  - 실험을 위해 여섯 가지 벤치마크 데이터셋을 사용
    - **20NG**: 20개의 레이블을 가진 뉴스 기사 데이터셋
    - **NYT**: 12개의 카테고리로 분류된 뉴욕 타임즈의 뉴스 기사 포함
    - **WoS**: 웹 오브 사이언스에서 출판된 논문들로 구성된 데이터셋, 7개 카테고리
    - **NeurIPS**: 1987년부터 2017년까지의 NeurIPS 컨퍼런스에서 발표된 논문 데이터셋
    - **ACL**: 1970년부터 2015년까지의 ACL 앤솔로지의 연구 기사 포함
    - **Wikitext-103**: 위키백과 기사 데이터셋

- **평가 지표**
  - 주제 모델링 평가 방법은 여전히 진행 중이며, 일반적인 연구를 따름
  - **주제 품질**
    - **주제 일관성**: 탐지된 주제의 상위 단어들 간의 일관성을 측정 (CV 지표 사용)
    - **주제 다양성**: 탐지된 주제 간의 차이를 측정, 고유 단어 비율로 평가
  - **문서-주제 분포 품질**
    - 문서 클러스터링을 수행하고, Purity와 NMI를 평가
    - Perplexity는 본 방법이 VAE 프레임워크를 따르지 않기 때문에 평가하지 않음

- **기준 모델**
  - 세 가지 패러다임에서 다음의 기준 모델 고려
    - **전통적인 주제 모델**
      - LDA-Mallet: 신경 모델에 경쟁력 있는 전통적인 방법
      - NMF: 비-음수 행렬 분해 사용
    - **클러스터링 기반 주제 모델**
      - BERTopic: 문서 임베딩 클러스터링 및 TF-IDF를 통해 주제 발견
    - **VAE 기반 신경 주제 모델**
      - CombinedTM: 맥락적 특징과 BoW 결합
      - GINopic: 그래프 동형 네트워크 사용
      - HyperMiner: 하이퍼볼릭 임베딩으로 모델링
      - ProGBN: 그래프 디코더로 다양한 수준의 문서 점진적으로 생성
      - ECRTM: 최적 수송을 사용하여 임베딩을 정규화한 최신 방법

- **하이퍼파라미터 튜닝**: 다양한 데이터셋과 주제 수에 따라 기준 모델의 하이퍼파라미터를 조정함.

---

# 4.2 Effectiveness: Topic Quality and Doc-Topic Distribution Quality

- FASTopic의 우수한 효과성을 입증
- **표 1**: 
  - 주제 품질 결과: 주제 일관성(CV) 및 주제 다양성(TD)
  - FASTopic이 모든 데이터셋에서 모든 벤치마크를 초과하는 가장 높은 성능을 보여줌
- **표 2**: 
  - 문서 클러스터링과 관련된 문서-주제 분포 품질 결과: Purity 및 NMI
  - FASTopic이 최고의 성능을 기록
- 결과적으로, FASTopic은 고품질 주제 및 문서-주제 분포를 생성하여 우수한 효과성을 보여줌
- 새로운 DSR 패러다임의 능력을 확인하는 결과
- 발견된 주제의 예시는 부록 H 참조

---

# 4.3 Effectiveness: Text Classification as Downstream Task

- 텍스트 분류를 주제 모델 평가를 위한 외부적 방법으로 고려
- Wu et al. [73]의 연구를 바탕으로 SVM 분류기를 훈련
  - 문서-주제 분포를 문서 특징으로 사용
  - 각 테스트 문서의 클래스를 예측
- 성능 측정 기준:
  - 정확도 (Accuracy, Acc)
  - F1 점수
- 그림 4에서 FASTopic이 항상 기준 모델보다 우수한 성능 발휘
- FASTopic의 성능 향상은 통계적으로 유의미 (p < 0.01)
- 결과는 FASTopic이 더 많은 다운스트림 분류 작업에 도움이 될 수 있음을 입증

---

# 4.4 Efficiency: Running Speed

- FASTopic의 매우 빠른 실행 속도를 보여줌.
- 표 3은 각 모델의 각 데이터셋에 대한 실행 시간을 보고함.
  - 실행 시간: 데이터 로딩 완료부터 훈련 완료까지의 소요 시간.
- FASTopic은 항상 가장 빠른 모델로, 0.01 수준에서 통계적으로 유의미한 차이를 보임.
- FASTopic은 1분 이내에 실행을 완료하며, 가장 긴 경우는 30분 소요.
- LDA-Mallet는 긴 문서를 가진 데이터셋에서 실행 시간이 증가함.
  - 예: 20NG에서 50초에서 Wikitext-103에서는 2000초로 증가.
- 반면, FASTopic은 문서 길이에 관계없이 빠른 성능을 유지.
- 그림 1b는 다양한 데이터셋 크기에서 FASTopic의 빠른 속도를 보여줌.
- FASTopic은 복잡한 모델링 구조에서 벗어난 깔끔하고 효율적인 DSR 패러다임을 채택함.
- 실행 시간에 대한 추가 분석은 부록 G에서 확인 가능.

---

# 4.5 Transferability
- FASTopic의 높은 전이 가능성을 검증함.
- Wikitext-103에서 주제 모델을 학습하고 다른 데이터셋(20NG, NYT, WoS)의 문서와 주제 분포 추론에 사용.
- 이러한 문서-주제 분포를 SVM 분류기를 위한 특징으로 사용하여 텍스트 분류를 수행.
- FASTopic의 전이 가능성이 기존 방법들보다 상당히 뛰어남을 그림 4에서 확인.
- 기존 방법들은 주로 Bag-of-Words에 의존했지만, FASTopic은 더 풍부한 표현을 활용함.
- 사전 학습된 문서 임베딩과 효과적인 ETP 방법을 통해 문서-주제 분포를 학습하여 더 높은 전이 가능성을 제공.

---

# 4.6 Adaptivity and Stability

- FASTopic의 적응성과 안정성을 WoS 데이터셋을 사용하여 다양한 시나리오에서 입증.
- **주제 수에 따른 성능**:
  - K가 75에서 200으로 변화할 때, FASTopic은 일반적으로 최고의 성능 유지.
- **데이터셋 크기에 따른 성능**:
  - N이 15k에서 40k로 변할 때, FASTopic은 주로 최상의 결과를 도출.
  - FASTopic의 실행 속도는 가장 빠름 (Figure 1b 참조).
- **어휘 크기에 따른 성능**:
  - V가 20k에서 50k로 변화할 때에도 FASTopic은 안정적이고 높은 성능을 보임.
- 모든 실험에서 동일한 하이퍼파라미터 사용 (Appendix D 참조).
- **ABALATION 연구 결과**:
  - ETP 없이 사용할 경우 (파라미터화된 소프트맥스 사용) 성능 저하.
- FASTopic은 다양한 시나리오에 원활하게 적응하며 안정적인 성능을 유지.
- 이러한 적응성과 안정성은 실용적 응용에서 중요한 장점.

---

# 4.7 Ablation Study

- **Embedding Transport Plan (ETP) 필요성 검증**: ETP 방법의 유용성을 평가하기 위해 ablation study 진행.
- **표 6 결과**:
  - ETP 없이 매개변수화된 소프트맥스를 사용할 경우 성능 저하 발생 (w/o ETP).
  - 주제 및 문서-주제 분포 품질 저하:
    - CV와 TD: 0.426, 0.983에서 0.368, 0.391로 감소.
    - Purity와 NMI: 0.577, 0.525에서 0.401, 0.452로 감소.
    - 이는 저품질의 반복 주제와 정확도가 낮은 문서-주제 분포를 나타냄.
- **표 9 유사 결과**: K=10인 경우에도 유사한 패턴 관찰.
- **ETP의 역할**: ETP는 의미 관계를 적절히 정규화하여 관계 편향 문제를 해결.
- **결론**: 효과적인 주제 모델링을 위해 ETP의 필요성이 강조됨.

---

# 5 Model Usage

- FASTopic는 PyPI에서 Python 패키지로 출시됨
- 사용자들은 pip를 통해 쉽게 설치 가능
- 사용법 예시:
  - 데이터셋을 전처리한 후, 주요 단어를 발견하고 문서-주제 분포 추론
- 간단한 API를 통해 사용자는 다양한 목적에 맞게 데이터를 처리할 수 있음
- 추가 튜토리얼 및 문서는 GitHub에서 확인 가능  

---

# 6 Conclusion

- 본 논문에서는 FASTopic이라는 신속하고 적응적이며 안정적이고 전이 가능한 주제 모델을 제안함.
- 기존의 VAE 기반 또는 클러스터링 기반 접근법 대신, FASTopic은 새로운 이중 의미 관계 재구성 패러다임을 사용하여 잠재적 주제를 모델링함.
- 관계 바이어스 문제를 해결하기 위해 새로운 수송 계획 관계 방법을 적용함.
- 종합적인 실험 결과, FASTopic이 효과성, 효율성, 적응성, 안정성 및 전이 가능성 측면에서 훨씬 우수한 성능을 보여줌.
- 이러한 장점은 FASTopic의 강력한 실용 능력을 나타내며, 다양한 실제 응용 분야에 이점을 제공함.