---
title: "[논문리뷰] RECAP- Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation (ACL 2023)"
date: 2025-04-08 16:00:00 +0900
categories:
  - Paper Review
tags:
  - ACL 2023
  - Persona-based Dialogue
---

챗봇에 일관된 개성을 부여하는 것은 engaging한 대화를 위해 중요하지만 여전히 해결되지 않은 문제입니다. 본 연구에서는 개인화된 응답 생성을 위한 새로운 검색 기반 접근 방식을 제안하며, 대화 도메인 데이터로 훈련된 계층적 변환기 검색기와 컨텍스트 인식 전처리 인코더를 설계하여 더 유창하고 개인화된 응답을 생성하는 모델의 효과를 실험을 통해 입증했습니다.

---

# 1 Introduction

- 최근 개방형 대화 생성에서 큰 성공을 거두면서 개인화된 대화 모델이 주목받고 있음.
- 개인화된 대화 모델의 장점:
  - 일관되고 매력적인 대화 생성 능력
  - 메시지 예측 생성에서 시간 절약 가능성

- 개인화된 응답을 생성하기 위해 대화 맥락과 사용자 페르소나에 조건 설정.
- 초기 연구는 주로 명시적 페르소나 모델링에 집중:
  - 사용자 특성, 프로필 또는 페르소나 설명 문장이 포함된 대화 데이터 필요.
  - 수집이 어려우며, 제한된 정보만 포함.

- 이후 연구에서는 자동으로 페르소나를 추출하는 방법 개발:
  - 콘텐츠 다양성을 개선하기 위한 시도로, 기존 페르소나와 비교해 한계 존재.
  
- 최근 연구들은 사용자 대화 기록을 암묵적 프로필로 통합:
  - 2단계에서 개인화된 응답 생성.
    - 1단계: 사용자 대화 기록에서 관련 대화 검색.
    - 2단계: 검색된 정보를 생성기에 융합.

- 암묵적 프로필 접근 방식이 실제 데이터셋에서 가장 견고하고 확장성이 있음에도 몇 가지 약점 존재:
  - 검색 단계에서 중요한 개인 정보 손실 가능성.
  - 융합 단계에서 프리 트레인 된 디코더의 완전 활용 부족.

- 본 연구에서는 암묵적 사용자 프로필 접근 방식을 집중적으로 다루며, 검색 및 융합 단계의 약점을 해결:
  - RECAP 모델 제안: Retrieval-Enhanced Context-Aware Prefix 인코더.
  - 사용자 페르소나 소통 최적화를 위한 계층적 트랜스포머 검색기 설계.
  - 컨텍스트 관련 정보 인코딩 및 효과적인 융합을 위한 프리픽스 인코더 설계.

- 기여 내용:
  - 개인화된 히스토리 검색을 위한 계층적 트랜스포머 검색기 설계.
  - 사용자 히스토리에서 관련 정보를 추출하여 생성기에 융합.
  - 자동 및 인간 평가에서 영어 Reddit 대화에 대한 개인화된 응답 생성에서 최상 성능 달성.

---

# 2 Methodology

- 개인화된 대화 응답 생성 작업을 형식적으로 정의
- RECAP 방법론 제안
- 이 방법론의 기본 개념 및 구조 설명
- 다양한 데이터셋 및 평가 기준 소개
- 모델 학습 및 검증 과정의 세부 사항 설명
- 성능 측정을 위한 수식 제시
  - 예를 들어, 모델의 정확도는 $$ \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}} $$와 같이 정의됨

---

# 2.1 Task Definition

- 목표: 개인화된 대화 모델 구축
  - 사용자에게 일관된 반응 생성
  - 대상 사용자와의 대화 이력 활용

- 사용자 집합: $$U$$
  - 특정 사용자 $$u \in U$$가 대상 사용자
  - 사용자 $$u$$의 이력: 
    - 형식: $$H_u = \{(c_{u1}, r_{u1}), \cdots, (c_{uT}, r_{uT})\}$$
    - 여기서 $$c_{ut}$$는 대화의 시작부터 단일 반응 $$r_{ut}$$ 직전까지의 문맥

- 현재의 (문맥, 반응) 쌍: $$(c_u, r_u) \notin H_u$$
  - 목표: $$p(r_u | c_u, H_u)$$ 최대화
  - 수식: 
    $$p(r_u | c_u, H_u) = \prod_{i=1}^{|r_u|} p(r_{u_i} | c_u, r_{u< i}, H_u)$$
    - 여기서 $$r_{u< i}$$는 $$r_u$$에서 $$r_{u_i}$$ 이전의 토큰

---

# 2.2 Model Overview

- **모듈 구성**: RECAP은 두 가지 주요 모듈로 구성됨.
  - **검색 모듈 (RE)**: 사용자 이력 응답을 선택.
  - **컨텍스트 인식 접두사 인코더 (CAP)**: 선택된 응답을 적절한 밀집 접두사로 변환.

- **퍼스널라이즈드 생성**: 
  - 생성된 접두사는 변환기 디코더의 중간 상태에 접두사 형태로 첨가되어 개인화된 결과를 생성함.
  - 이 방법은 Liu et al. (2022)에서 제안됨.

- **세부 설명**: RE와 CAP의 기능을 다음 섹션에서 자세히 설명함.

---

# 2.3 Retrieval Module (RE)

- **기본 구조**:
  - Bi-encoder 방식 사용 (Wu et al., 2018).
  - 사용자의 후보 대화 턴을 문서로 취급하여 밀집 표현 형성.
  - 대화의 맥락을 나타내는 쿼리도 생성.
  - 쿼리와 코사인 유사도가 가장 가까운 문서 집합 반환.

- **이전 연구와의 차별점**:
  - 기존 연구들은 사용자 최근 턴을 검색하거나 현재 대화와의 유사성에 따라 턴을 쿼리.
  - 본 모델은 사용자의 이력과 현재 맥락을 기반으로 한 다음 턴 예측에 기반하여 쿼리 형성.

- **응답 예측 모델**:
  - 계층적 대화 모델 및 변환기 기반.
  - 사용자 대화 이력과 현재 대화 맥락을 효율적으로 처리.

- **입력 및 임베딩**:
  - 과거 대화 턴을 결합하고 RoBERTa 모델로 인코딩 후 고정 길이 표현 생성.
  - 위치 임베딩 $$p_1$$과 발화 유형 임베딩 $$y_c$$ 추가.
  - 다음 단계로 넘어가기 위한 입력 형태:
    - $$ e_{ct} = \text{mean}(\text{RoBERTa}(c_t)) + p_t + y_c $$
    - $$ e_{rt} = \text{mean}(\text{RoBERTa}(r_t)) + p_t + y_r $$

- **훈련 과정**:
  - 발화 수준 임베딩을 생성하여 변환기에 제공.
  - ground truth 응답 표현을 예측하고 최소화 목표:
    - $$ L = \sum_{t=1}^{T} (1 - \frac{h_{rt} \cdot g_{rt}}{|h_{rt}||g_{rt}|}) $$

- **다양한 표현 방식**:
  - 스타일 표현 및 의미 표현 고려.
  - 스타일 표현: 비내용 독립 모델로 이력 인코딩.
  - 의미 표현: 문장 변환기를 통해 인코딩.

- **검색 과정**:
  - 생성될 응답의 스타일 및 의미 표현 예측 후 가장 유사한 응답 검색.
  - 검색된 응답은 이후 맥락 인식 접두어 인코더로 전달.

---

# 2.4 Context-Aware Prefix Encoder (CAP)

- CAP 모듈의 목적
  - RE로부터 검색된 역사적 응답을 고정 길이의 프리픽스 벡터로 변환.
  - 이 벡터는 변환기 디코더의 히든 상태에 프리픽스로 추가됨.

- 아키텍처 개요
  - 현재 대화 맥락과 검색된 응답을 RoBERTa 인코더로 연속 표현으로 인코딩.
  
- 수식
  - 현재 맥락 인코딩: 
    $$C = \text{RoBERTa}(c)$$
  - i번째 역사적 응답 인코딩: 
    $$H_i = \text{RoBERTa}(h_i) + q_i$$
  
- 벡터 시퀀스 생성
  - 모든 $$H_i$$를 긴 벡터 시퀀스 $$H = [H_1; \cdots; H_{t-1}]$$로 연결.

- 크로스-어텐션 프로젝션
  - CAP는 긴 벡터 시퀀스 $$H$$를 짧고 고정된 길이의 프리픽스로 변환하기 위해 두 개의 크로스-어텐션 작업을 수행.
  - 첫 번째 어텐션: 
    $$P_c = \text{Attn}(E,C,C)$$
  - 두 번째 어텐션: 
    $$P_h = \text{Attn}(P_c,H,H)$$

- 최종 프로젝션
  - $$P_h$$는 선형 레이어를 통해 $$R^{LNd}$$로 변환.
  - 이후, 각 시퀀스는 변환기 디코더의 대응 레이어의 히든 상태에 추가됨.

---

# 2.5 Generator

- 사전 훈련된 DialoGPT (Zhang et al., 2020b)를 생성기로 사용함.
- 개인화된 정보는 CAP에 의해 인코딩된 prefix 벡터를 통해 생성 과정에 융합됨.
- DialoGPT의 매개변수와 CAP 모듈을 함께 훈련하여 다음의 목적 함수를 최대화함: 
  $$\text{maximize} \; \log(\text{Objective})$$.

---

# 3.1 Dataset

- **데이터셋 출처**: Reddit의 personalized 대화 데이터셋, pushshift.io에서 추출 (Baumgartner et al., 2020).
- **수집 기간**: 2019년 8월부터 2021년 6월까지의 대화만 선택하여 테스트 데이터 유출 방지.
- **샘플 구성**:
  - 사용자 이름
  - 대화 맥락 (이전 대화 내용)
  - 응답
- **사용자 선택**: 총 샘플 수가 많아 115,000명의 사용자 랜덤 선택.
- **샘플 수 제한**:
  - 각 선택된 사용자에 대해 가장 최근 10개의 샘플은 생성기 훈련에 사용.
  - 가장 최근 100개의 샘플은 이전 대화로 활용.
- **데이터 분할 방식**:
  - 기존 작업들과 다르게 같은 사용자를 훈련, 검증, 테스트에 사용하지 않음.
  - 사용자 기준으로 데이터셋을 분할하여 모델의 일반화 능력 평가.
- **훈련/검증/테스트 사용자 수**:
  - 훈련: 100,000명
  - 검증: 5,000명
  - 테스트: 10,000명

---

# 3.2 Baseline Models

- 모델 비교 대상:
  - 총 4개의 기본 모델과 비교, 최신 개인화 대화 모델 포함.
  
- **DialoGPT**:
  - 대규모 사전 훈련된 대화 응답 생성 모델.
  - Reddit 대화 내용으로 훈련됨 (Zhang et al., 2020b).
  
- **DialoGPT w/ history responses**:
  - DialoGPT 입력(대화 맥락)에 검색된 이전 응답을 직접 추가.
  
- **DHAP**:
  - 개인화된 응답을 생성하는 모델로, 사용자 역사 대화로부터 동적 문맥 인지 사용자 프로필 표현을 구축.
  - 개인화된 디코더와 복사 메커니즘 사용 (Ma et al., 2021b).
  - 공정한 비교를 위해 DHAP에 사전 훈련된 변환기 추가.
  
- **MSP**:
  - 최신 개인화 대화 모델.
  - 선택된 토큰을 DialoGPT 입력 앞에 추가하여 개인화된 응답 생성.
  - 토큰은 3단계 계층 정제기를 통해 선택됨 (Zhong et al., 2022).

---

# 3.3 Implementation Details

- **기반**: HuggingFace의 Transformers와 Sentence Transformer 코드베이스 사용
- **실험 설정**: 다양한 하이퍼파라미터를 실험하고 최적의 설정만 논의
- **모델 초기화**:
  - **인코더**: 사전 훈련된 RoBERTa-base 모델에서 초기화
  - **디코더**: 사전 훈련된 DialoGPT-small 모델에서 초기화
- **파라미터**:
  - RoBERTa의 임베딩 차원: $$d = 768$$
  - 프리픽스 길이 $$N = 30$$ (MSP와 일치)
- **프로젝션 주의**: CAP의 두 가지 주의 모듈은 모두 단일 헤드 주의
- **역사 응답 수**: 10개
  - 검색 모듈 없이 사용하는 모델(DialoGPT + history, DHAP, CAP): 10개의 최신 역사 응답 사용
- **발화 수준 트랜스포머**: 
  - 숨겨진 차원: $$768$$
  - 층 수: 6
  - 각 층의 자가 주의: 12 헤드
- **훈련**:
  - 옵티마이저: AdamW
  - 학습률: $$5 \times 10^{-5}$$
  - 학습률 스케줄: 선형, 10 에폭
  - 검증당 퍼플렉서티 기반으로 최상의 모델 선택
- **생성**: 
  - Nucleus (top-p) 샘플링 사용, $$p = 0.8$$
  
| 모델                           | 파라미터 수 | 훈련 시간 (시간) |
|------------------------------|--------------|------------------|
| DialoGPT                     | 124M         | 8                |
| DialoGPT + history           | 124M         | 37               |
| DHAP                         | 431M         | 25               |
| MSP                          | 437M         | 15               |
| RE                           | 198M         | 13               |
| CAP                          | 269M         | 22               |

- **훈련 환경**: 모든 모델은 2× A40 GPU에서 반 정밀도로 훈련됨
- **표**: 총 파라미터 수와 훈련 시간은 표로 요약

---

# 3.4 Evaluation Metrics

- **자동 평가**
  - 모델 성능 평가를 위한 자동화된 지표를 4개 카테고리로 그룹화
  - 전반적인 성능 측정:
    - **Perplexity**: 모델이 샘플을 얼마나 잘 예측하는지 평가, 낮을수록 유창한 응답 생성
    - **Token-overlap 지표**: BLEU-1, BLEU-2, ROUGE-L, METEOR 사용, 높은 점수가 참조 텍스트와 높은 유사성을 의미

- **학습 기반 지표**
  - 사전 학습된 모델을 이용한 지표로, 사람의 판단과 잘 일치
  - BERTScore와 BLEURT 선택, 높은 점수는 높은 유사성을 나타냄

- **스타일 지표**
  - 개인의 글쓰기 스타일 포착 능력 평가
  - 두 가지 메트릭스:
    1. **임베딩 유사도**: 생성된 응답과 실제 응답의 코사인 유사도
    2. **대조 저자 검증(CAV) 정확도**: 생성 반응과 긍정/부정 실제 응답 간의 유사성을 판단

- **개인 특성 지표**
  - 개인 특성을 반영한 응답 모델 평가
  - 사용된 특성: 나이, 성별, MBTI
  - 각 특성에 대해 PANDORA 데이터셋을 기반으로 분류기 훈련
  - 높은 점수는 더 좋은 개인화된 모델을 나타냄

- **수동 평가**
  - 테스트 세트에서 100개 샘플을 랜덤하게 추출하여 수동 평가 실시
  - 두 명의 자원 봉사자가 다음 기준으로 평가:
    - **유창성**: 응답이 읽기 좋고 유창한지 평가
    - **일관성**: 대화의 연속성을 평가
    - **퍼소나 일관성**: 이전 텍스트가 해당 작가의 글처럼 보이는지 평가

각 기준은 1에서 3까지의 척도로 평가됨.

---

# 4 Results

- 실험 결과와 추가 분석을 논의함
- 제한된 시간과 계산 자원으로 인해 단일 실행 결과만 보고함
- 통계적 유의성 검정을 실행함

---

# 4.1 Automatic Evaluation Results

- **테이블 3**: 선택된 메트릭에 대한 모든 모델의 자동 평가 결과를 보여줌.
  - 유사한 메트릭에 대해 대표적 또는 집계된 메트릭만 표시
  - 전체 결과는 부록 C에 있으며, 대체로 테이블 3의 대표 결과와 일치함.

- **모델 성능**:
  - 대부분의 경우, 모든 자동 메트릭에서 상위 두 결과는 우리의 모델에 해당.
  - 리트리버 없이도 CAP 모델은 대부분의 자동 메트릭에서 기준 모델을 초과하는 성능을 보임.

- **리트리버 향상**:
  - RECAP 모델은 대부분의 자동 메트릭에서 더 나은 점수를 기록함.
  - 스타일 리트리버 향상을 통해:
    - 더 나은 스타일 임베딩 유사도
    - CA V 정확도
    - 평균 MBTI F1 점수 달성
    - 이는 목표 저자의 글쓰기 스타일을 보다 잘 반영한 것임.

- **의미적 리트리버 향상**:
  - RECAP 모델은 토큰 중복 메트릭과 학습 기반 메트릭에서 최고의 점수 달성
  - 이는 생성한 응답이 실제 정답과 더 유사함을 나타냄.

- **혼합 모델**:
  - 두 가지 향상 방법을 결합하여 각 리트리버로부터 절반의 이력 응답을 혼합함.
  - 두 RECAP 모델의 장점을 혼합했으나, 개선 효과가 약화됨.
  - 그럼에도 불구하고, RECAPmixed 모델은 Reddit 데이터셋의 모든 메트릭에서 최소 두 번째로 좋은 성능을 보임.

---

# 4.2 Human Evaluation Results

- 표 4는 인간 평가 결과를 보여줌.
- 두 평가자 간의 상관관계:
  - Cohen's κ: $$\kappa = 0.617$$ (상당한 합의)
  - Krippendorff's α: $$\alpha = 0.687$$ (임시 결론 도출 가능)
- 경미한 불일치가 있긴 하지만, 두 평가자와 자동 평가 결과는 Reddit 데이터셋에서 다음과 같은 모델들에 대해 일치:
  - 일반 응답 품질 상위 모델: 
    - RECAP-semantic
    - RECAP-mixed
  - 스타일/페르소나 메트릭 상위 모델:
    - RECAP-style
    - RECAP-mixed
- RECAP-mixed는 인간 평가에서 전반적으로 두 번째로 우수한 모델.

---

# 4.3 Style Consistency Analysis

- **모델 성능 평가**
  - 자동 및 인간 메트릭들은 모델 성능에 대한 일반적인 아이디어를 제공하지만, 해석하기 어렵고 명확하지 않음.

- **스타일 일관성 이해를 위한 사례 분석**
  - Wegmann et al. (2022)의 방법을 바탕으로 작성 스타일의 몇 가지 측면을 점검.
  - 선택한 세 가지 측면:
    - **마지막 문장부호**: 응답이 문장부호로 끝나는지 여부.
    - **축약형 철자**: “didn’t”와 같은 축약형에서 “n’t” 또는 “nt”의 사용 여부.
    - **대문자 사용**: 응답이 모두 소문자인지 여부.

- **응답 스타일 일치율 계산**
  - 생성된 응답이 실제 스타일과 일치하는 비율 계산.
  - **결과**:
    - 대부분 모델들이 기준 모델보다 세 가지 선택된 측면을 더 효과적으로 포착.
    - 유일한 예외는 RECAP-style 모델로, 마지막 문장부호와 대문자 사용 측면에서 DialoGPT + history 모델보다 약간 떨어짐.

- **테이블 요약**
  - 자동 평가 결과 및 인간 평가 결과를 기반으로 모델 비교.
  - 가장 우수한 결과의 모델은 굵게 표시되고, 두 번째로 우수한 결과는 밑줄로 표시됨.
  - 통계적 유의성은 p<0.05 기준으로 나타냄. 

- **결론**
  - 스타일 일관성 분석을 통해 다양한 모델의 글쓰기 스타일 캡처 능력 검토.

---

# 5 Related Work

- **개인화된 응답 생성 연구**는 주로 세 가지 범주로 나뉨:
  1. 사용자의 특정 임베딩을 사용해 응답을 개인화하는 방법 (예: Li et al., 2016; Chan et al., 2019)
  2. 명시적인 사용자 프로필이나 인물 설명 문장을 사용해 응답을 개인화하는 방법 (Zhang et al., 2018; Zheng et al., 2019; Song et al., 2019, 2021)
  3. 사용자 역사 대화를 통해 추출한 암묵적 사용자 인물을 사용해 응답을 개인화하는 방법 (Bak and Oh, 2019; Wu et al., 2021; Ma et al., 2021b; Zhong et al., 2022)

- **사용자 특정 임베딩**은 효과가 낮고 새로운 사용자에게는 일반화하기 어려움. 
- **명시적 사용자 프로필**은 수동 데이터 수집이 필요해 실제로 확장하기 어려움.
- 최근 연구 (Ma et al., 2021b; Zhong et al., 2022)는 암묵적 사용자 인물 기반 방법의 강력한 확장성과 견고성을 보여줌.

- **최신 암묵적 사용자 인물 방법 MSP**는 다음과 같은 절차를 따름:
  1. 유사한 8411 사용자의 과거 응답 중 정보가 많은 토큰 선택
  2. 선택된 토큰을 변환기 디코더 입력에 촉발로 추가하여 생성 과정을 개인화

- **MSP의 한계**
  - 훈련 데이터가 뉴스 데이터셋으로, 대화 작업에서 최적의 검색 성능을 보장하지 못함.
  - 이산적인 토큰 선택 모듈은 연속적인 프롬프트/프리픽스를 사용함으로써 개선될 가능성 존재.

- **개발한 모델** 
  - 모든 사용자 역사 대화를 사용할 수 있는 개인화된 검색 모델
  - Li와 Liang (2021), Liu et al. (2022)의 접두사 메커니즘을 기반으로 한 개인화된 생성기 개발
  - 프리픽스를 훈련하는 대신, 사용자의 역사 응답으로 동적으로 개인화된 접두사를 인코딩하는 프리픽스 인코더를 훈련

- **우리 모델과 MSP의 차이점** 
  1. 대화 도메인에서 훈련된 개인화된 응답 검색기를 사용
  2. 이산적인 토큰 프롬프트 대신 동적으로 인코딩된 연속적인 접두사 사용

- **계층적 변환기** 
  - 긴 문서를 모델링하기 위해 문장 수준 변환기와 일반적인 토큰 수준 변환기 결합
  - 문서의 모든 문장 임베딩 벡터를 연결하여 문장 수준 변환기에 입력으로 제공
  - 긴 텍스트 분류 및 요약 작업에 효과적 (Pappagari et al., 2019; Zhang et al., 2019)
  
- **우리 검색 모듈**은 발화 수준 임베딩 예측을 위한 계층적 변환기 사용, 하지만 작업 및 훈련 전략에서 차별화됨.
- 검색 모듈은 생성적 다음 응답 예측 작업에 대해 발화 수준 인과 마스크로 훈련됨.

---

# 6 Conclusion

- **RECAP 소개**: 
  - 개인화된 대화 모델로, 응답 생성을 검색 증강 방식으로 수행.
  - 계층적 트랜스포머 검색기가 사용자 역사 응답을 활용하여 개인화된 검색을 수행.

- **정보 융합**: 
  - 컨텍스트 인식 인코더가 검색된 응답의 유용한 정보를 인코딩하고 이를 정규 트랜스포머 디코더와 융합.

- **실험 성과**: 
  - 모델이 유창하고 일관된 개인화된 응답 생성이 가능함을 입증.

- **윤리적 문제**: 
  - 대규모 데이터 셋(Pushshift Reddit 데이터) 사용, 편향적 및 공격적 내용 포함 가능성.
  - 비윤리적 응답 방지를 위해 필터링 권장.
  - 개인적인 용도로만 응답 생성 의도, 악의적 사용 가능성 인지.

- **데이터 보호 제안**: 
  - 개인 데이터는 로컬로 저장, 여러 작성자의 대화 기록 활용 시 개인 정보 노출 위험 감소.

- **한계점**: 
  - 계층적 트랜스포머 검색기가 소규모 데이터로 훈련되어 성능 제한.
  - 서로 다른 유형의 응답을 동일하게 인코딩하여 생성 성능 저하 가능성.
  - 향후 연구에서는 서로 다른 인코더 설계로 성능 향상 가능성 제시.

- **지지 및 감사**: 
  - 이 연구는 ODNI 및 DARPA에서 지원받음. 
  - 저자 의견이 정부 공식 정책을 대변하지 않음을 명시.

---

# 7 Ethical Issues

- **초록 및 서론 요약**:   
  - 초록과 1장 서론에서 주요 주장 요약.
  
- **AI 작성 도구 사용**:   
  - 본 연구에 AI 작성 도구 사용 여부는 언급되지 않음.

- **과학적 아티팩트 사용**:  
  - 부록 B에 사용 및 생성한 과학적 아티팩트 요약.

- **아티팩트의 저자 인용**:  
  - 각 아티팩트의 첫 번째 발생 시 해당 저자 인용.

- **아티팩트 사용 조건 논의**:  
  - 부록 B에서 사용 조건 및 라이센스 논의.

- **기존 아티팩트 사용의 일관성**:  
  - 원본 접근 조건과의 호환성 여부를 특정. 연구 목적으로 접근된 데이터의 파생물 사용 금지.

- **데이터 수집 및 개인 정보 보호**:  
  - 본 연구는 데이터 수집을 하지 않았으며, 두 개의 기존 데이터셋 사용. 데이터 수집 관련 세부사항은 해당 문헌 참조. 개인화 및 개인 필체 보존 위해 추가 익명화 또는 필터링 없음.

- **아티팩트 문서화 제공**:  
  - 각 아티팩트의 첫 번째 발생 시 문서화 링크 또는 GitHub 링크 제공.

- **통계적 보고**:  
  - 데이터의 예시 수, 훈련/검증/테스트 분할 및 관련 통계 보고, 섹션 3.1 및 3.4.1 참조.

- **계산 실험 수행**:  
  - 섹션 3 및 부록 A에 실험 세부정보 포함.

- **모델 및 예산 보고**:  
  - 부록 A에서 모델의 파라미터 수, 계산 예산 및 인프라 언급.

- **실험 설정 논의**:  
  - 섹션 3.3 및 부록 A에서 하이퍼파라미터 검색 및 최상의 값 논의.

- **결과의 통계적 설명**:  
  - 섹션 4에서 결과 통계, 오차 범위 및 요약 통계 보고.

- **기존 패키지 사용**:  
  - 섹션 3.3 및 부록 A에서 구현, 모델 및 파라미터 설정 보고.

- **인간 평가 사용**:  
  - 섹션 3.4.2 및 4.2에서 수작업 평가 및 인간 평가 결과 논의.

- **참가자 수명 안내**:  
  - 섹션 3.4.2 및 4.2에서 참여자에게 제공된 전체 텍스트 및 지침 보고.

- **참여자 모집 및 보상 정보**:  
  - 섹션 3.4.2에서 자원 봉사자의 보상 내용 논의하지 않음.

- **데이터 사용을 위한 동의 확보**:  
  - 데이터 수집 없이 평가를 위한 주석자만 사용.

- **윤리 검토 승인**:  
  - 수집된 대화 데이터는 타사에서 이전에 수집된 것. 주석을 위한 프로토콜이 윤리 검토 위원회에서 승인됨.

- **주석자 인구통계학적 특성**:  
  - 데이터 수집하지 않았으며, 내부 주석자 설명만 포함.

---

# Limitations

- 계층적 변환기 검색기의 성능은 제한적임
  - 발화 수준 변환기가 작은 규모의 데이터셋에서 처음부터 훈련됨
  - 제한된 시간 및 계산 자원으로 인해 더 큰 데이터셋에 대한 사전 훈련 부족
  - 큰 데이터셋(예: 전체 Pushshift Reddit 데이터)으로 사전 훈련 시 성능 향상 가능성 있음

- RECAP-mixed 모델에서 두 가지 유형의 검색된 응답이 동일한 인코더로 인코딩됨
  - 두 가지 응답은 생성에 서로 다른 방식으로 기여해야 함
  - 동일한 방식으로 처리할 경우 생성 성능 저하 가능성
  - RECAP-mixed 모델은 두 가지 검색된 응답으로부터 개선되지만, 별개 모델보다 향상이 약함

- 향후 연구 방향
  - 다양한 유형의 검색된 응답을 위한 분리 인코더 설계 필요
  - 이를 통해 성능 향상을 극대화할 수 있음

---

# Acknowledgements

- 이 연구는 다음의 기관들에 의해 지원받음:
  - 국가정보국(ODNI)
  - 고급 정보 연구 프로젝트 활동(IARPA)
    - HIATUS 프로그램 계약 #2022-22072200006
  - DARPA
    - 계약 #HR001121C0169 및 #HR00112290025

- 본 연구의 견해와 결론은 저자들의 것임.
- 이 내용은 ODNI, IARPA 또는 미국 정부의 공식 정책을 반드시 반영하는 것으로 해석되지 않음.
  
- 미국 정부는 저작권 주석이 있더라도 정부 목적을 위한 재판 인쇄본을 복제하고 배포할 권리가 있음.
- 공개 발표승인을 받았으며, 배포는 무제한임.