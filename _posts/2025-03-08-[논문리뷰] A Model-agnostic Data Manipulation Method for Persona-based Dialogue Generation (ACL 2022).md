---
title: "[논문리뷰] A Model-agnostic Data Manipulation Method for Persona-based Dialogue Generation (ACL 2022)"
date: 2025-03-08 00:00:00 +0900
categories:
  - Paper Review
tags:
  - NLP
  - ACL 2022
  - Persona-based Dialogue
---

요약: 이 논문은 대화 생성 모델에 개인화를 도입하기 위한 데이터 문제를 해결하기 위해, 효율적인 데이터 조작 방법을 제안하고, 이를 통해 생성 모델의 성능을 향상시키는 방법을 탐구한다.

---

# 1 Introduction

- 대화 에이전트를 구축하려면 일관성 있는 페르소나로 응답을 생성하는 능력이 중요함.
- 최근 몇 년 동안 대화 생성 모델에 명시적인 페르소나를 도입하는 것에 대한 관심이 증가함 (Song et al., 2019; Wolf et al., 2019).
- 페르소나는 일반적으로 프로필과 개인 배경 사실로 구성된 텍스트.
- PersonaChat 데이터셋에서의 페르소나 기반 대화의 예시가 제공됨.
- 페르소나 기반 대화 생성 모델에서 생성된 응답은 대화 맥락과 페르소나와 일관성이 있어야 함.
- 기존의 대화 생성 모델은 충분한 페르소나 기반 대화로 훈련하는 데 의존하고 있으나, 데이터 수집 비용이 높은 상태로 데이터를 확보하기 어려움.
- PersonaChat 예시에는 약 162,000개의 대화 발화가 있으며 5,000개 미만의 고유 페르소나 프로필만 존재.
- 페르소나 기반 대화는 복잡하여 일반 대화 데이터보다 학습하기 어려움.
- Welleck et al. (2019)에 따르면 PersonaChat 데이터셋의 모든 응답이 제공된 페르소나와 일관되지 않음.
- 기존의 데이터 증강 방법을 사용하여 복잡한 페르소나 기반 대화 데이터를 자동으로 생성하는 것이 어려움.
- 몇몇 연구는 GPT나 BERT와 같은 사전 훈련된 모델을 미세 조정하여 데이터 문제를 완화하려고 시도함.
- 그러나 이들은 특정 모델에 국한되며, 데이터의 어려움 문제를 직접적으로 해결하지 않음.
- 본 연구에서는 데이터 규모와 어려움 문제를 해결하기 위한 모델 독립적인 방법을 설계하고자 함.
- 제안하는 데이터 조작 방법 (D3):
  1. 데이터 증류: 원래의 훈련 샘플을 유용하고 중복이 적은 페르소나 문장과 대화 발화로 단순화.
  2. 데이터 다양화: 더 쉬운 증류 샘플로부터 데이터 증강을 수행하여 데이터 다양성 향상.
  3. 데이터 커리큘럼: 증강된 증류 데이터와 원본 데이터를 정리하여 모델 학습을 위해 순서대로 제공.
- 제안된 방법의 유효성을 검증하기 위해 두 가지 강력한 기본 대화 모델(Transformer 기반 인코더-디코더 및 GPT2)에서 실험을 수행함.

---

# 2 Related Work

- 페르소나 기반 대화 생성에 대한 관심이 증가하고 있음
  - PersonaChat/ConvAI2와 같은 벤치마크 데이터셋 출시 덕분
- 이전 연구들은 대화 모델을 수정하여 보조 페르소나 정보를 조건화하는 데 집중
  - 추가 페르소나 임베딩 (Li et al., 2016b)
  - 프로파일 메모리 (Zhang et al., 2018a)
  - 페르소나에서 복사하기 (Yavuz et al., 2019)
  - 페르소나 정보를 포함한 CV AE (Song et al., 2019)
  - 저자원 페르소나를 증강하기 위해 메타-학습 사용 (Tian et al., 2021)
- 최근 연구들은 대규모 사전 훈련 모델을 이 작업에 적용
  - GPT/GPT2 (Radford et al., 2018, 2019) 사용
  - 다양한 파인튜닝 전략을 통해 생성 품질 개선 (Wolf et al., 2019)
  - BERT도 일부 연구에서 백본으로 활용됨 (Song et al., 2021)
- 이러한 방법들은 일반적으로 적절한 네트워크 수정 및 손실 함수 파인튜닝이 필요
  - 다양한 사전 훈련 모델에 적용하기 어렵고, 대부분 페르소나 텍스트와 대화 이력을 단일 입력 시퀀스로 결합함 (Wolf et al., 2019)
- 텍스트 데이터 조작
  - 다양한 데이터 증강 방법이 많은 NLP 작업에서 사용됨 (Sennrich et al., 2016)
  - 새로운 대화 발화와 검색 결과를 훈련 데이터 증강에 활용 가능
  - 이전 연구들은 쿼리와 응답 간의 쌍 관계만 연구하며, 페르소나와 같은 보조 정보를 포함한 기술들은 개발되지 않음
- 데이터 품질 향상을 위한 샘플 필터링 방법도 존재
  - 몇 가지 접근 방식이 비정보적이거나 노이즈 샘플을 필터링 (Csáky et al., 2019)
  - 데이터 증강과 재가중치를 결합하여 모델 학습 효과를 높이는 방법도 (Cai et al., 2020a)
- 커리큘럼 학습
  - 모델을 쉬운 것에서 어려운 것으로 순차적으로 교육하는 방법이 효과적임 (Bengio et al., 2009)
  - 기계 번역, 독해, 언어 이해 등 다양한 NLP 작업에 적용됨
  - Cai et al. (2020b)는 공개 도메인 대화 생성에 커리큘럼 개념을 적용
- 본 연구의 차별점: 새로운 증류 데이터를 커리큘럼으로 도입함

---

# 3 Our Data Manipulation Method

- **훈련 샘플 정의**
  - 페르소나 설명 문장 L (P), 대화 기록 H (M), 정답 R으로 구성
  - 훈련 데이터셋 D = {(P, H, R)}로 표기

- **데이터 조작 방법 D3**
  - 모든 대화 모델에 적용 가능 (모델 자체는 변경하지 않음)
  - 세 가지 데이터 조작 작업 개발:
    1. **데이터 증류**: 불필요한 정보 제거하여 간단한 페르소나 일관성 데이터 Ddis = {( ˜P, ˜H, ˜R)} 생성
    2. **데이터 다양화**: 다양한 방법으로 데이터의 다양성과 규모 증가시켜 Ddiv = {(˜p,˜h,˜r)} 생성
    3. **데이터 커리큘럼**: Ddis와 Ddiv를 결합하여 강화된 데이터셋 Da 생성 후, 난이도에 따라 학습 진행

- **3.1 데이터 증류**
  - 원본 훈련 샘플의 난이도 논의
  - 반응과 페르소나 문장 간의 의존성이 다름
  - 주목 기반 모델이 잡음에 의해 방해받을 수 있음
  - 페르소나 증류: 각 페르소나 문장과 목표 반응 R 간의 일관성 평가 (자연어 추론 문제 사용)
  - 대화 역사 증류: 훈련된 주목 기반 모델 사용, 마지막 대화 발화 유지

- **3.2 데이터 다양화**
  - 증류된 샘플의 규모와 다양성 증대 필요
  - **페르소나 편집**:
    - 토큰 및 구문 레벨 수정 방법 사용
  - **반응 정렬**: 수정된 페르소나에 맞게 새로운 반응 ˜r 생성
  - **대화 역사 증강**: 백번역 방법을 사용하여 대화 발화 다양한 변형 생성

- **3.3 데이터 커리큘럼**
  - 모델이 원본 데이터와 다수의 페르소나 문장 및 대화 역사 발화를 처리할 수 있도록 함
  - 강화된 데이터 Da와 원본 데이터 D를 비슷한 비율로 혼합하지 않고, 난이도에 따라 학습시킴 (Da를 쉬운 커리큘럼, D를 어려운 커리큘럼으로 처리)

- **통계 데이터**
  - 각 단계에서 샘플, 페르소나 및 토큰 개수 통계 제공

---

# 4 Experiments

- 제안된 모델 불문 데이터 조작 방법의 효과성을 검증하기 위해, 다음의 단계로 실험 진행:
  - PersonaChat 데이터셋을 사용하여 두 강력한 인물 기반 대화 생성 모델(Transformer 인코더-디코더 및 GPT2) 실험.
  - 데이터 조작 작업의 유용성을 분석하기 위한 일련의 분석 수행.

## 4.1 실험 설정
- **데이터셋**: PersonaChat은 각 샘플이 최대 15회화 히스토리와 4-6문장의 개인적 특성을 가지고 있음.
- **기본 모델**:
  - **TRANSFORMER**: 인코더-디코더 아키텍처, 포인터 생성기 통합.
  - **GPT2**: 이 작업에서 가장 강력한 사전 훈련 모델 중 하나.
- **비교 방법**:
  - **역 번역(BT)**: 모든 문장에 대해 역 번역 수행 후 원본 데이터와 함께 훈련.
  - **조건부 변분 오토인코더(CVAE)**: 원본 데이터로 훈련 후 새로운 응답 생성을 위한 샘플링.
  - **엔트로피 필터(Filter)**: 일반적인 응답을 제거.

## 4.2 결과
- 두 기본 모델에 대한 다양한 데이터 조작 방법에 대한 결과를 테이블로 보고.
- D3 방법이 인간 평가에서 다른 방법들에 비해 유의미하게 더 우수한 성능을 발휘.

## 4.3 추가 분석
- 다음 세 가지 질문에 대한 분석:
  1. 데이터 증류(Ddis)의 필요성.
  2. 데이터 다양화가 다양한 증류 데이터를 효과적으로 얻는지.
  3. 커리큘럼 전략이 증강 데이터를 더 잘 활용하는지.
- **데이터 증류 분석**:
  - 데이터 다양화를 없애면 성능이 감소하며, 증류가 효과적임을 확인.
- **데이터 다양화 분석**:
  - 다양화된 데이터가 많은 새로운 개인적 문장을 포함.
  - 모든 부분에서 성능에 기여, 특히 응답 필터링이 중요.
- **데이터 커리큘럼 분석**:
  - 다양한 커리큘럼 변형과의 성능 비교.
  - 우리의 커리큘럼이 모든 측면에서 우수함을 나타냄.
  - 토큰 및 문장 수준의 일관된 주의 가중치를 측정하여 개인적 특성 반영.

## 결론
- 연구는 인물 기반 대화 생성 과제의 도전 과제를 다루며, 데이터의 양과 다양성이 부족한 상황에서 데이터 조작 방법을 제안.
- 실험 결과, 제안된 방법이 Transformer 인코더-디코더와 GPT2를 효과적으로 개선함을 입증.

---

# 독자 의견

- 본 논문은 대화 생성 모델에 페르소나를 도입하는 데 있어 데이터 양과 다양성의 중요성을 강조하고 있음.
- 다양한 데이터 조작 방법을 통해 모델의 성능을 향상시킬 수 있음을 실험적으로 입증하였음.
- 특히, 데이터 증류, 데이터 다양화, 데이터 커리큘럼이 모델 성능 향상에 어떤 영향을 미치는지 분석한 점이 흥미로웠음.
- 현재 Test Time이 중요한 LLM 분야에 적용할 수 있는 데이터 메니퓰레이션 방법론을 제시할 필요가 있음.