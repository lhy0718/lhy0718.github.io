---
title: "[논문리뷰] Evaluating Intention Detection Capability of Large Language Models in Persuasive Dialogues (ACL 2024)"
date: 2025-03-05 00:00:00 +0900
categories:
  - Paper Review
tags:
  - NLP
  - ACL 2024
  - Persona-based Dialogue

---

Abstract: 본 연구는 대화의 맥락을 고려하여 설득적 다중 턴 대화에서 의도 탐지를 평가하기 위해 기존 데이터셋을 수정하고 새로운 데이터셋을 생성하여 대형 언어 모델(LLM)의 성능을 분석합니다.

---

# 1 Introduction

- 화자 의도를 파악하는 것은 원활한 대화를 유지하는데 필수적임
  - 예시: 앨리스가 밥에게 특정 자선단체에 기부를 요청했을 때, 밥이 회피적인 대답을 하면 기부 의사가 없음을 추측할 수 있음
  - 응답을 통해 뚜렷한 거절을 피하고 싶은 경우도 있음

- 대화 중 화자의 의도는 명시적으로 말하지 않고도 전달될 수 있으며, 상황에 따라 달라짐
  - 사람들은 대화 중 화자의 의도를 무의식적으로 추정하며 이는 자연스러운 소통에 필수적임

- 최근 LLM(대규모 언어 모델) 발전
  - 예: ChatGPT, GPT-4 등의 개발로 자연어로 사람과 같은 소통 가능해짐
  - LLM을 활용한 대화 시스템 연구 및 개발이 활발히 진행됨

- LLM이 대화 중 화자의 의도를 효과적으로 감지할 수 있다고 가정
  - GLUE와 같은 데이터셋이 LLM의 자연어 이해력을 평가하는 데 사용됨

- 그러나 LLM의 화자 의도 감지 능력 탐구에 대한 연구는 부족함

- 연구 목표:
  - 설득 대화에서 LLM의 의도 감지 능력을 측정하기 위한 데이터셋 구축
  - 데이터셋은 대화 중 화자의 의도를 파악하는 다중 선택 질문 포함
  - 대화의 맥락을 고려해야 하며, 감정에 영향을 미치는 발언의 중요성 강조
  
- 데이터셋 구축 시 인간 관계와 관련된 '페이스(face)' 개념 사용
  - 화자의 발언이 상대방의 감정에 미치는 영향을 측정하는데 중점
  
- 연구의 두 가지 기여:
  1. 설득 대화에서 의도 감지 능력을 측정하기 위한 데이터셋 구축
  2. 최신 LLM인 GPT-4와 ChatGPT의 발언 의도 감지 성능 평가 및 오류 분석 제공

---

# 2 Background

- 이 섹션에서는 얼굴과 얼굴 행위(face acts) 및 연구에 사용된 기존 대화 데이터를 설명합니다.
- 그 후, 대화 이해 및 의도 탐지에 관한 이전 연구를 논의합니다.

---

# 2.1 Face and Face Acts

- **Face의 개념**:
  - Face는 인간관계에서 기본적인 필요를 나타내는 개념.
  - Goffman (1967)에서 소개됨.
  - Brown과 Levinson은 politeness theory를 통해 face의 개념을 적용하고, 정중함 전략을 체계화함 (Brown et al., 1987).

- **Face의 두 가지 범주**:
  - **Positive Face**: 다른 사람에게 인정받고, 칭찬받고, 좋아지길 원하는 욕구.
  - **Negative Face**: 다른 사람이 자신의 자유나 영역을 침해하지 않기를 원하는 욕구.

- **Face에 영향을 미치는 발화**:
  - 일상 대화에서 특정 발화는 타인의 face에 다양한 방식으로 영향을 줌.
  - 예: 요청하는 발화는 타인의 시간을 빼앗아, 타인의 negative face를 위협함.

- **Face Acts와 Face Threatening Acts(FTA)**:
  - 자신이나 타인의 face에 영향을 주는 발화를 "Face acts"라고 함.
  - face를 공격하는 행위는 "Face Threatening Act(FTA)"라고 함.
  
- **Face Saving Acts (FSA)**:
  - 타인의 positive face를 칭찬하여 보호하거나, 요청으로 인한 부담을 완화하여 negative face를 보호하는 발화.

- **정중성 이론의 적용**:
  - 사람들은 관계를 관리하기 위해 가능하면 face를 공격하지 않으려 함.
  - face를 공격해야 할 때는 정중함 전략을 활용하여 공격의 위험을 감소시킴.

- **Dutt et al. (2020)의 연구**:
  - Face acts 개념을 설득 대화 분석에 적용.
  - face acts는 설득의 성공에 영향을 미치는 요소로 식별됨.
  - 대화 역동성을 추적하기 위해 기계 학습 모델 개발.
  - 상황에 따라 face acts를 다음의 세 가지 기준으로 8개의 범주로 나누었음:
    - 발화의 방향: 화자(speaker) 또는 청자(hearer) 지향 (s/h)
    - positive 또는 negative face 지향 여부 (pos/neg)
    - face가 보호되거나 공격되는지 (+/-)

- **설득 상황 예시**:

<img alt="image" src="https://github.com/user-attachments/assets/3c703e22-1f3d-4afa-84ad-cfc28bac9784" />

<img alt="image" src="https://github.com/user-attachments/assets/45f24366-85fd-4112-8327-f0d929ed95ef" />

  - 주장 변경을 요구하는 사람을 "persuader(ER)", 요구를 받는 사람을 "persuadee(EE)"로 표현.
  - 예: ER이 EE에게 무언가 요청할 때, 발화는 "hneg-"로 분류됨 (청자의 자유를 빼앗는 것).
  - ER이 자신의 주장 유효성을 보여줄 때, 발화는 "spos+"로 분류됨 (화자의 positive face를 방어하는 것).

---

# 2.2 Dataset Annotated with Face Acts

- 대표적인 영어 대화 데이터셋은 Dutt et al. (2020)에 의해 마련됨.
- 이 연구는 "Save the Children" (STC) 자선 기부에 관한 설득 대화에서 얼굴 행위(face acts)를 주석을 달음.
- 대화는 두 사람, 설득자(persuader, ER)와 설득당하는 사람(persuadee, EE) 간의 상호작용으로 구성됨.
- ER은 EE에게 STC에 기부할 것을 설득함.
- 데이터셋의 일부 대화 예시는 표로 제공됨.
- '기타(other)'로 분류된 발화는 인사, 필러 및 대화의 주요 주제와 관련 없는 발화 포함.
- 대화는 Wang et al. (2019)에서 처음 수집되었으며, Dutt et al. (2020)에서는 각 발화에 하나의 얼굴 행위만 부착됨.
- 한 발화에 두 개 이상의 얼굴 행위가 있을 수도 있지만, 이전 연구에서는 데이터셋의 2%만 해당됨.
- 따라서 가능한 얼굴 행위 중 하나를 무작위로 선택하여 금 표지(gold label)로 간주함.

---

# 2.3 Intention Detection

- **연구 배경**
  - 작업 지향 대화 시스템에서의 의도 탐지가 활발히 연구되고 있음.
  - 사용자가 발화를 통해 이루고자 하는 목표를 이해하거나 발화가 처리할 수 있는 도메인에 속하는지를 판단해야 함.

- **의도 탐지 작업 형식**
  - 주어진 라벨 세트에서 발화를 특정 의도 라벨로 분류하는 형식.
  - 일부 데이터셋은 여행(예: Hemphill et al., 1990) 또는 금융(예: Casanueva et al., 2020)과 같은 특정 응용 도메인에 초점을 맞춤.
  - 다른 데이터셋은 여러 도메인을 포함할 수 있음.

- **대표적인 데이터셋**
  - SNIPS 데이터셋이 대표적임.
  - GPT-2와 같은 대형 언어 모델(LLMs)이 의도 탐지 작업에서 높은 성능을 보임.
  - 기존 연구에서는 대화 맥락을 포함하지 않고 발화 자체에서 의도를 예측하는 모델들이 많음.

- **맥락 기반 의도 탐지 연구**
  - 일부 연구는 대화 맥락을 사용하는 의도 탐지를 다루고 있음.
    - Cui et al. (2020): 대화 이해 능력을 분석하기 위한 데이터셋 생성, 다음 발화 예측 작업을 채택.
    - 머신러닝 모델이 대화 맥락을 이해해야 논리적으로 일관된 다음 발화 선택 가능.
  
- **자세한 분석 미비**
  - 각 추론 능력에 대한 상세한 분석 수단은 탐구되지 않음. 

- **Dutt et al. (2020)의 연구**
  - 퍼스uasive 대화에서 발화의 의도를 예측할 때 대화 맥락을 통합할 수 있는 의도 탐지 모델 개발.
  - 특정 발화에서 얼굴 행위를 예측하도록 머신러닝 모델 학습.
  - LLM을 사용하지 않았으며, 다중 턴의 설득 대화에서 LLM이 의도를 얼마나 잘 탐지할 수 있는지는 여전히 불명확함.

---

# 3 Data

- 이전 연구에서는 의도 탐지를 위한 다중 턴 대화 데이터를 주로 적용하지 않았음.
- 의도 탐지 능력을 평가하기 위한 방법으로 Dutt et al. (2020)에서 생성된 설득적 대화 데이터셋을 활용할 수 있음.
  - 발화에서 얼굴 행위를 직접 예측하는 방법이 제안됨.
- 얼굴 행위는 추상적인 의도로, 직관적으로 다루기 어려움.
- 얼굴 행위는 LLM의 in-context learning에서 충분히 학습되지 않을 가능성이 높음.
- 이를 해결하기 위해 제로 샷이나 몇 샷 시나리오에서 적용 가능한 형식으로 수정이 필요함.
- 설득적 대화 데이터를 수정하여 의도 탐지 능력을 평가하기 위한 데이터셋 생성:
  - 얼굴 행위를 자연어로 작성된 의도 설명으로 변환하여 이해 가능하게 만듦.
- 데이터셋 구조:
  - 대화 이력과 마지막 발화에 대한 네 개의 의도 설명을 포함.
  - 출력은 네 가지 옵션 중 하나의 설명.
- 이 형식은 이전 대화 추론 연구에서 영감을 받은 독해 스타일로, LLM의 추론 능력 평가에 자주 사용됨.
- 평가 데이터셋 개발 목표:
  - 의도 탐지 능력 평가를 위한 데이터세트로, 설득적 대화 데이터셋을 8:1:1 비율로 분할하여 테스트 서브셋만 활용.
- 평가 데이터셋 개발 과정:
  1. 발화에 주석을 달 의도 설명 정의.
  2. 크라우드소싱을 통해 각 발화에 대한 설명 주석 작업.
  3. 네 가지 옵션을 생성하기 위한 세 개의 방해물 선택.

---

# 3.1 Preparation of Intention Description

- Dutt et al. (2020)는 설득 상황에서 발견된 여러 가지 의도 설명과 해당되는 얼굴 행위를 제시함.
- 이 설명들을 수정하고 확장하여 구체적인 발화에 맞게 주석을 달음.
- 모든 발화를 아우르는 새로운 설명을 고안함.
- 보다 광범위한 의도 설명을 더 구체적인 버전으로 세분화함.
- 총 42개의 설명을 큐레이팅하여 표 2에 기재함.

---

# 3.2 Intention Annotation

- 30개의 대화를 선택하여 의도 설명을 주석 처리함.
- 발화에는 Dutt et al. (2020)의 페이스 액트 레이블이 적용됨.
- 미국 거주 크라우드워커들이 Amazon Mechanical Turk (AMT)를 통해 주석 작업을 수행.
- 참여한 모든 작업자에게는 평균 시간당 $12의 공정한 보상을 제공.
- 주석 지침을 정제하기 위해 3회의 파일럿 테스트를 진행.
- 최종 주석 지침은 부록 A에 있음.
- 작업자들은 전체 대화를 주의 깊게 읽고, 서면의 발화에 특정 의도 설명을 지정.
- 발화와 동일한 페이스 액트로 분류된 후보 설명이 제공됨.
- 예를 들어, 특정 발화를 주석 처리할 때 "EE가 STC 또는 ER에 대해 의심하거나 비판함"과 같은 설명이 제공됨.
- 각 발화에 대해 3명의 작업자가 주석을 달아 3개의 설명을 수집.
- 다수결을 통해 각 발화의 가장 많은 설명을 채택하고, 2명 이상의 작업자가 같은 의도 설명을 주석한 경우 금본 레이블을 채택.
- 총 691개의 발화가 주석 처리되었으며, 그 중 620개는 3명 중 최소 2명의 동의가 있었음.
- 이후 620개의 발화에 대해 의도 분류 문제를 생성.
- 주석자 간의 동의 수준을 평가하기 위해 Krippendorff의 알파 값을 계산: 0.406으로 중간 수준의 동의를 나타냄.
- 주석자 동의에 대한 상세 정보는 부록 B에 있음.

---

# 3.3 Question Creation

- 620개의 발화에서 의도 설명을 주석 처리함.
- 동일한 설명으로 주석이 달린 연속 발화를 연결(concatenate)함.
- 일부 발화는 이후 발화를 들어야 의도가 명확해짐.
- 이 과정은 불완전한 발화에서 의도를 예측해야 하는 질문 생성을 방지하기 위해 중요함.
- 발화 연결 과정에 대한 자세한 내용은 부록 C 참조.
- 최종적으로 549개의 발화가 의도 설명과 함께 주석 처리됨.
- 이러한 발화로부터 다선택(multi-choice) 질문을 생성함.
- 각 발화에 대해 미리 정의된 설명 풀에서 임의로 3개의 방해 요소(distractor)를 선택함.
- 방해 요소 선택 과정에 대한 규칙은 부록 D를 참조.
- 데이터 통계는 표 3에 명시되어 있음.

---

# 4 Experiment

- **목적 및 방법론**
  - LLM(대형 언어 모델)의 발화 의도 탐지 능력 평가.
  - OpenAI의 GPT-4와 ChatGPT 포함 다양한 사이즈의 모델 사용.
  - Meta의 Llama 2-Chat과 LMSYS의 Vicuna 모델도 사용.

- **프롬프트 설정**
  - 발화 의도 탐지를 위한 정보 제공: 대화 상황, 작업 설명, 대화 스크립트 및 4개 선택 질문.
  - Zero-shot Chain-of-Thought 스타일에 따라 프롬프트 설계: 이유 설명 단계와 선택 단계로 나뉨.
  - 모델은 사전 발화를 모두 보고 의도를 탐지.

- **데이터 통계**
  - 질문 수: 549
  - 대화 수: 30
  - 평균 질문 수: 18.3
  - 평균 발화 수: 30.8
  - 평균 단어 수(발화당): 11.99
  - 평균 단어 수(설명당): 10.61

- **인간 성능 벤치마크**
  - AMT에서 작업자를 고용해 테스트 데이터에 대한 주의 깊은 주석을 제공.
  - 대화 전체를 읽고 최종 발화의 의도를 4개 옵션 중에서 선택.
  - 3명의 작업자 선택에 따른 다수결로 최종 답안 결정.

<img alt="image" src="https://github.com/user-attachments/assets/314d5e61-56b7-4e9c-96cc-8a0cec5930d3" />

- **모델 성능 결과**
  - 정확도는 모델 크기가 커질수록 향상됨.
  - 가장 작은 모델은 50% 이상의 정확도 달성, GPT-4는 90% 이상.
  - 모델들은 hpos- 카테고리에 속하는 의도 탐지에서 어려움을 겪음.
  - 특히, GPT-4는 hpos-로 레이블된 ER 발화의 의도를 7문제 중 1문제만 정확히 탐지.

- **결론**
  - 작은 LLM이 어려움을 겪는 행동 관찰 및 LLM, 특히 GPT-4의 의도 탐지 어려움 분석.

---

# 4.1 Behavior of Smaller LLMs

- **GPT-4와 비교**: 
  - GPT-4는 데이터셋에서 90% 이상의 질문에 정확히 답변함.
  - Llama 2-Chat-70B와 ChatGPT는 GPT-4보다 작지만 다른 작은 모델들보다 더 많은 질문을 올바르게 답변함.

- **문제 유형**: 
  - 두 가지 문제 유형으로 분류: 
    - 의도 관련 문제 (intention-related problems)
    - 비의도 관련 문제 (non-intention-related problems)

## 4.1.1 의도 관련 문제

<img alt="image" src="https://github.com/user-attachments/assets/2e46658a-7318-4f3c-9f77-5ee5b723ed2d" />

- 작은 모델들은 논리적으로 완벽한 추론을 수행하지만 독특한 사고 과정을 거침.
- GPT-4는 합리적인 한도 내에서 의도를 추측하지만, 작은 모델들은 가끔 과도하게 해석함.
  - 예시: 
    - GPT-4는 EE가 단순히 기부 습관을 언급한다고 해석.
    - ChatGPT와 Llama 2-Chat-70B는 EE가 이미 교회에 기부했으므로 STC에 기부할 의도가 없다고 과도하게 해석함.

## 4.1.2 비의도 관련 문제

<img alt="image" src="https://github.com/user-attachments/assets/7aaa42a1-8388-4dd6-a9e9-db04e4325c43" />

- Llama 2-Chat-70B는 의도 과해석 외에도 생성 루프 및 목표와 다른 발화의 의도를 예측하는 문제 발생.
- 작은 모델들은 복잡하고 긴 프롬프트를 이해하는 데 어려움을 겪어 지침을 제대로 이해하지 못함.
- 논리적 일관성 부재 문제:
  - 작은 모델들은 지침에 따라 논리적으로 답을 도출하는 능력이 떨어짐.
  - Llama 2-Chat-70B는 자주 마지막 옵션을 정답으로 선택하는 경향이 있음.
    - D 옵션은 전체 정답의 25.7%를 구성하지만 Llama 2-Chat-70B는 31.9%의 확률로 선택.
- 선택지 검토 후 가장 그럴듯한 옵션을 선택하는 데 어려움이 있으며, 추론 과정에서 일관성 부족은 작은 모델의 성능을 저하시킴.

---

# 4.2 About hpos-

- LLM(대형 언어 모델)은 hpos로 분류된 발화를 해석하는 데 취약함.
  - hpos 발화는 ER이 EE의 기부에 대한 주저함을 비난하거나, EE가 ER의 신뢰성에 의구심을 표명함.
  - GPT-4는 EE의 발화 의도를 추론하는 데 오류를 범함.
  

## 4.2.1 데이터셋의 패턴

<img alt="image" src="https://github.com/user-attachments/assets/44277449-8507-45e7-8373-02b7e25e9f5e" />

- ER이 EE를 비판하는 두 가지 주요 패턴:
  1. **소비 습관 질문**:
     - ER이 EE의 소비 습관을 물으며 불필요한 소비를 줄이고 기부를 권장함.
  2. **가난한 사람 언급**:
     - ER이 가난한 사람들을 언급하며 EE의 기부를 하지 않을 경우 발생하는 고통을 강조함.

## 4.2.2 인위적으로 생성된 데이터셋
- 비판적인 발화로 인식되는 정도를 확인하기 위해 시나리오를 인위적으로 생성함.
- 90개의 발화에서 머신과 사람의 판단 차이를 분석.
  - 대부분의 발화는 비판이 아닌 기부를 유도하는 것으로 판단됨.
  - 인간은 85개의 발화를 'ER이 EE를 기부하도록 동기부여'로 분류, 4개는 'ER이 EE를 비판'으로 분류.
  

- GPT-4와 인간의 발화 해석 차이:

<img width="397" alt="image" src="https://github.com/user-attachments/assets/4a2a6817-11b5-4959-b585-69fb7928c182" />

  - 인간이 비판적으로 판단한 발화는 명백하고 냉소적임.
  - 감정적 호소의 전술은 기부 동기를 높이는 수사 전략으로 인식됨.
  - 아이러니한 발언은 인간이 보다 섬세하게 의도를 파악하도록 만듦.

---

# 5 Conclusion

- 이 연구는 대화에서 LLM(대형 언어 모델)이 의도를 감지할 수 있는지 조사함.
- 기존의 설득 대화를 활용하고 데이터셋 구축 및 분석 프레임워크 설계.
- 연구는 특정한 대화 상황에 제한되었지만, 그런 방법 사용은 하지 않았음.
- 따라서 연구에서 얻은 통찰은 다양한 대화 장르에 적용될 가능성이 높음.
- 데이터셋은 평가 목적으로만 생성했으며, 사전 훈련된 언어 모델을 미세 조정할 수 있는 교육 데이터의 필요성을 강조.

### 향후 연구
- 미세 조정을 위한 충분한 양의 데이터를 수집하기 위한 연구가 필요함.
- LLM의 의도 감지 능력을 측정하기 위해 대안적 평가 방법 탐색이 요구됨.

---

# 6 Limitations

- **부적절한 라벨링**  
  - 데이터셋 제작 시 부적절한 라벨링 문제 발생.  
  - 미리 정의된 라벨 세트로 인해, 맞지 않는 의도 설명을 선택해야 하는 경우 발생.  

- **다양한 정답 가능성**  
  - 여러 올바른 답변이 가능한 질문의 경우가 많음.  
  - 같은 발화에서 비판으로 해석될 수도, 동기를 부여하려는 의도로도 해석할 수 있는 상황이 있음.  
  - 올바른 의도 설명을 선택하는 것이 적합하지 않을 수 있음.  

- **불완전한 데이터셋**  
  - LLM의 의도 탐지 능력을 충분히 측정하기 위한 데이터셋은 부족.  
  - 특정 의도가 덜 자주 나타나는 경우를 탐지하는 데 한계.  
  - 다양한 대화 유형을 포함한 균형 잡힌 데이터셋 필요.  

- **인간과 LLM 간 차이 탐색**  
  - LLM과 인간 간의 의도 인식 차이를 조사했으나, GPT-4의 편향이 실험 결과에 영향을 미침.  
  - 생성된 데이터의 인위성으로 인해 결과의 유효성에 문제가 있을 수 있음.  

- **윤리적 고려사항**  
  - LLM의 의도 탐지 능력 평가에 따라 심각한 윤리적 영향 발생할 수 있음.  
  - LLM이 정확하게 의도를 탐지하게 되면, 대화 시스템의 기초로 활용될 수 있으며, 이는 인간의 의도를 조작할 위험을 내포하고 있음.  
  - LLM이 허위 정보를 유포할 수 있는 능력을 가질 경우, 사회적 혼란이 초래될 수 있음.  

- **LLM의 내재된 편향**  
  - 연구에 사용된 LLM의 내재된 공격적인 지식 및 표현, 다양한 편향이 결과에 영향을 미침.

---

# 7 Ethical Considerations

- 이 연구는 대화에서 LLM의 의도 탐지 능력을 평가하는 것을 목표로 함.
- 연구 결과가 즉각적으로 심각한 윤리적 영향이 있는 분야에서 사용될 것이라고 예상하지 않음. 
- LLM이 의도를 정확하게 탐지할 수 있게 된다면, 다양한 분야에서 유용한 상호작용 에이전트로 사용될 것임.
- 그러나 LLM이 대화 시스템의 기초로 사용될 경우, 인간의 의도를 변경할 위험이 존재. 
- 악의적인 사용자가 LLM을 이용해 사기를 치거나 잘못된 정보를 퍼뜨리는 등의 위험이 초래 될 수 있음.
- LLM(People Acknowledgments 등)의 내재적인 편향 및 표현이 연구 결과에 영향을 미칠 수 있음. 
- LLM의 사용과 관련된 윤리적 문제를 인식하고, 미래의 연구에서 이러한 위험을 고려해야 함.
