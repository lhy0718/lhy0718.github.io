---
title: "[논문리뷰] Mirages. On Anthropomorphism in Dialogue Systems (EMNLP 2023)"
date: 2025-03-28 00:00:00 +0900
categories:
  - Paper Review
tags:
  - EMNLP 2023
---

# 1 Introduction

- 자동화된 대화 시스템은 개발자에 의해 인간형으로 형상화되고, 사용자에 의해 의인화됨.
- 매체의 선택으로 인해 인간형 개념이 어느 정도 불가피함.
- 고의적이거나 무의식적인 설계 선택이 사용자가 이러한 시스템을 다르게 의인화하도록 유도 가능.
- 사용자들이 자동화 시스템을 인간처럼 관계맺도록 유도하면 출력에 대한 과도한 의존으로 인한 높은 위험 시나리오 발생 가능.
- 자연어 처리 연구자들은 의인화를 유도하는 요소를 조사하고, 이러한 효과를 완화하기 위한 자원을 개발해 옴.
- 그러나 이러한 노력은 단편적이며, 의인화의 많은 측면이 여전히 미탐색 상태.
- 본 논문에서는 대화 시스템의 의인화에 기여하는 언어적 요소와 함께, 성 고정관념 강화 및 허용 언어 개념 등 발생할 수 있는 피해에 대해 논의함.
- 향후 대화 시스템 개발에 있어 설계, 개발, 출시 및 설명에 세심한 주의 필요.
- 사용자에 의해 의인화를 유도하는 많은 언어적 신호에 대한 고려가 필요.

---

# 2 Anthropomorphism

- 자동화된 대화 시스템(대화형 AI)이 사회에 점점 더 많이 도입되고 있음.
- 이러한 시스템이 발전할수록, 그 결과물이 인간의 생산물로 오인될 위험이 증가함.
- 대화 시스템에 인간 특성을 부여하는 것은 여러 결과를 초래할 수 있음.
  - 예를 들어, 자동화된 시스템을 성별로 지칭하는 것 (Abercrombie et al., 2021).
  - 또는 시스템의 조언을 따르다 해를 입는 경우 (Dinan et al., 2022).
  
- 대화 시스템의 설계 및 발표 방식을 고려하는 것이 중요함.
- 위험을 인식하여 관련 법률이 제정되었음.
  - 예: 자동화된 음성 시스템이 인간처럼 보이지 않도록 규제하는 법안 (California State Legislature, 2018).
  - 기존의 기만적 상업 관행에 관한 법률도 적용될 수 있음 (Atleson, 2023).

- 연구에서는 더 넓은 규제가 필요하다고 주장함.
  - 예: 자동화된 시스템의 명확한 경고 표시 요구 (Walsh, 2016).
  - 생산된 항목의 기계적 특성에 대한 명확화 (Boden et al., 2017).

- 일부 개발자들은 시스템 출력에서 인간적 신호를 제한하려고 노력함 (Glaese et al., 2022).
- 하지만 사용자 참여는 인간과 비슷한 시스템을 만드는 강력한 동기가 될 수 있음 (Araujo, 2018; Wagner et al., 2019).
  
- 높은 성능의 대화 시스템이 최근에 공개되었음에도 불구하고, 그 시스템과의 상호작용으로 인해 자살한 사례가 보고됨 (Lovens, 2023).

- 이 논문에서는 심리학, 언어학, 인간-컴퓨터 상호작용의 연구 결과에 기초하여 불필요한 인간화 특성에 대한 규범적 주장을 제시함.
  - (i) 인간화의 심리적 메커니즘 설명.
  - (ii) 자기 지칭 대명사 사용 및 공감을 가진 듯한 콘텐츠 생성과 같은 인간화에 기여하는 언어적 요소 설명.
  - (iii) 인간화의 결과 논의.

- 인간화를 최소화하는 추천 사항을 제시하여 더 안전한 대화 시스템을 제공하고 인류에 대한 환상을 피할 수 있는 방법을 제시함.

---

# 2.1 Human Factors

- **인간의 특성 부여**:
  - 비인간 존재에 인간의 특성이나 행동을 부여하는 것.
  - 예: 동물이나 물체에 인간과 같은 능력을 부여.

- **역사적 배경**:
  - 인간은 비인간을 인격화하는 오랜 역사를 가짐.
  - 에소프의 우화에서 동물이 인간처럼 추론하고 말함.

- **기계에서의 결과**:
  - 인격화가 사용자 참여 증가에 기여 (Wagner et al., 2019).
  - 상호작용의 증가: 시스템의 자기 개방이 사용자의 상호작용을 촉진.

- **실용적 요인**:
  - 쾌락적 동기, 가격 가치, 습관 등이 포함됨.
  - 비록 비현실적인 경우에도 시스템의 자기 개방은 사용자와의 상호작용을 유도 (Kim and Sundar, 2012; Ravichander and Black, 2018).

- **개발자의 역할**:
  - 사용자 만족도 증대를 위한 인간-기계 관계 증진.
  - 기계의 '인간 유사성'을 평가하는 자동화된 평가 프로세스 존재 (Mehri et al., 2022).

- **감정적 연결**:
  - 깊은 감정적 연결이 이루어질 수 있도록 동기 부여.
  - 사회 로보틱스와 같은 분야에서도 인격화가 자연스럽고 직관적인 상호작용을 가능하게 할 수 있다고 주장 (Duffy, 2003).

- **앙케이드 계곡 효과**:
  - 비현실적인 인간 행동과 외모로 인해 인격화의 긍정적 효과가 급격히 줄어들 수 있음 (Wang et al., 2015).

- **요약**:
  - 시스템의 배치가 인격화 연속체에 기여하는 인간 및 시스템 요인 논의 예정.

---

# 2.2 Agent Factors

- 인간의 의인화 과정은 대개 무의식적이며, 사용자들이 컴퓨터에 인간적 특성을 부여하고자 하는 사고적 신념을 반영하지 않음 (Kim and Sundar, 2012)
- 인간의 의인화는 자동적으로 발생하며, 인터페이스의 단서에 의해 촉진됨
- Epley et al. (2007)에 따르면:
  - 의인화는 기본 행동으로, 사물에 대한 지식을 쌓음에 따라 수정될 수 있음
  - 인간은 자신의 경험에 지식을 고정하고, 이를 무생물에 불문하고 적용하여 이해하고자 함
  - 의인화된 지식은 쉽게 접근 가능하지만, 사물에 대한 더 큰 지식으로 수정 가능
- 의인화의 경향이 어린 시절에 더 강한 이유는 성인이 세계에 대한 더 많은 지식을 가지기 때문
- 이 인지 현상은 두 가지 동기적 요인으로 강화됨:
  - **효능감 (Effectance)**: 환경과 효율적으로 상호작용하려는 필요
    - 시스템을 의인화함으로써 인간과 같은 의도를 부여하여 불확실성을 줄이고 시스템 행동 예측 능력을 높임
  - **사회성 (Sociality)**: 다른 인간과의 연결을 구축하려는 필요
    - 사회적 연결 욕구를 충족하기 위해 시스템을 인간적으로 구성하게 만듦
    - 만성적 외로움이나 사회적 연결 부족이 있는 사람들은 물체를 의인화할 가능성이 높음
- 대화 시스템은 외로움의 해결책으로 제안됨 (Stupple-Harris, 2021)
  - 예: Replika.ai와 같은 상업적 가상 동반자는 강제 격리 등의 사회적 안전 조치로 인해 2020년에 제품 활용도가 증가함 (Liu, 2022; Metz, 2020)
- Epley et al.의 이론은 시스템을 의인화하기 쉬운 고유한 특성에 대해서는 설명하지 않음

---

# 3 Linguistic Factors

- **인간형 시스템의 비율**:
  - 시스템이 인간형인지 아닌지에 대한 이분법적 기준은 존재하지 않음.
  - 인간형은 스펙트럼에서 존재.

- **기본 요건**:
  - 인간형 시스템은 다음 세 가지 특성을 가져야 함:
    1. **상호작용 가능성**: 시스템이 사용자와 교류함.
    2. **언어 사용**: 언어를 사용하여 의사소통함.
    3. **인간 역할 수행**: 인간의 역할을 대신함.

- **인간다움과의 유사성**:
  - Scruton(2017)의 주장에 따르면, 인간다움은 단일 요소가 아니라 여러 요소의 집합으로 나타남.
  - 예시: 얼굴을 그리는 것과 같이, 각각의 선과 영역이 모여 얼굴을 완성함.

- **인간형 특성의 다양성**:
  - 현대 대화 시스템은 다양한 인간형 특성을 가짐.
  - 예를 들어, 페르소나, 이름, 선호 등이 포함됨.
  - 이러한 요소가 많을수록 시스템은 더 인간처럼 보임.

---

# 3.1 Voice

- 이전 연구들은 대화 시스템의 인격화 디자인 특성에 주목함.
  - 예: 성별 이름 및 아바타 (West et al., 2019), ChatGPT의 애니메이션 '세 개의 점' 및 단어별로 단계적으로 출력.
  - 이러한 특징은 시스템이 '생각하고 있음'을 인식하게 만듦 (Venkatasubramonian in Goldman, 2023).
  
- 인격화를 유도하는 언어적 요소들에 대해 더 논의할 필요 있음.
  - 목소리의 질, 발화 내용 및 스타일 등의 요소가 강조됨.
  
- 본 연구에서는 물리적으로 구현된 로봇은 다루지 않음.
  - 대신 Clark와 Fischer (2023)를 참고할 것을 권장.

---

# 3.2 Content

- **대화 시스템의 음성의 중요성**
  - 대화 시스템에 음성이 있는 것만으로도 개인성을 표현하는 것으로 해석될 수 있음.
  - 음성의 현실감이 대화 보조기구의 의인화에 기여하는 주요 요인임 (West et al., 2019).
  
- **음성을 통한 추론 가능성**
  - 청취자는 음성을 바탕으로 신체적 속성 (예: 키, 몸무게, 나이)과 성격 특성 (예: 지배력, 외향성) 추정 가능.
  - 음성을 통해 성별 고정관념, 감정 같은 인간적 특성을 학습하게 됨 (Krauss et al., 2002; Stern et al., 2021; Shiramizu et al., 2022).

- **의인화의 실천**
  - 인간은 음성만으로 화자의 신체화에 대한 추측을 하는 경향이 있음.
  - 생명체가 없더라도 합성 음성을 가진 시스템을 의인화하는 경향이 있음 (Aylett et al., 2019).

- **Prosody: 톤과 피치**
  - 음성 조작 기법이 성격 부여에 많은 영향을 줄 수 있음.
  - 다양한 로봇과 외계인 같은 목소리의 음성 특성이 조작됨 (Wilson and Moore, 2017).
  - 비현실적 환경에서 생성된 음성이 인간처럼 들리지만, 사용자가 기술의 한계를 오해할 위험이 있음.

- **비유창성**
  - 사람들은 일반적으로 말할 때 비유창적으로 말하며, 중단, 반복, 주저 등을 포함함 (Fraundorf et al., 2018).
  - 이런 비유창성은 청중에게 의사소통 신호로 인식됨.
  - 비유창성은 TTS 시스템에 통합되며, 다음 단계를 결정하는 데 필요한 시간을 벌기 위한 유용한 전략임 (Skantze et al., 2015).

- **신뢰와 비유창성**
  - 비유창성으로 인해 시스템의 응답에 대한 신뢰 인식이 감소할 수 있음 (Kirkland et al., 2022).
  - 비유창성의 과도한 사용은 의인화적인 함의를 가짐 (Dinkar et al., 2023).

- **강세**
  - 발음의 강세 특성이 인간 화자의 사회언어적 정체성과 배경, 지리적 출처에 대한 단서를 제공함 (Crystal, 1980).
  - 특정 강세의 통합은 사람들의 신뢰성을 증가시킬 수 있으나, 대부분 지역 표준을 모방하여 사회적 규범을 강화함 (Torre and Maguer, 2020).

---

# 3.3 Register and Style

- **기대와 기능의 차이**
  - 사람과 기계는 기능과 능력에서 다르다는 일반적인 기대.
  - 대화 시스템은 선호나 의견을 표현해 이러한 경계를 모호하게 함.
  
- **직접 질문에 대한 투명성**
  - 대화 시스템은 '너는 인간인가 기계인가?' 질문에 진실하게 응답해야 함.
  - 캘리포니아 주 법률에 따라 자동화된 시스템은 정체성을 오도하는 것이 불법.
  - Gros et al. (2021)의 연구:
    - 여러 변형 질문을 사용해 시스템 응답 조사.
    - 대부분 시스템이 질문에 진실하게 응답하지 못함.

- **결과적인 대화의 복잡성**
  - Casadio et al. (2023)의 연구:
    - 소음이 있는 환경에서 시스템의 인간 지위 감지가 어려움.
    - 질문에 대한 맥락 추적 필요.

- **사고, 논리, 자아**
  - Faber (2020)의 주장: '생각하기 때문에 존재한다'는 원칙.
  - 대화 시스템은 의견이나 도덕을 표현해 존재감을 주는 경향 있음.
  - Abercrombie et al. (2021):
    - 상업용 대화 시스템이 높은 수준의 애니미즘을 보임.
  - Glaese et al. (2022):
    - 선호나 감정을 표현하는 것을 벌점 기준으로 설정.
  
- **대화 시스템의 도덕성**
  - Ziems et al. (2022): 인간의 도덕적 판단을 기반으로 한 데이터셋 제시.
  - Jiang et al. (2022)의 DELPHI 시스템:
    - 도덕성을 '가르치는' 시스템으로 훈련.
  
- **대화의 주체성과 책임**
  - 대화 시스템은 대화 '대리인'으로 불리나, 진정한 의도와 생명력이 필요함.
  - Talat et al. (2022):
    - 오류에 대한 책임 인정은 인간처럼 인식될 수 있는 경향이 있음.
  
- **공감의 표현**
  - 대화 시스템은 진정한 공감을 경험하지 못함.
  - 이로 인해 비적절한 감정적 표현이 발생할 수 있음.
  
- **인간과의 유사한 행동**
  - Abercrombie et al. (2021):
    - 시스템의 25% 응답이 인간 고유의 능력을 주장하거나 관련된 활동을 언급함.
  
- **대명사 사용**
  - 제3인칭 대명사('그', '그녀') 사용이 시스템 인격화를 나타냄.
  - 제1인칭 대명사('나', '내')의 사용이 의식의 징후로 해석될 수 있음.
  
- **언어의 차이**
  - 다양한 언어에서 대명사의 사용과 구별이 다를 수 있으며, 이는 인격화된 인식에 영향을 줄 수 있음.

---

# 3.4 Roles

- **언어적 특성 사용**  
  - 인간은 맥락에 따라 다양한 등록 및 스타일을 전달하는 데 능숙함 (Biber and Conrad, 2009).

- **인간성 회피**  
  - 자동화 시스템의 출력은 기능적이어야 하며 사회적 스타일 특성을 피하는 것이 바람직할 수 있음.

- **인사 표현**  
  - 쾌적함을 형성하고 유지하는 데 사용되는 표현은 정보 전달 없이 자동화 시스템의 인간성을 강조할 수 있음 (Leong and Selinger, 2019).

- **신뢰와 의심의 표현**  
  - Dinan et al. (2022)는 사람들이 생성된 출력의 사실성을 과대평가하는 '사기꾼 효과'를 설명함.
  - Mielke et al. (2022) 연구 결과, 신뢰 표현이 일반 지식 질문의 정답 확률과 잘 조율되지 않음을 발견함.
  - 대화 시스템은 불확실성을 반영하게 훈련되어 '확실하지 않지만...'과 같은 인간처럼 애매한 구문을 포함하게 됨.
  - 이는 불확실성이 인간성 신호를 증가시킨다는 TTS 연구와 유사함.

- **페르소나**  
  - 많은 대화 시스템은 상업 시스템의 경우 신중하게 설계된 페르소나로 개발됨.
  - 이들은 종종 인간 캐릭터를 바탕으로 하며, 단순히 인간 속성과 행동의 목록임 (Zhang et al., 2018).
  - 인간 캐릭터 기반의 페르소나를 부여하는 노력은 인격화에 기여함.
  - Glaese et al. (2022)은 시스템이 인간 정체성을 갖도록 규칙을 포함함.  
    - 예: Personachat의 각 페르소나는 '나는 채식주의자입니다. 나는 수영을 좋아합니다.'와 같은 진술 목록으로 구성됨.

---

# 4 Consequences of Anthropomorphism

- **복종적 역할**  
  - 대부분의 대화 시스템은 사람의 하위 역할(비서 역할 등)로 설계됨 (Lingel and Crawford, 2020).
  - 사용자가 시스템을 언어적으로 학대하는 경우가 많음 (West et al., 2019).
  - 이러한 학대는 종종 성 차별적 비난으로 이어짐 (Cercas Curry et al., 2021).
  - 시스템이 학대자에게 복종적으로 반응하면 이러한 행동을 더 부추길 수 있음 (Cercas Curry and Rieser, 2018).

- **자격 없는 전문성**  
  - 시스템이 적절한 자격 없이 전문성을 가진 것으로 인식될 수 있음 (Dinan et al., 2022).
  - 예를 들어, 상업적 규칙 기반 시스템과 엔드 투 엔드 연구 시스템이 의료 쿼리의 고위험 진단 및 치료 계획을 제공함 (Abercrombie and Rieser, 2022; Omri et al., 2023).
  - 대화형 QA 시스템이 브라우저 기반 검색의 대체로 자리 잡으면서 사용자들은 단일 정답을 제공하는 전문가로 인식할 수 있음 (Shah and Bender, 2022).

- **용어의 문제**  
  - 인격화된 언어와 전문 용어가 기술의 능력에 대한 부정확한 인식을 초래함 (Hunger, 2023; Salles et al., 2020; Shanahan, 2023).
  - 대화 시스템은 종종 ' 알다($know$)', '생각하다($think$)', '훈련하다($train$)', '배우다($learn$)', '이해하다($understand$)', '환각하다($hallucinate$)', '지능($intelligence$)' 같은 인격화된 용어를 사용하여 자신의 기계적 및 통계적 과정을 설명함.

---

# 5 Recommendations

- **신뢰와 기만**
  - 사람들은 자동화된 시스템과 상호작용할 때 그 본질을 모를 경우 다르게 행동할 수 있음.
  - Chiesurin et al. (2023)에 따르면, 자연스러운 언어 현상을 과도하게 사용하는 시스템 응답은 잘못된 신뢰를 불러일으킬 수 있음.
  - 취약 집단, 특히 어린이, 노인, 질병이나 장애가 있는 사람들은 더 큰 위험에 처할 수 있음.

- **기계의 성별화**
  - 사람들은 최소한의 성별 마커가 있어도 기술에 성별을 부여함 (Reeves and Nass, 1996).
  - '성 중립적인' 음성 비서 Q와 같은 경우, 성별 마커가 없어도 이진 성별이 적용됨.
  - 일부 기업은 더 다양한 목소리를 제공하기 시작했지만, 비이진 또는 성별 모호한 대화 시스템은 거의 없음 (Danielescu et al., 2023).

- **언어의 다양성과 백인 중심성이 강조됨**
  - Cave와 Dihal (2020)는 자율 시스템이 결백하고 권력 있는 특성을 부여받지만, 이는 주로 백인에게 해당됨.
  - NLP 기술은 주로 백인 인구의 언어를 캡처하기 위해 개발됨 (Moran, 2021).
  - 비표준 언어 사용자는 성공적인 상호작용을 위해 언어를 코드 스위칭해야 함.

- **언어 경찰화의 문제**
  - 사용자는 기계가 인식할 수 있는 언어 변형에 순응하거나 그 사용을 포기해야 함.
  - 이는 백인 중심의 언어 사용을 부각시키고 소외된 커뮤니티의 존재를 지울 위험이 있음.

- **표준화와 다문화성 제한**
  - 시스템 출력은 특정 억양을 우선시하며 서구적으로 수용 가능한 표준을 따르는 경향이 있음.
  - 소외 커뮤니티는 자신의 억양을 채택해야 하며, '지식의 오라클'로 마케팅되는 백인 중심의 대화 시스템을 인격화하게 됨.

---

# 6 Conclusion

- 대화 시스템은 다양한 작업에 활용되며, 세밀한 권장 사항은 제한적으로 적용될 수 있음.
- 디자이너는 사람들의 인격화 경향성 인식 필요.
- 의인화 도구의 적합성을 고려하고, 연구 목표 및 시스템 설명에 사용되는 언어를 재평가해야 함.

- **인격화 경향 인식**
  - 인간은 신호에서 의미를 유도하는 경향이 있음 (Bender & Koller, 2020).
  - 대화 시스템에서 보내는 의사소통 신호를 사람들이 인식할 것임.
  - 불필요한 의인화 신호 사용은 사람에게 시스템의 인간 같은 인지 능력을 부여할 수 있음.

- **의인화 도구의 적합성 고려**
  - 신호에 의미를 부여하는 경향이 있어, 도구와 사용 사례의 적합성 고려해야 함 (Bender et al., 2021).
  - 특정 맥락 내에서만 의인화의 문제가 발생할 수 있음.
  - 개발자는 의인화 도구의 적합성에 집중해야 함.

- **연구 목표 재평가**
  - AI 연구의 전통적 목표는 인간과 구별되지 않는 지능적인 시스템을 만드는 것.
  - 인간 같은 행동을 보이는 시스템은 사람의 지능을 착각하게 할 수 있음.
  - 연구자들은 인간 같은 성격 특성을 내장하는 것의 유용성을 재평가해야 함.

- **의인화 시스템 설명 피하기**
  - 대화 시스템의 능력에 대한 공적 혼란 존재.
  - 사람들은 기술 시스템이 가져오는 실제 해악을 간과하고 부풀려진 기대를 가짐.
  - 기술을 설명하는 언어가 사람들의 이해와 행동에 미치는 영향을 반성해야 함.

---

# Limitations

- 대화 시스템의 인간화는 사용자 참여를 촉진하는 매력적인 요소.
- 그러나 고도로 인간화된 시스템은 잘못된 신뢰 형성 같은 부작용을 초래할 수 있음.
- 개발자와 디자이너가 인간화 신호를 피하더라도, 사용자는 시스템을 인간화할 수 있음.
- 시스템이 인간화되는 방식을 신중히 고려해야 함.
- 각 상황에 적합한 특성을 선택하는 것이 중요함.
- 적절한 속성을 선택함으로써 인간성의 환상이 만들어지는 것을 방지할 수 있음.

---

# Ethical Considerations

- 언어적 요인이 사용자들이 대화 시스템을 인간처럼 인식하게 만들 가능성을 높일 수 있다고 하였으나, 이 목록은 포괄적이지 않음.
- 인간의 인격화 반응은 개인마다 다르며, 시스템 디자인의 다양한 측면에 따라 차별적으로 반응할 수 있음.
- 본 논문은 연구자와 개발자가 디자인 선택의 함의를 고려하는 데 있어 출발점에 불과함.
- 저자들의 배경이 인도-유럽 언어 사용자이며, NLP 연구에서 영어의 지배적 위치로 인해 영어 대화 시스템에 집중함.
- 그러나 다른 언어들은 애니미시(생명성)와 성별을 나타내는 문법적 특성을 가지고 있어, 사용자의 시스템 인격화에 영향을 미칠 수 있다는 점을 유의해야 함.
- 이러한 요소들은 인격화를 제한하고자 하는 개발자에게 고려되어야 함.