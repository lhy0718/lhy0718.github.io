---
title: "[논문리뷰] Knowledge Enhanced Reflection Generation for Counseling Dialogues (ACL 2022)"
date: 2025-05-23 11:38:48 +0900
categories:
  - Paper Review
tags:
  - ACL 2022
  - Empathetic Dialogue Systems
---

이 논문은 상담 대화에서 상식 및 도메인 지식을 통합해 응답을 생성하는 방법을 제안하고, 검색 기반 및 COMET 생성 지식이 응답 품질 향상에 효과적임을 실험적으로 입증하였다.

---

# 1 Introduction

- COVID-19 팬데믹으로 인해 정신 건강 관리가 매우 중요해졌으며, 상담 서비스에 대한 수요가 크게 증가하고 있고, 보건 의료 종사자들도 신체적·정신적 부담이 크다 (Paredes et al., 2021; Huffman et al., 2021).

- 자연어 처리 기술의 발전을 상담 지원에 활용하는 방안을 모색하는 것이 자연스러운 상황임.

- 다양한 상담 방식 중에서 '반영적 경청(reflective listening)'은 효과적인 상담의 기본 절차로, 내담자의 말을 주의 깊게 듣고 그 의미를 적극적으로 추측하는 과정이다 (Katz and McNulty, 1994).

- 반영적 경청은 내담자가 자신이 이해받고 있다고 느끼게 하여 자기 탐색을 촉진하지만, 내담자가 항상 말하는 그대로의 의미를 직설적으로 표현하지 않는 경우가 많다.

- 반영 반응(reflection)은 내담자의 말에 명시적으로 드러나지 않은 의미를 해독해야 할 때가 있으며, 내담자에게 명확한 설명을 강요하면 표현을 방해할 수 있다 (Miller and Rollnick, 2012).

- 따라서 상담자는 사전 지식을 바탕으로 추론을 해야 하며, 예를 들어 "이번 주 다이어트가 정말 힘들었어요"라는 발언에 대해 "이 방법으로 살을 뺄 수 있을지 궁금하군요"라는 반영은 상식적 지식을 바탕으로 한 추론이다.

- 좋은 반영은 때때로 도메인 지식도 필요로 한다. 예를 들어, 환자가 흡연과 관련된 폐기종(emphysema)이나 Chantix(금연 치료제)를 언급할 때, 상담자는 이들 의료용어의 의미를 알아야 적절한 반영을 할 수 있다.

- 현존하는 최첨단 언어 모델들도 이러한 상담 대화에서의 상식 및 도메인 지식 활용에 어려움을 겪음.

- 본 논문에서는 대화 맥락뿐 아니라 상식 및 도메인 지식을 활용하여 상담용 반영 문장 생성 과제를 제안함.

- 기존 사전 학습 언어 모델들은 사전 학습 중 일부 지식을 습득하였지만, 일관되고 유익하며 관련 지식을 포착하는 응답 생성을 제대로 하지 못함 (Petroni et al., 2019a).

- 정확한 상담 반영문 생성을 통한 시스템은 상담 훈련 보조 또는 상담 중 내담자의 발언에 대한 대체 반영 제공 등으로 활용될 수 있음.

- 지식 융합을 위한 두 가지 전략을 실험함:
  - 1) 벡터 표현 기반 검색: BERT 기반 모델을 사용하여 대화 문장과 지식베이스 내 문장 간 벡터 유사도로 관련 지식을 검색 (Reimers and Gurevych, 2019a).
  - 2) 생성 기반: 대화에서 핵심 문구를 추출하고, COMET 모델을 통해 사전 정의된 관계 집합에 따른 가능한 지식 삼중항을 쿼리 (Bosselut et al., 2019).

- 제안 모델은 K-BART로, 소프트 위치 인코딩과 마스킹된 자기 주의(attention) 기법을 활용하여 지식의 위치를 표시하고 특정 핵심 문구에만 지식이 노출되도록 설계 (Lewis et al., 2020).

- 상식 지식베이스는 일반 도메인 개념에 대해 넓은 커버리지를 가지지만, 의료 용어 등 도메인 특화 지식은 제한적임.

- 예를 들어, ConceptNet (Speer et al., 2017)에서 'Chantix'(금연 치료제)를 조회할 경우, 유의어·관련어·상위어 관계 3개만 제공되며, 일반 단어인 'daughter'에 비해 상대적으로 적음.

- Figure 1의 Chantix 예시에서 ConceptNet은 금연 보조제의 부작용이나 권장 사용법 관련 관계가 없어, 금연 상담 대화에 필요한 인과 관계 정보를 제공하지 못함.

- 이를 해결하기 위해, 의료 개념 추출과 수동 정의 템플릿을 활용한 웹 마이닝을 통해 상담 도메인 지식 데이터셋을 수집함.

- 이 웹 수집 데이터와 공개 상식 지식베이스를 비교하고, 무인 주석으로 수집된 데이터가 보완적 지식자원으로 활용 가능함을 보여줌.

- 상식 지식의 다양한 카테고리에 대한 성능 분석을 통해, 의도(intentional) 및 인과(causal) 관계가 상담 반응 생성에 더 유용하다는 결과를 도출하였으며 이는 의료 문헌과 일치함 (Miller and Rollnick, 2012).

## 주요 기여

1. 상담 분야 지식베이스를 수집하고 이를 상식 지식베이스와 함께 활용하여 다양한 검색 기반 방법으로 반영문 생성 과제에 적용.

2. K-BERT의 인코딩 방식을 BART에 도입하여 COMET이 생성한 지식을 융합.

3. 다양한 상식 및 도메인 지식 유형을 분석하고 이들의 반영문 생성에 미치는 영향을 탐구.

---

# 2 Related Work

- 의료 및 상담 환경에서 자동 응답 생성 작업을 다룬 이전 연구들
  - Greer et al. (2019): 결정 트리를 이용해 미리 작성된 스크립트를 제공하고 사용자에게 긍정적 감정 기술 학습을 유도
  - V et al. (2019): 암 관련 질문에 답하기 위해 의학 개체와 사용자의 의도 식별
  - Almusharraf et al. (2020): 금연 상담에서 다음 질문 선택을 위한 클라이언트 반응 분류
  - 상업 시스템 예: Woebot (Fitzpatrick et al., 2017), 사용자의 정신 건강 문제를 탐지하고 관련 정보로 안내

- 자유 형식 응답 생성 연구는 위와 같은 템플릿 기반 접근법에 비해 제한적임
  - Shen et al. (2020): GPT-2를 기반으로 대화 맥락과 유사 상담 세션에서 검색한 응답을 이용해 상담 반영문 생성에 주력
  - 본 연구는 상담가들이 실제로 하는 역할을 더 잘 모방하기 위해 상식 및 도메인 특화 지식을 주입해 생성 과정 향상

- 상담 응답 생성에서 지식의 효과에 대한 연구는 아직 충분하지 않음

- 대규모 사전학습 언어모델의 특징
  - 일부 지식을 사전학습 목적을 통해 암묵적으로 내포 (Petroni et al., 2019a)
  - 상식 (Shwartz et al., 2020) 및 사실 지식 (Petroni et al., 2019b) 포함
  - 그러나 문맥에 기반한 추론이 필요한 다운스트림 작업에서는 여전히 어려움 (Do and Pavlick, 2021; Kassner and Schütze, 2020)

- 외부 지식과 사전학습 모델을 결합하여 성능 향상을 시도한 최근 연구들
  - 다양한 다운스트림 태스크 및 모델 구조에서 지식 도입의 성공 사례 (Ren et al., 2020; Zhao et al., 2020; Song et al., 2019)
  - 예시:
    - Mao et al. (2019): 다중 과제 학습으로 상식 QA 데이터셋 활용 스토리 생성
    - Zhao et al. (2020): BERT를 지식 선택 모듈로 활용해 대화 생성 개선
    - Chakrabarty et al. (2020): COMET로 생성된 지식을 활용해 반어법 생성 시 랭킹
    - Ji et al. (2020): ConceptNet에 그래프 합성곱 신경망(GCN)을 적용한 다중 홉 추론

- 본 연구도 상담 대화 텍스트 생성을 위해 외부 지식 자원을 활용

- 외부 지식 자원의 활용
  - 대규모 상식 지식 그래프(CSKG): 지식 삼중항 형식으로 구조화된 상식 지식 저장
  - 주요 CSKG: ConceptNet (Speer et al., 2017), ATOMIC (Sap et al., 2019), TransOMCS (Zhang et al., 2020)
  - 의료 관련 지식베이스: UMLS (Bodenreider, 2004), OHAMA
  - 본 연구에서는 상식 지식은 ConceptNet, 상담 특화 도메인 지식은 별도의 상담 지식베이스 수집 (일반 의료 지식베이스는 필요 지식이 부족함)

---

# 3 Methodology

- 본 논문에서는 기존 상식 지식베이스와 도메인 특화 지식을 결합한 모델을 제안함.  
- 대화 컨텍스트 $$c$$와 외부 지식베이스 $$K$$를 활용해 대화 응답 $$r$$을 생성하는 작업에 초점을 맞춤.  
- 대화 컨텍스트는 연속된 문장들 $$c = (x_1, x_2, \dots, x_M)$$로 구성되며, 지식베이스 $$K$$는 엔티티 쌍과 관계로 이루어진 트리플릿 $$\epsilon_i = (e_1, r, e_2)$$들의 집합임.  
- 생성 모델은 컨텍스트와 관련된 지식 집합 $$k_c$$와 파라미터 $$\theta$$를 입력받아 조건부 확률 $$P(r \vert c, k_c; \theta)$$를 최대화하는 응답 $$\hat{y}$$를 생성함.  

## 3.1 Task Definition

- 대화 컨텍스트 $$c$$와 외부 지식 $$K$$를 입력으로 받아 응답 $$r$$을 생성하는 과제 정의  
- 트리플릿 $$\epsilon_i = (e_1,r,e_2)$$은 엔티티 $$e_1, e_2$$와 관계 $$r$$로 구성되며, 텍스트 형태는 $$s_i$$로 표기  
- 생성 시, 문맥 $$c$$와 관련된 지식 세트 $$k_c$$를 추가 입력으로 활용하여 응답 생성  

## 3.2 Domain Knowledge Collection

- 상식 지식베이스들은 규모가 크지만, 의료 상담과 같은 도메인 특화 개념과 인과관계 정보(예: 약 복용 이유, 부작용)는 제한적임.  
- 도메인 특화 지식을 수집하는 자동화된 파이프라인 제안 (인간 노력이 크게 필요없음).  
- 주요 단계:  

  - **의학 개념 추출**: 상담 대화 데이터셋에서 Amazon Comprehend Medical을 사용해 의료 엔티티를 추출, 신뢰도 임계값 0.6 적용 및 2회 이상 등장한 엔티티만 보존  
  - 최종 452개의 의료 엔티티 확보 (345 의료 상태, 44 약물, 63 검사 및 치료 절차)  
  - **웹 쿼리를 통한 지식 수집**: 표 1의 의료 엔티티 유형별 11종의 인과 및 의도 관계 쿼리 템플릿을 사용해 구글 검색( Zenserp API 활용)  
  - 상위 100개 웹사이트에서 텍스트 추출 후 문장 단위로 파싱(Spacy 툴킷 사용)하여 후보 지식 문장 수집  
  - **인과 관계 분류**: SemEval10 Task 8 데이터셋의 인과 문장과 비인과 문장으로 이진 분류기(BERT-large 기반) 학습  
  - 분류기 신뢰도 0.7 이상인 문장 22,980개를 인과관계 의료 지식 문장으로 선별  

## 3.3 Retrieved Knowledge Setup

- 외부 지식 $$k_c$$는 대화 컨텍스트 $$c$$와 의미적으로 가깝다고 가정  
- 문장 임베딩(sentenceBERT 사용, paraphrase-distilroberta 모델 기반)으로 각 문장 및 지식 텍스트 임베딩 획득  
- 코사인 유사도 $$\mathrm{Sim}(F(c), F(s_j))$$ 최대인 $$s_j \in K$$ 선택:

  $$
  k_c = \argmax_{s_j \in K} \mathrm{Sim}(F(c), F(s_j))
  $$

- 세 가지 문장 검색 방법 실험:  
  - retrieval-each: 각 문장 $$x_i$$별 지식 선택  
  - retrieval-average: 문장 임베딩 평균 $$\frac{\sum_i F(x_i)}{M}$$으로 지식 선택  
  - retrieval-diff (oracle): 출력 임베딩과의 차이를 이용한 문서 임베딩 활용  
- ConceptNet 트리플릿을 텍스트 문장 형태로 변환해 검색 대상에 포함 (예: (knife,CapableOf,cut) → "Knife is capable of cut")  
- 지식 문장은 특수 토큰 \texttt{</s>}로 구분하여 대화 컨텍스트 앞에 붙여 BART-large 모델에 입력  

## 3.4 Generated Knowledge Setup

- 텍스트 매칭의 어려움을 극복하기 위해 생성 기반 방법 적용:  
  - 대화 내 추출된 엔티티 $$e_1$$와 관계 $$r$$가 주어지면 지식 트리플릿의 두 번째 엔티티 $$e_2$$를 생성하여 완성  
- COMET(GPT 기반) 사용: ConceptNet 등 지식베이스로 미리 학습된 모델로 $$ (e_1, r, \ast) \rightarrow e_2 $$ 예측  
- 각 발화 $$x_i$$에서 구문 트리 분석을 통해 동사구, 명사구 추출 후 COMET에 입력  
- 제한된 관계 세트(Commonsense subset)만 사용해 노이즈와 생성량 억제  

- **지식 위치 정보 및 통합 문제 해결을 위해 K-BART 구조 채택**  

  - COMET로 생성된 지식 $$(r, e_2)$$를 원래 문맥 내 $$e_1$$ 바로 뒤에 삽입 (inplace)  
  - BART (RoBERTa 기반) positional embedding은 일련의 토큰에 하나씩 벡터 할당, 문장 내 분기 구조를 반영 못하므로 확장 필요  
  - 이를 위해 문장을 트리 구조로 간주하여 $$r$$과 $$e_2$$를 $$e_1$$에 부속된 브랜치로 처리 (예: “I’ve been smoking [causes cancer] too much”에서 “causes”와 “too”는 같은 위치 인덱스 공유)  
  - **Mask-Self-Attention 기법**: 새로운 지식 토큰은 해당 $$e_1$$ 토큰에게만 보이도록 attention 마스크 설정하여 불필요한 토큰들에 영향 없음  

- 이 구조로 도메인 및 상식 지식을 효과적으로 언어모델에 통합하여 상담 응답 생성 개선 도모

---

# 4 Experiments

- **모델 및 실험 설정**
  - 생성 모델의 백본으로 BART를 선택함.
  - BART는 양방향 인코더와 좌→우 디코더를 가진 표준 seq2seq 스타일 변환기이며 GPT2와 BERT를 일반화한 구조임.
  - 각 모델은 3개의 랜덤 시드로 학습됨.

- **4.1 데이터셋**
  - Motivational Interviewing (Pérez-Rosas et al., 2016) 데이터 사용, 277개의 상담 세션 포함.
  - 행동 변화 주제(금연, 체중관리 등)에 대한 상담 대화와 상담사 발화 유형(질문하기, 반영적 응답, 협력 요청 등) 주석 포함.
  - 데이터 샘플은 반영적 응답을 목표 텍스트 y로, 상담 대화 내 이전 5개의 발화를 문맥 c로 사용, 필터링 후 3000개 이상 샘플 확보.
  - 일반 상식 지식베이스로 ConceptNet 사용, 21백만 개의 34개 관계 포함.
  - 영어 문장 및 의미 기반 선택된 관계만 사용하여 약 3.4백만 개의 삼중항 사용.

- **4.2 평가**
  - 단어 중복 기반 유사도: BLEU-1/2, ROUGE-1/2, METEOR.
  - 문맥 임베딩 유사도: BertScore.
  - 다양성: 생성 문장 내 유니그램 및 바이그램의 고유 비율.

- **4.3 검색 방법 결과**
  - 도메인 특화 지식베이스를 소스로 다양한 검색 방법 평가(Table 2).
  - 문장 단위 임베딩 이용 `retrieval-each`는 Rouge-1, METEOR에서 기준선 초과.
  - 문맥 단위 평균 임베딩 `retrieval-avg`는 BLEU-2, Rouge-2, BertScore에서 최고 성능.
  - Oracle 방법 `retrieval-diff`는 Dist-1 제외 모든 메트릭에서 최고 점수 기록.
  - 결론: 도메인 지식베이스에서 관련 정보 검색 가능해 생성 개선에 효과적임.
  
  $$ \text{retrieval-diff의 최고점 차이 예시} $$

- **4.4 K-BART 모델 구조 실험**
  - COMET으로 생성된 지식을 문맥에 제공하는 실험 수행.
  - 지식 삽입 방식: `inplace`는 관계 r과 생성된 e2를 e1 옆에 삽입.
  - 마스킹된 셀프어텐션(Att)과 소프트 위치 인코딩(Pos) 적용 여부 비교(Table 3).
  - 결과:
    - `inplace` 기법이 기준선 대비 Dist-1/2 향상 포함 유의미 개선.
    - 마스킹된 어텐션은 일부 메트릭에서 추가 개선, BLEU 점수는 다소 하락.
    - 소프트 위치 인코딩은 단독 또는 결합 시 성능 저하.
  - 해석:
    - BART는 마스킹 어텐션이 어텐션 드롭아웃과 유사해 강인하지만,
    - 소프트 위치 인코딩은 위치 충돌 및 더 많은 학습 데이터 필요성이 문제.

- **4.5 지식 출처에 따른 실험**
  - 검색 기반 방법 `retrieval-diff` 사용 (실제 정답 응답 기반 성능 상한선으로 간주).
  - 지식 출처: ConceptNet 내 표면 텍스트 삼중항 (상식 지식) 및 웹에서 수집한 도메인 특화 지식 비교.
  
  - 도메인 특화 vs 상식 지식 (Table 4):
    - 둘 다 성능 향상에 기여하지만 ConceptNet(상식)은 거의 모든 메트릭에서 우수함(Metric Dist-2 제외).
    - 상식 지식의 양과 적용 범위가 도메인 특화보다 큼.
    - 두 지식 결합 시 성능이 더 우수, 도메인 지식이 상담 특유 정보(예: 약물 부작용) 보완.
    - 실제 검색 결과 중 도메인 지식 문장 비율 > 20%, 상식 지식은 30배 이상 크기임에도 높은 비중 유지.
  
  - 상식 지식 종류별 역할 분석 (Table 5):
    - ConceptNet 관계 범주(Attribution, Causal, Comparison, Conditional, Intentional, Spatial, Temporal) 순차 제거하며 종합 평가.
    - Intentional 관계 제거시 Rouge-1/2, METEOR에서 가장 큰 성능 하락.
    - Causal 관계 제거시 BLEU-1과 BertScore에서 가장 큰 하락.
    - 상담 대화에서 의도 파악, 인과 추론이 핵심임을 시사.
    - 일부 범주(Attribution, Temporal) 제거는 미미하거나 성능 향상 효과도 있음, 노이즈 가능성 존재.

- **4.6 인간 평가**
  - 생성 모델(검색, 생성)과 기본 모델의 응답 비교 평가.
  - 평가 항목: 유창성(문법/자연스러움), 일관성(주제 적합성), 반영성(고객 발언 요약 또는 해석).
  - 3점 리커트 척도 사용.
  - 지식을 사용한 응답에서 어노테이터가 지식이 유용한지 여부 평가(생성: 삼중항, 검색: 문장).
  - 50 샘플 무작위 선정, 두 명의 블라인드 어노테이터 평가.
  
  - 결과 요약 (Figure 4):
    - 실제 정답 응답은 반영성과 일관성 점수 최고, 보통 더 길고 정보가 많음.
    - 지식 사용 모델이 기준선 대비 유창성 및 반영성 개선.
    - 생성 지식 모델은 세 가지 평가 항목에서 기준선보다 우수.
    - 지식의 실제 도움이 된다는 판단 비율: 생성 지식 22%, 검색 지식 38%-48% (도메인, 상식 각각).
    - 모델 성능과 인간 인식 간 차이 존재, 지식 활용 양상 추가 분석 필요.

---

---

# 5 Conclusion

- 본 논문에서는 지식 향상 상담 반영 생성(knowledge enhanced counseling reflection generation)이라는 새로운 과제를 제안함.
- 회상 생성 모델에 지식을 도입하는 다양한 방법(검색 기반 및 생성 기반 설정)을 실험함.
- 두 가지 전략 모두 다양한 자동 평가 지표에서 생성 과제에 긍정적인 영향을 주었으며, 인간 평가를 통해서도 그 효과가 확인됨.
- 상담 도메인 지식이 ConceptNet과 함께 유용한 보완적 지식 소스 역할을 함을 보임.
- 소거 연구(ablation study)를 통해 의도적(intentional) 및 인과적(causal) 관계와 관련된 상식이 상담 도메인에서 필수적임을 확인함.
- 주요 발견 수식 예시:  
  $$\vert \text{Intentional Relationships} \vert + \vert \text{Causal Relationships} \vert \to \text{Essential for Counseling Domain}$$