---
title: "[논문리뷰] BoB- BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data (ACL 2021)"
date: 2025-03-06 00:00:00 +0900
categories:
  - Paper Review
tags:
  - NLP
  - ACL 2021
  - Persona-based Dialogue
---

Abstract: 대화 에이전트를 위한 일관된 페르소나 유지는 중요하며, 제한된 페르소나 데이터의 규모가 이에 대한 훈련의 장벽이 되고 있다. 본 연구에서는 BERT-over-BERT (BoB) 모델을 통해 페르소나 기반 대화 생성을 두 개의 하위 작업으로 분리하여 이러한 문제를 해결하고, 다양한 데이터 셋에서 모델의 우수성을 증명하였다.

---

# 1 Introduction

<img width="396" alt="image" src="https://github.com/user-attachments/assets/6634e754-bc0b-4fe5-91ce-2530916483fc" />

- 다양한 접근법들은 대화 모델에서 명시적인 페르소나 도입을 탐구해 왔다.
- 페르소나는 프로파일과 배경 개인 정보 등의 정체성 요소의 조합으로 정의될 수 있다.
- 페르소나 기반 대화에서는 대화 맥락뿐 아니라 사전에 정의된 페르소나에 따라 반응이 생성되어 일관성 있는 성격을 나타낼 수 있다.
- 기존의 페르소나 기반 대화 모델은 대화 데이터, 특히 PersonaChat과 같은 멤버가 풍부한 페르소나 데이터를 활용한다.
- 이러한 크라우드소싱 데이터 세트는 비용이 많이 들며, 일상 대화에서는 페르소나와 관련된 사례가 적다.
- 대규모 소셜 미디어 데이터를 통한 수집은 페르소나와 관련된 대화 예시가 제한적이어서 페르소나 희소성을 가진다.
- 제한된 개인화 데이터로 훈련된 모델은 페르소나 일관성을 충분히 이해하지 못한다.
  
- 페르소나 기반 대화 생성은 다음과 같은 능력을 요구한다고 설명된다:
  1. 페르소나-응답 일관성 이해
  2. 대화 맥락을 주어진 페르소나 관련 응답 생성
  
- 이 두 가지 주요 작업을 각각 하위 작업으로 분리:
  - 일관성 이해는 대규모 비대화 추론 데이터로 처리 가능
  - 대화 생성은 이미 다양한 대규모 페르소나 희소 데이터 세트가 존재
  
- 이 연구에서는 제한된 개인화 대화와 대규모 비대화 추론 데이터를 병합하여 일관된 페르소나 기반 대화 모델을 학습
- 제안 모델은 다음으로 구성:
  - 인코더 E
  - 응답 생성을 위한 자동회귀 디코더 D1
  - 일관성 이해를 위한 양방향 디코더 D2
  
- 페르소나 P와 대화 쿼리 Q가 주어지면, 인코더 E와 디코더 D1은 응답 맵핑을 캡처하여 초기 대응 표현을 생성
- R1과 페르소나 P는 양방향 디코더 D2에 입력되어 최종 응답 표현으로 변환
  
- 모든 모듈은 BERT에서 초기화되며 BoB 모델로 명명
- 제한 데이터 시나리오에서 모델의 효과성을 검증 (persona-dense 및 persona-sparse 시나리오)
- 모델은 다른 설정에서 잘 일반화되며, 특히 페르소나 일관성에서 강력한 벤치마크보다 성능이 우수
- 연구의 주요 기여:
  - 페르소나 기반 대화 생성 작업을 일관성 이해와 대화 생성으로 분리
  - 제한된 데이터로 페르소나 기반 대화 모델을 훈련하기 위한 BoB 프레임워크 제안
  - 비대화 추론 데이터를 활용한 비가능성 훈련 방법 제안하여 페르소나 일관성 이해를 강화

---

# 2 Related Work

- **Persona-Based Dialogues**  
  - 최근 연구들은 데이터 중심의 접근 방식에서 진행 중임.
  - 개인화된 대화 데이터셋을 통해 암묵적인 페르소나 임베딩(Li et al., 2016b)이나 명시적인 프로필(Qian et al., 2018), 개인 사실(Mazaré et al., 2018) 등 페르소나 관련 특징을 학습.
  - 이후 연구는 상호 페르소나(Liu et al., 2020)나 다단계 페르소나 기반 대화 생성(Song et al., 2020a)을 포함하는 정교한 신경 모델 개발로 확장됨.
  - 다양한 사전학습 방법이 페르소나 대화 생성에 적용됨.
    - Wolf et al. (2019)와 Golovanov et al. (2019)은 사전 학습된 GPT를 페르소나가 풍부한 데이터셋으로 파인튜닝하면 대화 품질이 향상됨을 보여줌.
    - Zheng et al. (2020)은 GPT 기반 모델에서 페르소나 정보 흐름을 제어하는 어텐션 라우팅 메커니즘을 제안.
    - Lin et al. (2020)은 BERT 모델을 대화 생성에 활용하는 방법 탐색.
    - Roller et al. (2020), Madotto et al. (2020) 등의 대규모 사전학습 챗봇들이 페르소나 기반 대화에 효과적임을 증명.

- **Disentangled Representation**  
  - **"분리 표현"**은 모델의 일부 속성만 변경하고 나머지 속성은 그대로 두는 변환으로 정의됨(Higgins et al., 2018).
  - 변이 오토인코더(Kingma and Welling, 2013)는 분리 표현 학습 프레임워크로 간주되며, 여러 방법이 이를 기반으로 구축됨(Kim and Mnih, 2018; Locatello et al., 2019).

- **Unlikelihood Training**  
  - 유사도 학습은 목표 시퀀스의 확률을 최대화하지만, **비유사도 학습**은 부정적인 후보의 확률을 최소화하여 알려진 편향을 수정(Welleck et al., 2019a).
  - Li et al. (2020)은 처음으로 대화의 논리적 모순을 해결하기 위해 비유사도 학습을 탐색.
    - DNLI를 통해 PersonaChat에서 모순된 대화를 추출하여, 모순된 응답의 확률을 줄임.
    - Li et al. (2020)과는 다르게, 신중하게 설계된 디코더를 사용하여 비대화 추론 데이터셋에서도 학습 가능.
    - 이는 페르소나가 풍부한 데이터셋과 페르소나가 희소한 데이터셋 모두에 일반화될 수 있는 가능성을 제공함. (실험에서 보여줌)

---

# 3 Model

<img width="811" alt="image" src="https://github.com/user-attachments/assets/75802edb-b4dd-4afb-98fc-527c5bd1b52e" />

- **목표**
  - 제한된 개인화 데이터를 사용하여 인격 기반 대화 모델 학습 목표.
  - 대규모 비대화 추론 데이터를 활용하여 데이터 제한의 일관성 이해 문제 해결.
  
- **모델 구성 요소**
  - 입력 데이터: 대화 쿼리(Q), 목표 응답(R), 인격(P), 비대화 추론 데이터(N).
  - 모델 M은 인격과 쿼리에 기반하여 일관된 응답 ˆR을 생성.
  - 세 개의 BERT 기반 서브모듈로 구성: 인코더 E, 응답 디코더 D1, 일관성 이해 디코더 D2.
  - D1은 인코딩된 히든 상태(H)를 사용하여 응답 R1을 생성.
  - D2는 비대화 추론 데이터를 통해 일관성 이해를 학습하여 최종 생성 응답 R2를 생성.

- **디스인탱글링 기법**
  - 기존의 인격 기반 대화 모델은 {P, Q, R, Label} 형식의 충분한 데이터 수집 어려움.
  - D2는 R1을 사용하여 생성과 이해를 분리, Q의 참여 없이도 R1을 매핑.
  - 분리가 가능하여 {P, Q, R}와 {P, R, Label} 기반으로 학습 가능.
  
- **BERT-over-BERT 구조**
  - **인코더 E**
    - 인격 P와 대화 쿼리 Q를 입력으로 받아들의 히든 벡터 시퀀스 생성.
    - 멀티헤드 어텐션 사용하여 히든 벡터 시퀀스 H로 변환.
  - **응답 생성 디코더 D1**
    - BERT로 초기화하여 언어 모델을 상속받고 자동 회귀 디코더 방식으로 작동.
    - 교차 주의(attention) 삽입 및 좌측에서 우측으로의 마스크 적용.
  - **일관성 이해 디코더 D2**
    - 인격 일관성 이해를 위해 BERT로부터 초기화.
    - 각 레이어에서 두 번의 멀티헤드 어텐션 수행하여 최종 표현 R2 도출.
  
- **훈련 목표**
  - 대화 생성에는 NLL (Negative Log-Likelihood) 손실 사용.
  - 일관성 이해에는 비호감도 학습 적용.
  - **개인화된 대화 데이터 기반으로 응답 생성 손실 L1** 계산.
  - **비대화 추론 데이터에서 일관성 이해로 비호감도 손실 L2** 계산.
  - L1과 L2 합산 후 역전파로 파라미터 업데이트.

- **훈련 절차**
  - BERT 기본 모델로부터 초기화.
  - Adam optimizer 사용, 학습률을 변화시켜 최적화 수행.

- **훈련 결과**
  - Nvidia Telsa V100 32G GPU에서 훈련.
  - 세부 사항은 공개된 프로젝트 참조.

---

# 4 Experiments

- ## 4.1 데이터셋
  - 제안된 모델의 성능을 평가하기 위해 두 개의 공개 데이터셋에서 실험을 진행
    - **PersonaChat**: 인물 특성을 반영한 대화 데이터셋, ConVAI2 PersonaChat 사용
    - **PersonalDialog**: 중국 소셜 미디어 Weibo에서 수집된 대규모 데이터셋, 대부분의 대화가 인물과 관련되지 않음
  - 비대화 추론 데이터인 **MNLI**와 **CMNLI**를 보조 데이터로 활용
  - 대화 일관성 평가를 위해 **DNLI**와 **KvPI** 도 사용

- ## 4.2 비교 방법
  - 비사전 훈련 모델과 사전 훈련 모델 비교
  - **기본 모델**: Vanilla Transformer
  - **비사전 훈련 모델**: CMAML, GDR
  - **사전 훈련 모델**: LIC, AttentionRouting, GPT2

- ## 4.3 평가 지표
  - 대화의 응답 품질과 인물 일관성을 중점으로 평가
  - 자동 평가 지표: Perplexity, Distinct 1/2, Consistency Score (C.Score), Delta Perplexity (∆P)
  - 사용된 인간 평가 기준: 유창성(Flue.), 정보성(Info.), 관련성(Relv.), 인물 일관성(Per.C.)

<img width="811" alt="image" src="https://github.com/user-attachments/assets/a625a34a-1272-4f62-9a88-d2cdc82e4f9f" />

<img width="811" alt="image" src="https://github.com/user-attachments/assets/7cf6783b-a635-4db1-9dae-eb726019296c" />

- ## 4.4 인물 밀집 시나리오 결과
  - **전체 PersonaChat 데이터셋 결과**: 제안된 모델이 모든 자동 및 인간 평가 메트릭에서 우수한 성능을 보임
  - **제한된 데이터 환경**: 제안된 모델이 기존의 최적 성능을 1/8의 훈련 데이터만으로도 초과
  - 모델이 비대화 추론 데이터를 사용하여 대화 일관성 이해력 개선

- ## 4.5 인물 희소 시나리오 검증
  - **랜덤 테스트셋과 편향 테스트셋** 사용
  - 랜덤 테스트셋에는 다른 모델들과 큰 차이가 없으나, 편향 테스트셋에서 제안된 모델이 대부분의 메트릭에서 우수한 성능

- ## 4.6 분석 및 소거 연구

  <img width="397" alt="image" src="https://github.com/user-attachments/assets/89e860a4-2353-4793-86c2-b1479c05a324" />

  <img width="397" alt="image" src="https://github.com/user-attachments/assets/ec139c19-3a7d-4166-9195-94974bcf7bbd" />

  - **주요 질문**:
    1. BoB 모델의 이해 능력의 핵심은 무엇인가?
    2. 사전 훈련된 모델이 개인화된 대화를 통해 일관성을 이해할 수 있는가?
    3. 매우 낮은 PPL은 BERT 모델의 초기화에서 기인하는가?
  - **소거 실험 결과**:
    - 일관성 이해의 핵심은 **비호감 목적(UL)** 훈련
    - 사전 훈련된 모델은 개인화된 대화를 통해 일관성을 이해하지 못함
    - 아키텍처에서 **D2**가 PPL에 가장 큰 기여

- ## 4.7 재현성
  - BoB 모델의 구현은 공개된 GitHub 리포지토리 제공

각 소주제는 실험 방법과 결과, 모델 성능 증가의 이유, 각 모델의 강점 및 약점을 종합적으로 다룸.

---

# 5 Conclusions

- 새로운 BERT 기반 대화 모델을 제안하였으며, 제한된 개인화된 데이터로부터 학습할 수 있도록 응답 생성과 일관성 이해를 분리하였습니다.
- 비대화 추론 데이터를 활용한 비 likelihood 학습을 통해 모델의 이해 능력을 강화하였습니다.
- 두 개의 공개 데이터셋을 대상으로 실험한 결과, 제한된 개인화된 대화 데이터로 훈련된 경우에도 강력한 기존 방법들보다 유의미한 개선을 이루었습니다.
- 본 연구는 중국 국가 자연과학재단과 중국 과학기술 혁신 2030 주요 사업의 지원을 받았습니다.
- 익명의 리뷰어들에게 유익한 의견과 제안에 대해 감사드립니다.
- 이 연구는 공개된 작업에서 파생된 데이터만 사용하여 개인정보 문제를 배제하고, 참가자의 신원 특성을 추론하거나 속성을 부여하지 않습니다.
- 최종 목표는 대화 시스템에 자기 논리적 일관성을 부여하는 것으로, 특정 인간을 모방하는 것이 아닙니다.

---

# 독자 의견

- 본 연구는 BERT를 생성모델처럼 사용하였으며, 학습 데이터셋으로는 각각 다른 데이터로 응답 손실과 일관성 손실을 계산하여 학습했음.
- BERT 모델을 1개는 인코더로써, 2개는 디코더로써 사용한 방법이 특이했다. 하지만 이 방법이 GPT와 같은 디코더 모델 또는 T5와 같은 인코더-디코더 모델보다 어느 면에서 더 나은지, 왜 3개의 BERT 모델을 사용했는지에 대한 설명이 부족하다.
