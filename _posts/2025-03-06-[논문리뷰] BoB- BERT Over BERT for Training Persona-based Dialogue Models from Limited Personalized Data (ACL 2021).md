---
title: "[논문리뷰] BoB- BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data (ACL 2021)"
date: 2025-03-06 00:00:00 +0900
categories:
  - Paper Review
tags:
  - NLP
  - ACL 2021
  - Persona-based Dialogue
---

Abstract: 대화 에이전트의 일관된 페르소나 유지를 위해, 연구에서는 페르소나 기반 대화 생성을 두 개의 하위 작업으로 나누어 새로운 BERT-over-BERT(BoB) 모델을 제안하고, 이 모델이 반응 생성과 일관성 이해를 효과적으로 학습함을 보여준다. 실험 결과, 제안된 모델이 응답 품질 및 페르소나 일관성에서 강력한 기준 모델보다 우수한 성능을 보였다.

---

# 1 Introduction

- 다양한 접근법이 대화 모델에서 명시적 페르소나를 도입하기 위해 탐구됨 (Qian et al., 2018; Song et al., 2019; Zheng et al., 2020; Liu et al., 2020).
- 페르소나는 프로필과 개인적 배경 사실 등의 정체성 요소의 조합으로 정의됨.
- 페르소나 기반 대화에서 생성된 응답은 대화 맥락뿐만 아니라 미리 정의된 페르소나에 따라 결정됨.
- 기존의 페르소나 기반 대화 모델은 PersonaChat과 같은 페르소나 관련 대화 데이터셋을 많이 활용함 (Wolf et al., 2019; Golovanov et al., 2019).
- 크라우드 소싱된 데이터셋은 풍부한 페르소나 특징을 포함하지만, 수집 비용이 비쌈.
- 일상 대화는 항상 페르소나와 관련되지 않으며, Twitter 분석에 따르면 10% 미만의 메시지만 개인적인 에피소드나 활동을 포함함.
- 대규모 소셜 미디어 데이터는 페르소나 관련 대화를 적게 포함하여 "페르소나 부족" 현상이 발생함.
- 제한된 페르소나 데이터로 훈련된 모델은 페르소나 일관성을 충분히 이해하지 못할 수 있음.
- 페르소나 기반 대화 생성의 본질을 재고하면, 대화 에이전트는 페르소나-응답 일관성을 이해하고 대화 맥락에 맞는 응답을 생성할 능력이 필요함.
- 일관성 이해를 위한 대규모 비대화 추론 데이터 이용 가능 (SNLI, MNLI 등).
- 본 연구에서는 제한된 개인화된 대화로부터 일관된 페르소나 기반 대화 모델을 학습하고자 함.
- 제안된 모델은 인코더 E, 응답 생성을 위한 자기 회귀 디코더 D1, 일관성 이해를 위한 양방향 디코더 D2로 구성됨.
- 모델의 효과를 검증하기 위해 두 가지 제한된 데이터 시나리오에서 실험: 1) 페르소나 밀집 시나리오, 2) 페르소나 희소 시나리오.
- 이 연구의 기여는 다음과 같음:
  - 페르소나 기반 대화 생성을 두 개의 하위 작업(일관성 이해 및 대화 생성)으로 분리함.
  - 제한된 데이터로부터 페르소나 기반 대화 모델을 훈련하기 위한 BERT 기반 생성 프레임워크 BoB 제안.
  - 페르소나 일관성 이해를 강화하기 위한 비용소거 훈련 방법 도입.

---

# 2 Related Work

- **퍼소나 기반 대화**
  - 최근 연구는 데이터 기반으로 퍼소나 대화 생성에 초점을 맞춤.
  - 개인화된 대화 데이터셋에서 퍼소나 관련 특징을 학습함.
    - 암시적 퍼소나 임베딩 (Li et al., 2016b)
    - 명시적 프로필 (Qian et al., 2018) 및 개인적 사실 (Mazaré et al., 2018)
  - 더 정교한 신경망 모델이 등장:
    - 상호 퍼소나 모델링 (Liu et al., 2020)
    - 다단계 퍼소나 기반 대화 생성 (Song et al., 2020a)
  - 다양한 사전 훈련 방법 적용:
    - GPT를 퍼소나 밀집 데이터셋에 미세 조정하여 응답 품질 개선 (Wolf et al., 2019; Golovanov et al., 2019)
    - 퍼소나 정보 흐름 제어를 위한 주의 라우팅 메커니즘 제안 (Zheng et al., 2020)
    - BERT 모델을 활용한 대화 생성 탐색 (Lin et al., 2020)
  - 대규모 사전 훈련 챗봇의 효과성 연구 (Roller et al., 2020; Madotto et al., 2020)

- **분리된 표현**
  - “분리”는 모델의 특정 속성만 변경하고 나머지는 불변으로 유지하는 변환으로 정의 가능 (Higgins et al., 2018)
  - 변별 자동 인코더(Variational Autoencoder)는 분리 표현 학습 프레임워크로 볼 수 있음 (Kingma and Welling, 2013)
  - 다양한 방법이 이 안에서 개발됨 (Kim and Mnih, 2018; Locatello et al., 2019)

- **언라이클리후드 훈련**
  - 가능성을 최대화하려는 가능성(Likelihood)와 부정 후보의 가능성을 최소화하여 알려진 편향을 수정하는 언라이클리후드(Unlikelihood) 개념 (Welleck et al., 2019a)
  - Li et al. (2020)은 대화의 논리적 모순을 해결하기 위해 언라이클리후드 훈련을 처음 탐구.
    - PersonaChat에서 반박된 대화를 DNLI를 통해 추출 (Welleck et al., 2019b)
    - 반박된 응답의 확률 감소를 위한 언라이클리후드 훈련 적용.
  - 우리의 모델은 정교하게 설계된 디코더를 통해 대규모 비대화 추론 데이터셋에서 학습할 수 있으며, 다양한 시나리오에서 일반화 가능함.

---

# 3 Model

- **목표 설정**
  - 개인화된 데이터에서 페르소나 기반 대화 모델 학습.
  - 일관성 이해 문제를 해결하기 위해 대규모 비대화 추론 데이터 활용.

- **모델 구성**
  - 입력: 대화 쿼리(Q), 목표 응답(R), 페르소나(P), 비대화 추론 데이터(N).
  - 모델 M의 출력: 일관성 있는 응답 ˆR 생성.
  - M은 BERT 기반의 세 가지 서브모듈로 구성됨:
    1. **인코더(E)**: 페르소나와 쿼리를 인코딩하여 숨겨진 상태 H 생성.
    2. **응답 디코더(D1)**: H에 대해 교차 주의를 수행하고 대략적인 응답 R1 생성.
    3. **일관성 이해 디코더(D2)**: 비대화 추론 데이터 N을 학습하여 P와 R1을 최종 표현 R2로 변환.

- **분리(disentangling)**
  - 응답 생성을 위해 페르소나 P와 대화 쿼리 Q가 필요.
  - 일관성 이해를 위해 P, 응답 R, P와 R 간의 일관성 레이블 필요.
  - D2는 R1을 Q에 의존하지 않고 R2로 매핑하여 생성과 이해를 분리함.

- **BERT-over-BERT 아키텍처**
  - **인코더**: 표준 BERT 모델처럼 작동하여 페르소나 P와 대화 쿼리 Q를 인코딩.
  - **응답 생성 디코더(D1)**: 교차 주의 및 왼쪽->오른쪽 마스크를 적용하여 자동 회귀 방식으로 응답 생성.
  - **일관성 이해 디코더(D2)**: P와 R1으로부터 정보를 통합하여 최종 표현 R2 생성.

- **훈련 목표**
  - 대화 생성 및 일관성 이해를 위해 부정 로그 우도(NLL) 손실 및 비일관성 손실 적용.
  - 훈련 절차:
    1. 대화 생성 손실 L1 계산 (P, Q, R 입력).
    2. 비대화 추론 데이터에서 얻은 D+와 D-를 바탕으로 일관성 이해 손실 L2 계산.
    3. L1과 L2를 합산하여 매개변수 업데이트.

- **모델 세부사항**
  - BERT 기본 모델에서 초기화, 12층 및 숨겨진 크기 768으로 설정.
  - Adam 옵티마이저 사용, 학습률은 5e-6에서 5e-5로 변동.
  - α는 5e-3, β는 0.1로 설정, Nvidia Tesla V100 32G GPU에서 훈련.

---

# 4 Experiments

## 4.1 데이터세트
- 제안된 모델의 성능 평가를 위한 대화 생성 실험은 두 개의 공개 데이터세트에서 수행:
  - **PersonaChat**: 풍부한 개인 정보를 포함한 데이터세트. 개인 사실에 기반한 대화로, ConvAI2 PersonaChat 사용.
  - **PersonalDialog**: 중국 소셜 미디어 Weibo에서 수집된 대규모의 개인 정보가 부족한 데이터세트. 두 개의 테스트 세트 제공: 무작위 테스트 세트와 편향 테스트 세트.
- 일관성 이해 문제를 해결하기 위해 비대화 추론 데이터인 MNLI와 CMNLI를 보조 데이터로 사용.
- 모델 성능 비교를 위해 DNLI와 KvPI 두 개의 대화 추론 데이터셋 활용.

## 4.2 방법 비교
- 비교된 모델: 프리트레인된 모델과 비프리트레인 모델 모두 포함.
- **기본 모델**: Vanilla Transformer를 기본 모델로 사용.
- **비프리트레인 모델**:
  - CMAML: 메타 학습 기반 방식으로 적은 샷의 개인 정보에서 학습.
  - GDR: PersonaChat에 대한 추론 능력을 도입한 생성-정제 프레임워크.
- **프리트레인 모델**:
  - LIC: PersonaChat에서 가장 높은 성능을 보인 모델.
  - AttentionRouting: 개인 정보 부족 데이터셋을 위한 프리트레인 방법.
  - GPT2: PersonaChat에서 thorough한 비교를 위한 파인튜닝된 모델.

## 4.3 평가 지표
- 개인화된 대화의 두 가지 주요 측면에 초점을 맞춤: 응답 품질과 개인 정보 일관성.
- **자동 평가 지표**:
  - Perplexity (PPL) 및 distinct 1/2 (Dist.1/2)를 활용.
  - 일관성을 평가하기 위한 Consistency Score (C.Score) 및 Delta Perplexity (∆P) 사용.
- **인간 평가**:
  - 전문 평가자 팀을 모집하여 대화 품질과 개인 정보 일관성을 평가.
  - 평가 기준: 유창성, 정보성, 관련성 및 개인 정보 일관성.

## 4.4 개인 정보가 밀집한 결과
- 전체 PersonaChat 실험 결과: 모든 자동 및 인간 평가 지표에서 우수한 성능을 달성.
- 모델의 PPL과 ∆P에서 유의미한 향상을 보여줌.

## 4.5 개인 정보가 부족한 유효성
- 개인 정보가 부족한 시나리오에서 모델을 검증.
- Random 테스트에서 모든 방법이 일관되게 다른 방법을 초과하지 못함.
- Biased 테스트 세트에서 대부분의 지표에서 최고의 성능을 기록.

## 4.6 분석 및 블라인드 연구
- BoB 모델 성능 향상의 주요 원인을 분석.
- **Q1**: 이해의 핵심은 비슷하지 않았던 데이터(Contradictions)에 큰 PPL을 할당하는 것.
- **Q2**: 프리트레인 모델은 개인화 대화에서 일관성을 거의 이해하지 못함.
- **Q3**: BoB 아키텍처의 D2가 PPL에 가장 크게 기여함.

## 4.7 재현성
- BoB 모델 구현은 [GitHub 링크](https://github.com/songhaoyu/BoB)에서 제공.

---

# 5 Conclusions

- 새로운 BERT 기반 대화 모델을 제안함
  - 제한된 개인화된 데이터에서 학습 가능
  - 응답 생성과 일관성 이해를 분리하여 학습
  
- 비대화 추론 데이터를 통한 비 전통적 훈련 방법 도입
  - 모델의 이해 능력 향상
  
- 공개 데이터셋 두 개를 통한 실험 결과
  - 제한된 개인화 대화 데이터로도 훈련 가능
  - 강력한 방법들보다 의미 있는 개선 결과 도출

- 연구 지원 및 감사
  - 중국 국가 자연 과학 기금과 과학 기술 혁신 2030 주요 프로젝트 지원
  - 익명의 리뷰어들에게 감사

- 윤리적 진술
  - 인물 기반 대화 연구는 퍼소나 불일치 문제 해결 목표
  - 대화 시스템에 특정 퍼소나 부여하여 불일치 문제 완화
  - 데이터 자원은 모두 출판된 자료에서 수집, 개인 정보 문제 없음
  - 참가자의 정체성 특성을 자동으로 추론하거나 분류하지 않음