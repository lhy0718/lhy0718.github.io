---
title: "[논문리뷰] PK-ICR- Persona-Knowledge Interactive Multi-Context Retrieval for Grounded Dialogue (EMNLP 2023)"
date: 2025-04-08 17:40:00 +0900
categories:
  - Paper Review
tags:
  - EMNLP 2023
  - Persona-based Dialogue
---

대화 시스템에서 관련된 페르소나와 지식을 함께 식별하는 것이 중요하다는 점을 강조하며, 복잡한 다중 맥락 대화에서 효과적인 응답 생성을 위한 새로운 접근 방식을 제안한다. 새로운 기초 검색 방법과 함께, 데이터 증강과 관련된 난이도가 높은 부정 샘플에 대한 랭킹 성능을 측정하는 독창적인 평가 방식을 도입하였다.

---

# 1 Introduction

- 효과적인 대화 에이전트는 응답 생성을 향상시키기 위해 외부 컨텍스트가 필요함.
- 개별 페르소나와 지식 기반 대화 시스템에 대한 연구는 진전을 보였으나, 두 가지를 결합한 연구는 적음.
- 산업에서 페르소나 기반 QA 시스템에 대한 관심이 제한적임.
- 이전 연구들은 대화에서 지식 추출을 직접 최적화하는 것의 중요성을 강조함.
- 실용적인 설정에서는 여러 개의 컨텍스트의 유용성을 가정하는 것이 더 현실적임.
- DIALKI에서의 지식 식별 과제를 따르며, 페르소나와 지식을 동시에 식별하는 'Persona and Knowledge Dual Context Identification' 과제를 정의.
- 페르소나 기반 QA 작업과 유사하나, 우리 연구는 대화형 설정에 초점을 맞춤.
- 연구 목표는 구성 요소 간 상호작용을 형식화하여 다중 컨텍스트 검색 방법론을 향상시키는 것.
- 기존 작업을 재사용하여 질문 답변(QA)을 유망한 후보로 제안함.
- 새롭게 제안한 방법론인 Null-positive Rank Test (NRT)를 통해 하드 네거티브 특성을 정량화함.

### 주요 기여
1. 페르소나 및 지식의 이중 컨텍스트 검색 방법론을 개발하여 대화 컨텍스트의 성공적인 검색을 achieved하며, SOTA 성능 달성.
2. 대화 컨텍스트 상호작용의 크로스-태스크 적응을 위한 프레임워크 도입.
3. 페르소나 증강된 대화의 하드 네거티브 특성을 평가할 수 있는 새로운 테스트 제안.

---

# 2 Related Works

- **지식 강화 텍스트 생성** (Zhu et al., 2022; Yu et al., 2022)
  - 내부 또는 외부의 근거 맥락을 포함하여 대화 및 Q&A와 같은 생성 작업을 해결.
  - 외부 지식 시스템에 대한 "지식 선택" 개발에 중요한 기여.
  - 다양한 유형의 근거 맥락(페르소나 및 지식)을 효과적으로 선택하는 방법을 모델링한 첫 연구.

- **대화 시스템 개발**
  - 외부 지식 정보를 의존하는 대화 시스템에 대해 연구.
  - 자주 사용되는 데이터세트: 
    - Wizard of Wikipedia (Dinan et al., 2018)
    - PersonaChat (Zhang et al., 2018b)
  - 최근 데이터세트: 페르소나 및 지식에 기반한 대화(Jang et al., 2021) 또는 혼합 시나리오(Shuster et al., 2020; Smith et al., 2020).

- **페르소나 및 지식 조사**
  - 페르소나와 지식을 다른 근거로 취급, 각각의 특성을 조사.
  - 대화 에이전트와 페르소나 또는 지식을 통합하는 연구가 활발히 진행됨.
    - 페르소나 관련 연구: Zhang et al. (2018a); Majumder et al. (2020); Xu et al. (2020); Rashkin et al. (2019) 
    - 지식 관련 연구: Dinan et al. (2018); Zhao et al. (2020); Liu et al. (2021); Li et al. (2020); Ghazvininejad et al. (2017).

- **제한 사항 및 해결책**
  - 페르소나 전용 방법은 상세한 지식의 활용을 제한.
  - 관련 지식은 사용자 페르소나에 따라 달라질 수 있음.
  - 모든 대화 요소의 상호작용을 연구하여 이러한 한계를 보완.

- **지식 식별(Knowledge Identification) 작업**
  - 최근 문서에서 정의됨(Wu et al., 2021).
  - 맥락 식별을 중요한 작업으로 간주하고 대화 설정에서의 유사성 탐구.
  - 연구는 페르소나와 지식을 이중 맥락으로 지정하여 대화에서 함께 검색되도록 확장.

---

# 3 Methodology

- **대화 전환의 상호작용 극대화**
  - 대화의 모든 구성 요소 간의 상호작용을 극대화하여 효과적인 대화 기초 정보 검색을 목표.

- **지식 검색 (Section 3.1)**
  - 최상위 순위 작업으로 설정.
  - 제로샷 방식으로 지식 검색 해결.

- **인물 검색 (Section 3.2)**
  - 점수 기반 작업으로, 참 인물 레이블이 1 또는 0인 경우 처리.

- **하드-네거티브 특성 조사 (Section 3.3)**
  - Persona-augmented Dialogue의 하드-네거티브 특성을 조사하기 위해 null-positive rank test 도입.

---

# 3.1 Knowledge Retrieval

- 대화 구성 요소를 QA 프롬프트로 적응한 새로운 방식 소개
- 이 방식은 짧은 질문 및 설명 답변 쌍을 복제하기 위해 모두 연결된 대화의 관계를 추론
- 수식 E : {Qi, Aj}= {Pi + D, Kj}에서 구성 요소 설명:
  - E는 모델에 입력
  - Qi: 특정 QA 후보
  - Aj: 특정 대화 답변
  - Pi: 개인 정보
  - Kj: 지식 정보
  - D: 쌍을 위한 대화
- 모든 i, j 쌍에 대해 최적의 지식 검색:
  - 수식: $$besti, bestj = \text{arg max}_{i \in 1...n,j \in 1...m} Mq\{Pi + D, Kj\}$$
  - 여기서 besti, bestj는 최고의 개인 정보/지식 쌍의 인덱스
  - truej는 예측된 지식 K의 인덱스
- besti는 폐기됨
- Mq는 쌍의 가능성 점수를 제공하는 QA 검색 모델
- n: 개인 정보 수, m: 지식 수

---

# 3.2 Persona Retrieval

- **모델 세부 조정**:
  - QA 검색 모델을 증강된 페르소나 및 예측된 실제 지식 쌍을 사용하여 세부 조정.
  
- **데이터 셋 및 준비**:
  - 데이터 표현: $$E' : \{Qi, A_{true}\} = \{P_i + D, K_{truej}\}$$ 명시.
  - $$E'_{train}$$는 별도의 훈련 세트로 구성되며, 라벨이 지정된 실제 지식을 포함함.
  
- **모델 훈련**:
  - $$E'$$는 기존의 $$E$$와 유사한 방식으로 모델에 입력되지만, 실제 지식은 고정됨.
  - $$M_f$$는 세부 조정된 모델.

- **확률 점수 계산**:
  - 선택된 데이터 쌍으로부터 페르소나 가능성 점수 추정: $$p_i = M_f\{P_i + D, K_{truej}\}$$.
  - 페르소나 검색에 대한 임계값 적용:
    - $$true_i = \mathrm{arg \ max} \ i \{ p_i, \text{if } p_i \ge p_{thres} \text{ otherwise } 0 \} \text{ for } i \in 1...n$$.

- **계산 효율성**:
  - 추가 계산 복잡도가 $$O(nm)$$에서 $$O(n)$$으로 감소.
  - 부정적인 쌍의 수가 300만에서 30만으로 감소, 10배 속도 향상.

- **정보 검색**:
  - 최종적으로 검색된 정보:
    - $$R : \{D, P, K\} = \{D, P_{truei}, K_{truej}\}$$.
  - $$R$$은 주어진 대화 턴에 대한 실제 페르소나 및 지식 쌍.

---

# 3.3 Null-positive Rank Test

- 모델 Mq를 Personaaugmented Dialogue (Pi + D)로 미세 조정하여 모델 Mf를 생성하는 것은 특정한 선택임.
- QA 설정은 조정 없이는 사용할 수 없고, 이는 모델의 점수 출력이 왜곡됨에 따라 발생함 (Fig. E1).
- Persona-augmented Dialogue는 하드 네거티브 샘플링으로 해석됨 (Appendix G) 
  - 이 증강은 구별하기 어려운 샘플을 생성함.
  
- 새로운 'null-positive rank test' 방법론을 제시하여 Pi + D 샘플의 내재적 평가 난이도를 정량화함.
  - MRR, MAP, NDCG와 같은 순위 기준에서 영감을 받아, 특정 샘플의 순위를 통해 모델 성능을 계산함.
  - 이 방법은 점수 출력과 상관없이 관심 있는 샘플에 대한 모델의 구별 성능을 분리함 (Fig. 2, Table A1의 예시).

- 'null-positive (Po)' 샘플을 모델의 기준점으로 지정.
- 성능 측정 항목:
  - 긍정 샘플도 생성됨 (Table A1 참조).
  - 이 증강은 페르소나 전용 작업에 적합함.
  
- 모델이 null-positive 샘플을 비트리비얼하게 유사하지 않은 증강 샘플과 관련하여 올바르게 순위를 매길 수 있는지 평가.
  
- '비트리비얼성' 메트릭은 다음과 같이 평균 거리를 계산:
  $$\mathcal{¬T} = \frac{\sum_{r_{\text{max}}}^{r_{\text{min}}} n_r \cdot |r|}{\sum_{r_{\text{max}}}^{r_{\text{min}}} n_r}$$
  
- 여기서 $$\mathcal{¬T}$$는 비트리비얼성 메트릭으로, 낮은 값일수록 모델의 순위가 좋음을 의미.
- $$n_r$$는 조정된 순위 $$r$$을 가진 Po 샘플의 수 (Fig. 2).
- 각 모델 Mq, Mf에 대한 "비트리비얼성" 보고.

---

# 4 Experiment Setup

- **데이터셋**: 
  - Call For Customized Conversation (Jang et al., 2021) 사용
  - 각 대화는 사용자의 페르소나와 위키피디아 지식 기반 정보로 구성

- **모델**:
  - MS MARCO 데이터셋 (Nguyen et al., 2016)에서 훈련된 여러 신경 질문 응답 모델 활용

- **상세 정보**: 
  - 추가 세부사항은 부록 D에 기재

---

# 5.1 Knowledge Retrieval

- 대화, 인격, 지식 상호작용의 실험 및 패러메트리브 평가가 최상의 성능을 발휘함.
- 표 1에서는 대화 전용 모델 대비 우리의 프롬프트 입력에서 성능 향상을 확인. 
  - 모든 대화 요소가 중요함을 나타냄.
- 세 가지 샘플 중 하나가 양성 샘플 아래 등급을 가져야 함.
  - "중립 등급 테스트"라는 이름도 고려됨.
- 실제 시나리오에서는 여러 양성 샘플이 있을 수 있으며, 우리의 지표는 짧은 등급 거리의 가중치를 덜 씀.
- 다양한 모델 성능 비교:
  - Baseline: 86.86%
  - BERT-base: 71.82%
  - Proto-gen: 87.75%
  - D & Pi: 86.78%
  - Pi & Ktruej: 86.75%
  - Pi + D & Ktruej: 83.83%
  - Pi & Ktruej (fine-tuned): 89.12%
  - Pi + D & Ktruej (fine-tuned): 91.57% (+4.71)
- 표 2: 비대칭 QA 프롬프트별 인격 검색 정확도 (크로스 인코더) 
  - 제로-샷 지원 여부.
- 표 3: Pi + D & Ktruej 크로스 인코더 모델의 널-양성 순위 테스트 결과.
  - "Ours" 모델은 파인 튜닝된 변형, Z.S.는 제로-샷 모델.
  - $$p_{thres} = 0$$에서 인격 검색 정확도 보고 및 비단순성의 여러 변형 ($$eq. 9$$, $$eq. 12$$, $$eq. 10$$, $$eq. 11$$).
  - 비단순성이 적을수록 우수한 순위 능력 의미.

---

# 5.2 Persona Retrieval

- **성능 비교**: 
  - 표 2에 따르면, 파인튜닝된 Pi + D 모델이 가장 우수한 성능을 보임.
  - 비파인튜닝된 Pi + D 모델은 낮은 성능을 보임.

- **원인 분석**:
  - QA 관계가 대화의 실제 지식에 영향을 미치는 것이 성능 저하의 원인임 (Fig. E1 참조).

- **필요성 강조**:
  - 크로스 도메인 적응을 활용하기 위해 모델의 파인튜닝이 필요함.

---

# 5.3 Null-positive Rank Test

- Pi + D의 효과를 검증하기 위해 null-positive rank test를 수행함.
- 모델의 성능이 top-1 rank 설정에서 증가함:
  - 임계값: 0, 정확도: 0-Acc.
- 모든 비사소성(non-triviality) 변형이 두 모델에서 개선됨.
- 샘플 수를 rank별로 분석함.

---

# 6 Discussions and Conclusion

- 본 논문에서는 PK-ICR이라는 페르소나-지식 이중 맥락 검색 방법을 소개함.
- QA-informed prompt-augmentation을 통해 대화 구성 요소 간의 상호작용을 활용.
- 제로샷 최상위 1 지식 검색 및 정확한 페르소나 점수를 수행함.
- Null-positive rank test라는 새로운 평가 방법을 제시하여 Persona-augmented Dialogue의 하드-네거티브 효과를 고립시킴.
- Call For Customized Conversation 벤치마크의 검색 작업에서 SOTA 결과를 달성하고, 비트리비얼 메트릭과 임계값 없는 성능의 정렬을 보고함.
- 대화 맥락을 상호작용하는 여러 구성 요소의 전체로 모델링하면 더 복잡한 대화 시스템을 다루는 데 도움이 될 것으로 기대함.
- 미래의 방향 제안:
  - 다양한 형태의 그라운딩 통합 (페르소나/지식 요약, 웹 검색, 위키 문서 등).
  - 장기 기억 또는 상호 페르소나와 같은 더 정교한 대화 설정으로 방법론 확장.
- 페르소나 인식 대화 증강은 인간 행동 모델링의 한 형태로, Turing test와 관련됨.
- Null-Positive Rank Test의 효과성을 검토하여 대화 증강의 성공을 확인함.
- 두 가지 페르소나-대화 증강 방향 제안:
  1. 페르소나와 지식을 먼저 증강하는 등의 다양한 상호작용 강조.
  2. 고급 프롬프트 지정으로 각 그라운딩에 대한 정보를 제공하여 성능 향상 가능성 탐색.
- Null-Positive Rank Test(NRT)는 정보 검색 및 순위 모델에 광범위하게 적용 가능함.
- 긍정적 및 부정적 대화 증강만을 사용하여 모델 훈련했으나, "중립" 대화에 대한 순위 정확성이 개선됨을 보고함.
- 이 평가 방법은 데이터 증강 또는 개인화 검색/QA와 같은 다른 순위 작업에 직접 활용될 수 있음.
- 미래 작업에 대해 우리 검토 방법을 수행할 것을 권장함.

---

# Limitations

- 대화 기반 검색을 QA 작업으로 전이하는 접근 방식의 한계:
  - 특정 과제로의 제한
  - 프롬프트 구성의 한계
  
- 다중 컨텍스트 시나리오를 위한 귀납적 편향이 있는 검색 모델이 개선 가능

- 다중 컨텍스트 상호작용 및 검색 연구
  - 대화 시스템의 발전에 중요한 문제
  
- 향후 연구 방향:
  - 그라운딩 상호작용에 기반한 하향식 생성 작업 모델링 보고 가능