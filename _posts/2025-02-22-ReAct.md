---
title: "ReAct: Synergizing Reasoning and Acting in Language Models"
date: 2025-02-20 00:00:00 +0900
categories:
  - Agents
tags:
  - Agents
  - LLM
---

요약: 추론 추적(reasoning traces)과 작업별 행동(task-specific actions)을 교차적으로 생성하여 두 가지 간의 더 큰 시너지를 가능하게 하는 방법인 ReAct를 제안한다.

# 1. 서론

## 연구의 배경

- 인간의 지능은 **추론(reasoning)과 행동(acting)**을 자연스럽게 결합하여 작업을 수행하는 능력을 포함한다.  
- 예를 들어, 요리를 할 때 “재료를 다 썰었으니, 이제 물을 끓여야겠다”라고 생각(추론)한 후, 실제로 행동(물 끓이기)한다.  
- 이러한 과정에서 우리는 **현재 상황을 추적하고**, **계획을 조정하며**, **필요한 정보를 검색**하는 등 **추론과 행동을 결합**한다.

## 기존 대규모 언어 모델(LLM)의 한계  
- **추론(Chain-of-Thought, CoT) 방식**: 모델이 내부 지식만 활용하여 논리를 전개하지만, 외부 정보를 업데이트하지 못해 오류(환각, hallucination)가 발생할 수 있음.  
- **행동(Action-only) 방식**: 모델이 외부 환경과 상호작용할 수는 있지만, 복잡한 논리적 사고가 부족하여 비효율적인 정보 검색이 발생함.

## ReAct 접근법의 제안
- **ReAct(Re**asoning + **Act**ing)**는 LLM이 **추론 과정과 행동을 교차적으로 수행**하는 새로운 방식이다.  
- 이를 통해 모델은 다음과 같은 이점을 얻는다.  
  - **추론(trace)**: 모델이 현재 진행 상황을 인식하고 조정할 수 있음.  
  - **행동(action)**: 외부 환경과 상호작용하여 추가 정보를 수집할 수 있음.  
  - **더 나은 의사결정**: 행동을 통해 얻은 정보를 활용하여 보다 정확한 판단을 수행할 수 있음.  

## 주요 실험 및 결과
- ReAct는 다양한 작업에서 기존 방법보다 **더 나은 성능과 해석 가능성**을 제공한다.  
  - **질문 응답(HotpotQA) 및 사실 검증(Fever)**: 환각 오류를 줄이고, 외부 정보를 활용하여 더 신뢰할 수 있는 답변을 생성.  
  - **상호작용 기반 의사결정(ALFWorld, WebShop)**: 강화 학습 및 모방 학습을 뛰어넘는 성능을 보이며, 소수의 예제만으로도 효과적인 학습이 가능.

## 연구 기여
1. 추론과 행동을 결합하는 **ReAct 패러다임** 제안.  
2. 다양한 작업에서 ReAct의 **우수한 성능과 해석 가능성**을 실험적으로 입증.  
3. 추론이 행동을 돕고, 행동이 추론을 강화하는 **상호보완적 관계**를 분석.  
4. 향후 **강화 학습 및 대규모 AI 시스템과의 결합 가능성**을 제시.  

# 2. `ReAct`

## ReAct 개념 및 원리
- ReAct는 **추론(Reasoning)**과 **행동(Acting)**을 결합하여 **더 효과적으로 작업을 수행할 수 있도록 하는 접근법**이다.
- 기존 방법들은 추론(CoT)과 행동(Action)을 각각 독립적으로 수행했지만, **ReAct는 이를 교차적으로 수행함으로써 상호보완적인 장점을 극대화**한다.

## 기존 접근법의 한계
- **추론(CoT)만 수행하는 방식**  
  - 모델이 논리적으로 사고할 수 있지만, 외부 환경과 상호작용할 수 없어 새로운 정보를 업데이트할 수 없음.  
  - 결과적으로, **잘못된 정보(환각, hallucination)가 포함될 가능성이 높음**.  

- **행동(Action-only) 방식**  
  - 모델이 외부 데이터를 검색할 수 있지만, 어떤 정보를 찾아야 하는지에 대한 체계적인 계획이 부족함.  
  - 정보 검색이 비효율적이며, 중요한 맥락을 놓칠 가능성이 큼.  

## ReAct의 핵심 원리
- **모델의 행동 공간(action space) 확장**  
  - 일반적으로 AI 모델은 주어진 입력에 대한 **행동(action)만을 예측**함.  
  - ReAct는 행동뿐만 아니라 **자연어 기반의 추론(trace)**도 함께 생성하여 더 나은 의사결정을 가능하게 함.

- **추론과 행동을 교차적으로 수행**  
  - **추론 → 행동**: 모델이 먼저 상황을 분석하고 어떤 행동을 할지 결정함.  
  - **행동 → 추론**: 모델이 외부 환경과 상호작용한 후, 얻은 정보를 바탕으로 다시 추론을 진행함.  

## ReAct의 장점
1. **더 나은 의사결정**  
   - 행동을 수행하기 전에 **논리적 사고**를 통해 더 효율적인 행동을 선택할 수 있음.  
2. **환각 오류(hallucination) 감소**  
   - 외부 환경에서 직접 정보를 검색하여 잘못된 정보를 줄일 수 있음.  
3. **해석 가능성(Interpretability) 증가**  
   - 모델이 내린 결정을 사람이 쉽게 이해할 수 있도록 함.  
4. **다양한 작업에 적용 가능**  
   - 질문 응답, 사실 검증, 게임 플레이, 웹 탐색 등 다양한 작업에서 활용할 수 있음.

# 3. Knowledge-Intensive Reasoning Tasks

## 실험 개요
- ReAct를 **지식 기반 추론(knowledge-intensive reasoning) 작업**에 적용하여 효과를 평가함.
- 대표적인 두 가지 작업을 선정하여 실험 진행:
  1. **HotpotQA**: 다단계(multi-hop) 질문 응답 시스템  
  2. **FEVER**: 사실 검증(fact verification)  

- 두 작업 모두 외부 지식(위키피디아 등)을 활용하여 정답을 도출해야 하므로, **추론과 행동의 결합이 중요한 문제**이다.

## 실험 설정
- **데이터셋**  
  - **HotpotQA**: 두 개 이상의 위키피디아 문서를 참조해야 정답을 찾을 수 있는 질문 응답 데이터셋.  
  - **FEVER**: 주어진 주장(claim)이 참인지 거짓인지 판단하는 데이터셋.  

- **ReAct의 동작 방식**  
  - 모델은 질문을 받은 후, **(1) 논리적으로 추론(Thought)**하고 **(2) 행동을 통해 정보를 검색(Action)**한 후, **(3) 최종적인 답변을 도출(Final Answer)**하는 구조.  
  - 예를 들어, “A와 B가 같은 대학을 나왔나요?”라는 질문이 주어지면:  
    1. **추론**: "먼저 A의 학력을 검색해야 한다."  
    2. **행동**: A의 위키피디아 페이지 검색 → 결과 확인  
    3. **추론**: "이제 B의 학력을 검색해야 한다."  
    4. **행동**: B의 위키피디아 페이지 검색 → 결과 확인  
    5. **추론**: "A와 B가 같은 대학을 나왔다면 '예', 아니라면 '아니오'를 답해야 한다."  
    6. **최종 답변** 제출  

- **행동(Action) 공간 정의**  
  - 모델이 사용할 수 있는 행동은 아래와 같이 정의됨:
    1. **search[entity]**: 특정 개체(entity)의 위키피디아 페이지 검색  
    2. **lookup[string]**: 문서 내 특정 단어 검색  
    3. **finish[answer]**: 최종 답변 제출  

## 실험 결과

### 1) ReAct vs. 기존 방법 비교
| 방법 | HotpotQA (정확도) | FEVER (정확도) |
|------|----------------|----------------|
| **Standard (기본 LLM)** | 28.7% | 57.1% |
| **CoT (Chain of Thought, 추론만)** | 29.4% | 56.3% |
| **CoT-SC (CoT + Self-Consistency)** | 33.4% | 60.4% |
| **Act-only (행동만)** | 25.7% | 58.9% |
| **ReAct (추론 + 행동 결합)** | 27.4% | 60.9% |
| **CoT-SC → ReAct (조합 기법)** | **34.2%** | **64.6%** |

- **CoT (추론-only) 방식**이 단순 LLM(Standard)보다 다소 우수했지만, **환각 오류(hallucination)**가 발생하여 신뢰성이 떨어짐.  
- **행동-only 방식**은 검색 기능을 활용하지만, 논리적인 사고 없이 단순히 정보를 가져오기 때문에 성능이 낮음.  
- **ReAct (추론+행동 결합 방식)**은 FEVER에서 CoT보다 높은 성능을 보이며, **더 정확하고 신뢰할 수 있는 답변을 제공**함.  
- 특히 **ReAct + CoT-SC 조합 방식**이 **HotpotQA와 FEVER에서 가장 높은 정확도를 달성**함 → **내부 지식과 외부 정보의 결합이 효과적**임을 입증.  

### 2) ReAct의 장점 분석
- **환각 오류(hallucination) 감소**  
  - CoT 방식은 내부 지식만 활용하여 잘못된 정보를 생성하는 경우가 많았으나, ReAct는 외부 지식을 검색하여 오류를 줄임.  
- **추론 능력 향상**  
  - 행동을 통해 정보를 검색함으로써 더 논리적인 사고가 가능해짐.  
- **해석 가능성(Interpretability) 증가**  
  - 사람이 모델의 답변 과정을 쉽게 따라갈 수 있도록 **추론과 행동을 명확하게 나열**함.  

## 결론 및 시사점
1. **ReAct는 지식 기반 추론 작업에서 더 신뢰할 수 있는 답변을 생성함.**  
2. **단순히 추론(CoT)만 수행하거나 행동(Action)만 수행하는 방식보다 효과적임.**  
3. **내부 지식(CoT)과 외부 지식 검색(Acting)을 결합하면 최상의 성능을 달성할 수 있음.**  
4. **미래 연구 방향**  
   - ReAct의 행동 방식을 강화 학습(RL)과 결합하여 더 발전시킬 가능성이 있음.  
   - 더 많은 훈련 데이터를 사용하여 모델 성능을 추가로 개선할 수 있음.  
