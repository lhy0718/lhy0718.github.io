---
title: "[논문리뷰] E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation (EMNLP 2023)"
date: 2025-03-11 21:00:00 +0900
categories:
  - Paper Review
tags:
  - EMNLP 2023
  - Empathetic Dialogue Systems
---

요약: 이 논문에서는 감정 상관관계를 고려한 새로운 공감적 대화 생성 프레임워크를 제안하여, 감정 인식과 반응 생성의 정확성을 개선하고 이를 통해 보다 인간적인 대화 시스템을 구현하는 방법을 다룹니다.

---

# 1 Introduction

- 공감(empathy)은 인간의 감정 인식을 개선하고 인간화된 대화 시스템을 이루는 데 도움을 주는 바람직한 특성임.
- 공감 대화 생성(empathy dialogue generation, EmpDG)은 대화에서 감정 표현을 인식하여 적절한 공감이 풍부한 응답을 생성하는 것을 목표로 함.
- EmpDG는 여러 분야에서 사용자 경험과 만족도를 향상시키는 능력으로 인해 많은 관심을 받고 있음.

- 기존의 대화 생성 방법들은 다중 과제 학습 패러다임을 따르며, 감정 분류와 대화 생성 작업을 함께 훈련하여 공감 제약을 가진 응답 생성을 달성함.
- 최근 연구는 두 가지 측면에 초점을 맞춤:
  - 감정 인식을 개선하는 방법
  - 생성 전략을 촉진하는 방법

- 기존 방법들은 주 감정을 단일 레이블 감정 분류기로 예측하고, 예측된 감정을 생성에 주입하여 공감 표현을 달성함.
- 그러나 인간의 감정은 독립적이지 않고 내재된 상관관계를 가지고 있으며, 이는 여러 감정이 동반되는 경우가 많음.

- **감정 상관관계를 고려**하는 것은 정확한 감정 인식과 더 나은 공감 표현을 위해 필수적임.
- 다중 감정 상관관계를 모델링하고 학습하는 것, 편향 없이 상관된 감정을 활용하는 것, 다중 감정보다 지나치거나 잘못된 도입을 방지하는 감독 제공이 주요 도전 과제임.

- 이를 해결하기 위해 **E-CORE**라는 새로운 공감 대화 생성 프레임워크를 제안.
  - **감정 상관관계를 촉진하는 인코더 및 디코더를 포함.**
  - **감정 상관관계 손실을 구축하여 다중 감정 규제를 제공함.**

- 기여:
  1. 기존의 감정 독립성 가정을 깨고 감정 상관관계를 모델링함.
  2. 세 가지 맞춤형 모듈을 통해 공감 인식과 표현을 효과적으로 개선함.
  3. 실험을 통해 방법의 우수성을 검증하며, 감정 예측과 응답 생성에서 향상을 달성함.

---

# 2 Related Work

- **행동 인식을**  
  - 다양한 방법론이 존재하며, 과거 연구들은 주로 비디오에서의 행동 인식에 중점을 두었음.
  - 최신 연구에서는 딥러닝 기법을 활용하여 시각적 특징을 학습하고 이를 기반으로 행동을 인식하는 데 초점을 맞추고 있음.

- **단일 센서 기반 접근**  
  - 일반적으로 비디오 카메라 또는 심박 센서를 이용하여 행동을 추적하고 인식하는 방식이 사용됨.
  - 이러한 센서들은 각각의 장점과 단점을 가지며, 특정 환경에 적합한 해법이 필요함.

- **다중 센서 융합**  
  - 최근에는 여러 센서를 결합하여 행동 인식의 정확성을 높이려는 노력이 이루어지고 있음.
  - 다중 센서 데이터는 상충하는 정보를 제공할 수 있기 때문에, 이를 함께 분석하는 방법이 필요함.

- **심층 학습 방법**  
  - 심층 신경망 모델을 통해 시간적 및 공간적 패턴을 효과적으로 학습할 수 있음.
  - 이러한 모델들은 고차원 데이터에서 중요한 특징을 자동으로 추출할 수 있어 많은 연구에서 채택되고 있음.

- **적용 분야**  
  - 개인 건강 모니터링, 스마트 홈, 안전 감시 및 운동 분석 등 다양한 분야에서 활용되고 있음.
  - 각 분야에는 특정 요구사항이 있어 행동 인식 기술의 발전이 필수적임.

---

# 2.1 Emotional Dialogue Generation

- 최근 몇 년 간, 오픈 도메인 대화 시스템이 큰 발전을 이루었음 (Li et al., 2016; Liu et al., 2016 등).
- 감정과 성격의 결합이 더 인간 같은 시스템을 만든다는 논리로, 감정 반응을 생성하는 감정 대화 생성 태스크가 제안되고 발전됨 (Song et al., 2019 등).
- 일부 연구는 수동으로 주석이 달린 감정을 기반으로 다중 감정에 대한 가이드를 제공하려고 시도했으나, 주로 제공된 다중 감정의 인코딩에 초점을 맞춤 (Firdaus et al., 2021).
  
## 프레임워크 개요
- 제안된 E-CORE는 세 가지 단계로 구성됨:
  1. **맥락 인코딩**: 대화 맥락과 모든 감정을 임베딩 기능과 맥락 표현으로 인코딩.
  2. **다중 해상도 감정 그래프 네트워크**: 다양한 해상도에서 감정 상호작용을 캡처하여 감정 상관관계를 인코딩.
  3. **감정 상관관계 향상 디코딩**: 감정 상관관계를 통합하여 감정 신호 인식 및 반응 생성을 향상.

- 이 과정에서 사용되는 주요 요소:
  - **Emotion Correlation Weights Matrix R**: 감정 상관관계를 반영하는 매트릭스.
  - **Soft/Hard Gated Generator**: 감정 신호의 글로벌/로컬 인식을 위해 사용하는 생성기.
  
## 연구 방향
- 본 연구는 실제 대화 시나리오를 더 잘 모사하고, 맥락 감정에 대한 청자의 인식과 추론을 모방.
- 다중 감정 학습에 초점을 맞추며 감정 간 상관관계를 중요시함.

---

# 2.2 Empathetic Dialogue Generation

- 감정 대화 생성과 달리, 공감 대화 생성 작업은 구체적인 주석 감정이 아닌 인지된 감정을 기반으로 공감하는 반응을 생성하는 것을 목표로 함.
  
- Rashkin et al. (2019) (= EMPATHETIC DIALOGUES; ED)이 이 작업을 처음 제안하고, 새로운 작업 벤치마크와 대규모 공감 대화 데이터셋을 기여함. 
  
- 이후 여러 연구(Majumder et al., 2020; Li et al., 2020a; Kim et al., 2021; Gao et al., 2021)가 공감 인식을 향상시키기 위해 노력함. 
  
- Lin et al. (2019)은 적절한 청취자의 감정적 응답을 결합하는 다중 디코더 모델을 제안함; 각 청취자는 독립적임. 
  
- Kim et al. (2022)은 발화 간의 특징 변화를 식별하기 위한 특징 전환 인식기를 제안하여 의미 이해를 향상시킴. 
  
- Li et al. (2022b) 및 Sabour et al. (2022)는 상황 이해를 개선하기 위해 상식 지식을 도입함. 
  
- Li et al. (2022a)는 세분화된 감정 특징과 상식 지식을 효과적으로 활용하여 공감 응답을 향상시키기 위한 직렬 인코딩 및 감정-지식 상호작용 방법을 제안함. 
  
- 그러나 이러한 연구들은 대부분 공감 신호를 포착하기 위해 단일 감정 예측에 의존하며, 대화에서 존재하는 감정 공존을 무시함. 
  
- 본 연구에서는 공감 인식 및 표현을 향상시키기 위해 상관 기반 감정 공존을 조사함.

---

# 3 Proposed Approach

- 대화 맥락 $$U = [u_1, u_2, \ldots, u_m]$$의 m개의 발화가 주어짐.
- 공감적 대화 생성은 다음의 공감적 응답 $$y$$를 감정 일관성과 정보적 표현으로 생성하는 것을 목표로 함.
- 선택적으로, 감정 예측 작업은 맥락의 의미적 이해를 기반으로 하여 공감적 제약을 달성하기 위해 수행됨.
- 제안하는 E-CORE는 감정 상관관계를 명시적으로 탐색하고 통합하여 공감적 인식 및 표현을 강화함.
- E-CORE 프레임워크는 다음의 3단계로 구성됨:
  1. 컨텍스트 인코딩
  2. 다중 해상도 감정 그래프 네트워크
  3. 감정 상관관계 강화 디코딩

- 이 모든 과정은 도식적으로 Fig.3에서 보여짐.

---

# 3.1 Context Encoding

- 이전 방법(Sabour et al., 2022; Li et al., 2022b)을 따름
- 대화 맥락 $U$를 긴 단어 시퀀스로 연결
- 시작 부분에 특별한 [CLS] 토큰 삽입
  - $$X = [CLS, x_1, x_2, \ldots, x_{M-1}]$$
  - 여기서 $$M - 1$$은 $U$의 총 단어 수이며, $$x_0$$는 [CLS]를 나타냄
- 맥락 임베딩을 다음 세 가지 종류의 임베딩의 합성으로 표현
  - 단어 임베딩
  - 위치 임베딩 (Vaswani et al., 2017)
  - 대화 상태 임베딩 (각 단어가 화자 또는 청취자에서 오는지 지시)
- 맥락 임베딩 $x$는 변환기 인코딩 층에 입력됨 (Vaswani et al., 2017)
- 이를 통해 맥락 표현 획득:
  - $$x = e_w(X) + e_p(X) + e_d(X)$$ (1)
  - $$h_X = Enctrans(x)$$ (2)
- $$h_X \in \mathbb{R}^{M \times D}$$이며, $$D$$는 특성 차원임

---

# 3.2 Multi-resolution Emotion Graph Network

- **배경 및 목적**
  - 사회 심리학 연구에 영감을 받아 감정 단어 상호작용을 통해 감정의 상관관계를 탐구.
  - 감정 강도를 기반으로 한 다중 해상도 감정 그래프를 구성하여 서로 다른 해상도에서의 문맥 기반 감정 상호작용 포착.

- **감정 강도 주석**
  - SKEP를 이용하여 감정 강도 주석 생성.
  - 단어 xi의 긍정 정도를 나타내는 점수 $$η(x_i)$$로 정의되며, 감정 강도는 $$ci = (η(x_i) - 0.5)^2$$로 표현.

- **그래프 구성**
  - **노드**: M개의 단어 노드($$V_w$$) 및 $$P$$ 개의 감정 노드($$V_e$$).
  - **엣지**: 단어 노드 간의 상호작용 연결 및 감정 노드 간의 상관 연결.
  - 단어 노드는 문맥 내의 미묘한 감정 상호작용을 포착해야 함.
    - 기본 상호작용 연결: 단어 노드는 이전 단어 노드 및 모든 감정 노드와 연결.
    - 감정 강도를 기반으로 한 정제된 상호작용 그래프 생성.
  
- **감정 노드**
  - 내재된 감정 상관관계를 모델링하기 위해 감정 노드 간의 상관 연결 구성.
  - 상관 가중치를 인코딩하기 위해 글로벌 학습 행렬 $$R$$ 사용.
  - R의 대칭성을 고려하여 매개변수 재표현 기법 적용: $$R = S^T S$$.

- **초기 엣지 가중치 정의**
  - 각 노드의 초기 엣지 가중치는 이웃 노드의 정규화로 설정.
  - 이웃 노드 연결을 위한 다양한 가중치 정의.
  
- **그래프 업데이트**
  - 독립적인 업데이트 및 레이어 기반 융합을 실현하는 다중 해상도 주의 메커니즘 설계.
  - 각 그래프에서 노드 및 엣지 특성을 업데이트하는 과정 정의:
    - 노드 업데이트: $$h_{i}^{l+1} = \Pi^l \left[ \bigg \|_{k=1}^{K} \left( \sum_{j \in N_k i} A_{ij}^{l,k} V^{l,k} h_{j}^l \right) \right]$$
    - 엣지 업데이트: $$E^{l+1,k}_{ij} = (W^{l,k}_V h^l_{j}) \odot (W^l_E (E^{l,k}_{ij} + \hat{A}^{l,k}_{ij}))$$
  
- **결과**
  - 여러 차례의 그래프 업데이트 및 엣지 가중치 합산 후 감정 그래프의 표현을 획득:
    - 단어-감정 엣지 가중치 $$E_{w-e} \in \mathbb{R}^{M \times P}$$
    - 감정-감정 엣지 가중치 $$E_{e-e} \in \mathbb{R}^{P \times P}$$
    - 단어 노드 특징 $$h_{node} \in \mathbb{R}^{M \times D}$$
  - 이후 감정 인식 및 반응 생성에 사용.

---

# 3.3 Emotion Correlation Enhanced Decoding

- **샘플 특정 감정 상관관계**: 그래프를 통해 캡처된 감정 상관관계를 활용하여 감정 신호 인식과 공감 응답 생성을 향상.
  
- **감정 신호 지각기(Emotion Signal Perceptron)**:
  - 상관관계 기반 집합 방식을 채택하여 감정 인식을 향상.
  - 그래프의 엣지 가중치는 감정에 대한 주의를 반영, 다음과 같은 글로벌 지각 신호 정의:
    $$ h_{emo}^g = E_{e-e} \left( \sum_{i=1}^{M} E_{w-e}^{i} \right) $$
  - $E_{e-e}$는 $R$로 초기화되고 샘플 맥락으로 업데이트, 대각선 값은 1로 리셋.
  - 글로벌 지각 신호는 맥락 표현 $h_{X}$와 결합 후, 선형 계층과 소프트맥스 계층을 통해 감정 카테고리 분포를 얻음:
    $$ h_{emo}^m = W_{\epsilon}(h_{emo}^g || W_{x}h_{X}) $$
    $$ P(\epsilon | X) = \text{Softmax}(h_{emo}^m) $$
    $$ L_{emo} = -\log(P(\epsilon = \epsilon^{*} | X)) $$
  
- **소프트/하드 게이트 생성기(Soft/Hard Gated Generator)**:
  - 주요 감정 신호 인식은 주석 감정 감독 제공, 그러나 다른 감정 억제 가능.
  - 소프트 및 하드 게이트 전략을 설계하여 의미 있는 공존 감정 캡처.
  - 글로벌 및 주요 감정 지각 신호에서 의미 있는 감정 특징 추출을 위한 게이티드 주의 메커니즘 사용:
    $$ h_{emo} = \sigma(W_{e}h_{emo}^g) \odot h_{emo}^m + h_{emo}^m $$
  
- **소프트 전략**:
  - 주의 특징을 감정의 소프트 레이블로 취급:
    $$ E_{ij}^{0} = (\text{Softmax}(h_{emo}))_{j}, \quad \forall v_{j} \in V_{e} $$
  
- **하드 전략**:
  - 맥락과 관련이 없는 감정을 직접 스크리닝, OTSU 알고리즘을 통해 중요 감정에 대한 포괄적인 주의 실현:
    $$ V_{relevant}^{e}, V_{irrelevant}^{e} = \text{OTSU}(h_{emo}, V_{e}) $$
  
- **결론**:
  - 소프트 전략은 유연하고 하드 전략은 안정적이며, 두 전략 모두 공존 감정의 적응적 선택 및 활용 성공.
  
- **개선된 그래프 피쳐**:
  - 소프트 또는 하드 전략을 통해 중요한 감정에 초점을 맞추는 개선된 그래프 특징을 얻음.
  - 개선된 노드 특징 $\hat{h}_{node}$를 수정된 변환기 디코더에 입력하여 생성:
    $$ s_{t} = \text{Dec}_{M}^{trans}(y_{<t}, h_{X}, \hat{h}_{node}) $$
    $$ P(y_{t} | y_{<t}, X) = \text{Softmax}(W_{s}s_{t}) $$
  
- **최적화 목표**:
  - 대부분의 대화 생성 작업에서 사용되는 음의 로그 우도 손실:
    $$ L_{gen} = -\sum_{t=1}^{n} \log P(y_{t} | y_{<t}, X) $$

---

# 3.4 Emotion Correlation Loss

- 감정 정보의 과도한 또는 잘못된 도입을 방지하기 위해 감정 상관 손실(emotion correlation loss)을 구성
- 감정 상관 손실은 다음과 같이 정의됨:  
  $$ L_{eco} = -\frac{\sum_{v_i,v_j \in V', i<j} R[v_i, v_j]}{|V'|} $$
- 여기서, $V'$는 학습된 공존 감정으로, 소프트 전략에는 상위 3개의 감정이 사용되며, 하드 전략에는 $$V_{relevant}^e$$가 사용됨
- $L_{eco}$ 손실을 최소화하면 낮은 상관 가중치를 가진 다중 감정의 도입을 방지
  - 낮은 가중치는 감정들이 같은 맥락에서 발생할 가능성이 낮음을 의미
- 이 모든 구성 요소를 고려하여, 최종 최적화 목표를 위한 결합 손실 함수가 사용됨:  
  $$ L = L_{gen} + \gamma_1 L_{emo} + \gamma_2 L_{eco} $$

---

# 4 Experiment Settings

- 실험의 목적:
  - 특정 알고리즘의 성능 평가
  
- 데이터셋:
  - 사용된 데이터셋의 종류와 크기
  - 데이터 전처리 방법
  
- 평가 지표:
  - 성능 측정에 사용된 지표 설명 (예: 정확도, F1-score 등)
  
- 하이퍼 파라미터:
  - 실험에 사용된 주요 하이퍼 파라미터 목록
  - 각 하이퍼 파라미터의 설정 값
  
- 실험 환경:
  - 실험이 수행된 하드웨어 및 소프트웨어 사양
  - 실험을 실행한 플랫폼 및 버전 정보
  
- 반복 실험:
  - 실험의 반복 횟수 및 이유
  - 결과의 평균과 분산 계산 방법

---

# 4.1 Datasets

- E-CORE는 EMPATHETIC-DIALOGUES 데이터셋에서 평가됨.
  - 데이터셋은 Rashkin et al. (2019)에서 수집됨.
  - Amazon Mechanical Turk에서 약 25,000개의 오픈 도메인 대화 수록.
  - 대화는 화자와 청취자로 구성되며, 화자는 개인적인 감정을 이야기하고 청취자는 공감적으로 반응함.
  
- 데이터셋 구성:
  - 훈련/검증/테스트 세트를 각각 19,533 / 2,770 / 2,547 개의 대화로 분할.

- E-CORE의 감정 상관 모델링 검증을 위해 서브 데이터셋 구축.
  - 서브 데이터셋 구성 절차:
    1. 대규모 언어 모델 ChatGPT (OpenAI, 2022) 및 ChatLLaMa (Nebuly-AI, 2023)를 사용하여 감정 주석 추가.
    2. 실제 감정이 식별되고 다중 감정 레이블이 포함된 샘플 선별.
    3. 수동 검사를 통해 잘못된 주석 필터링.
  
- 서브 데이터셋 특성:
  - 총 739개의 샘플로 구성.
  - 샘플당 평균 2.93개의 감정 레이블 포함.

---

# 4.2 Baselines

- E-CORE와 비교하는 최신 기술 기준 모델들:
  - **Transformer (Vaswani et al., 2017)**: 응답 생성을 위한 트랜스포머 기반 모델
  - **MIME (Majumder et al., 2020)**: 감정 군집과 감정 모방을 고려한 모델
  - **EmpDG (Li et al., 2020a)**: 다중 해상도 감정을 활용한 모델
  - **KEMP (Li et al., 2022b)**: 외부 지식을 도입한 모델
  - **CEM (Sabour et al., 2022)**: 상식 활용을 통해 정보를 더 많이 끌어내는 모델
  - **SEEK (Li et al., 2022a)**: 직렬 인코딩과 감정-지식 상호작용을 활용한 모델

- 공정하고 명확한 비교를 위해:
  - 모든 모델과 E-CORE 및 SOTA 모델 변형은 대화 수준 감정 주석을 기반으로 처음부터 훈련됨
  - 실험에서 Ours(Soft)와 Ours(Hard) 두 가지 전략을 각각 사용함

- E-CORE 모델 구조:
  - 기반: Transformer (Vaswani et al., 2017) 프레임워크
  - 블록 수: 4개
  - 헤드 수: 3개
  - 감정 그래프: 레이어 L = 2
  - 해상도 수준: K = 3 (임계값: $$[0, 0.075, 0.15]$$)
  - 손실 함수 매개변수: $$\gamma_1 = \gamma_2 = 1$$

- 추가 구현 세부사항은 부록 D에 포함됨

---

# 4.3 Evaluation Metrics

- **자동 평가 (Automatic Evaluation)**
  - **Perplexity (PPL)**: 응답 생성의 품질을 측정.
  - **Distinct-n (Dist-n)**: 생성된 응답의 다양성을 측정.
  - **감정 정확도 (Emotion Accuracy, Acc)**: 예측된 주요 감정과 실제 감정 간의 일관성을 측정.

- **인간 평가 (Human Evaluation)**
  - 인간과 유사한 응답을 생성하는 모델의 능력을 평가하기 위해 3가지 측면에서 인간 평가를 실시:
    - **유창성 (Fluency)**: 응답의 유창성.
    - **관련성 (Relevance)**: 대화 맥락과의 적절성.
    - **공감 (Empathy)**: 응답의 공감적 표현.
  - 100개의 대화를 무작위로 선택하여 대화 맥락과 기준의 응답과 함께 평가.
  - 3명의 인간 주석자가 각 항목을 [1, 5] 범위 내에서 점수 부여 (높을수록 우수).
  - 모든 주석자의 평균 점수가 인간 평가 결과.

- **모델 성능 비교 (Table 1)**
  - 다양한 모델의 자동 평가와 인간 평가 점수 제시.
  - 점수가 낮을수록 성능이 우수함을 나타냄 (↓).

- **A/B 테스트 (Table 2)**
  - 인간 A/B 테스트를 통해 최고 성능의 모델과의 비교 진행.
  - 응답의 쌍별 비교를 통해 각 항목에서 더 나은 응답 선택.
  - 동점(Tie) 허용: 두 응답 모두 좋거나 나쁨. 
  - 인간 평가의 자세한 내용은 부록 I에 수록.

---

# 5 Results and Analysis

- 실험은 벤치마크 데이터셋에서 수행하여 감정 상관 학습의 가능성을 검증함.
- 감정 인식 및 공감 생성의 두 가지 측면을 모두 고려함.
- 다중 감정 주석 하위 집합에서 공존 감정 인식 능력을 조사함.
- E-CORE 방법의 감정 상관 학습의 본질을 추가로 검증함.

---

# 5.1 Comparison with State-of-the-Art

- **자동 평가** 
  - 기존 SOTA 모델들은 주로 초기 상태에서 훈련되었기 때문에, 공정한 비교를 위해 본 연구에서도 처음부터 훈련된 결과를 제시.
  - 제안한 E-CORE 모델은 모든 자동 평가 지표에서 SOTA보다 우수한 성능을 나타냄.
  - 응답 품질에서 상대적으로 8.53%, 절대적으로 3.08 (PPL) 개선.
  - 응답 다양성에서 상대적으로 11.5%, 절대적으로 0.36 (Dist-2) 개선.
  - E-CORE는 더 풍부한 감정 정보를 제공하여 보다 관련성이 높은 댓글을 생성.

- **감정 정확성**
  - 응답의 감정 정확성이 상대적으로 8.34%, 절대적으로 3.28 (Acc) 개선됨.
  - 상관 관계 기반 집합 집합 방식을 채택하여 주요 감정 인식에 유익함을 증명.

- **인간 평가**
  - 모든 평가 측면에서 E-CORE가 더 나은 성능을 기록, 특히 관련성 및 공감에서 두드러진 향상.
  - 감정 상관 학습이 보다 관련성이 높은 감정 지침을 제공하여 인간적이고 공감이 가득한 응답을 생성하는 데 기여.

- **하위 데이터셋 결과**
  - 단일 레이블 지도로 EmpDG를 사용할 때도 E-CORE가 공존 감정 학습에서 효과적임을 입증.
  - 다중 감정 주석 하위 데이터셋에서 다중 감정 학습 능력을 추가로 검증, Recall@k 지표 사용.
  - Tab.3에서 보여주는 결과는 E-CORE의 다중 감정 학습이 큰 우수성을 나타냄 (R@3에서 44.1% 향상, R@5에서 31.3% 향상).
  
- **시각화 및 감정 상관도**
  - 데이터셋과 E-CORE의 감정 상관성을 시각화하여 직관적 비교 제공.
  - 감정 쌍의 공동 발생 수를 기반으로 계산한 상관 가중치 및 모델 훈련 후 학습된 가중치 R 사용.
  - E-CORE는 실제 분포에 매우 근접한 감정 상관성을 보여 감정 상관 모델링의 정확성을 입증.

---

# 5.2 Ablation Study

- E-CORE의 각 디자인 요소가 기여하는 바를 평가하기 위해 ablation 연구를 수행함.
- 다양한 변형 모델을 테스트함:
  - **w/o graph**: 다중 해상도 감정 그래프 없이 기본 변환기 프레임워크로 다른 모듈 구현
  - **w/o co-p**: 감정 인지 집계에서 상관관계 인식을 제외한 모델
  - **w/o co-g**: 생성기에서 상관관계가 있는 공통 감정 안내를 제외하고, 소프트/하드 전략을 사용하지 않으며 주 감정으로 응답 생성
  - **w/o co-loss**: 감정 상관관계 손실을 제외한 모델
- Tab.4에 보고된 바와 같이 모든 모듈이 E-CORE에 합리적인 기여를 함:
  - 감정 그래프를 변환기로 대체 시 성능이 크게 저하되며, 이는 감정 상관관계 학습에 있어 다중 해상도 감정 그래프의 효과성을 입증함.
  - 감정 정확도와 응답 품질에서 상관관계 활용이 없는 모델들이 낮은 성능을 보이므로, 설계한 집계 및 소프트/하드 전략이 공감 감정 인지 및 표현을 향상시키는 데 효과적임을 나타냄.
  - 상관관계 손실이 없는 결과는 전역 감독에서의 중요성을 보여줌.
- 추가적인 ablation 연구 및 분석은 부록 J에 추가됨.

---

# 5.3 Case Study

- Fig. 1에서는 E-CORE의 능력이 서로 다른 공존 감정(두려움과 감사)을 함께 안내하는 모습을 보여줌
- Tab. 5는 유사한 공존 감정에 대한 종합적인 질적 분석을 위한 사례를 제시
- 화자가 “옛날 물건”에 대한 감정을 표현함
- 감정적 느낌과 향수의 significant correlation을 기반으로 E-CORE가 성공적으로 보조 감정인 향수를 식별
- E-CORE는 “go back memories” 및 “those moments”와 같은 더 관련성 있는 구문 생성
- 기본 모델들은 보편적인 응답만 생성함
- 유사하거나 멀리 떨어진 공존 감정이 EmpDG에 중요함
- 이러한 감정들이 전반적이고 세부적인 공감 표현에 기여
- 감정 상관 학습을 통한 E-CORE는 충분한 감정 안내 제공
- 결과적으로 공감이 풍부한 더 인간적인 응답 생성

---

# 6 Conclusion

- 본 논문에서는 대화에서의 내재적 감정 상관성을 활용하여 공감 대화 생성의 향상을 제안했습니다.
- 감정 상관성 학습, 활용 및 감독을 다루는 세 가지 효과적인 모듈로 구성된 독특한 프레임워크를 설계했습니다.
- 벤치마크 데이터셋에서의 광범위한 실험을 통해 본 프레임워크가 감정 인식 및 공감 생성 향상에 상당한 장점을 입증했습니다.
- 구체적인 분석은 우리의 감정 상관성 학습의 정확성을 더욱 증명했습니다.
  
### 향후 연구 방향
- 본 연구는 다중 감정 상관성 학습을 탐구할 수 있는 다른 접근 방법에 영감을 줄 수 있습니다.
- 단일 감정 레이블에 국한되지 않고 감정 관련 작업을 탐색하는 것이 가능해질 것입니다.

### 한계점
1. 거의 모든 대화에는 주요 감정 외에도 미세한 감정이 동반됩니다. 이러한 감정을 모두 주석 처리하고 감정 가중치를 매기는 것은 거의 불가능합니다.
   - 다중 감정 학습을 개선하기 위한 기존 정보 활용 방법을 검토해야 합니다.
2. 현재 모든 방법은 유일한 벤치마크 데이터셋인 EMPATHETIC DIALOGUES에서 평가되었습니다.
   - 다국어 및 다양한 카테고리 데이터셋이 부족합니다.
3. 기존 모델은 복잡한 샘플에서 일반적인 응답을 생성하는 경향이 있습니다.
   - 어려운 샘플 학습이 공감 대화 생성의 개발 방향이 될 수 있습니다.

### 윤리적 고려사항
- 본 논문에서 사용된 감정 대화 데이터셋은 공개적으로 제공되며, 개인정보 보호가 철저하게 이루어졌습니다.
- 인적 평가 과정에서 익명화를 보장하였습니다.
- 우리의 연구 작업은 EMNLP 윤리를 준수한다고 믿습니다.

---

# 7 Limitations

- **정확한 감정 주석의 어려움**: 
  - 대부분의 대화는 주 감정 외에 미세한 감정을 동반하지만, 모든 미세한 감정과 해당 감정의 가중치를 주석하는 것은 거의 불가능함.
  - 단일 레이블에 대한 가이드를 바탕으로 한 다중 감정 학습은 성공적이나, 정보를 활용하여 더 효과적인 다중 감정 학습을 위한 감독 방법 개선이 필요함.

- **데이터셋 제한**: 
  - 현재의 모든 기존 방법은 유일한 벤치마크 데이터셋인 EMPATHETIC DIALOGUES에서 평가됨.
  - 공감 대화 생성은 신흥 작업으로, 영어 외의 다른 언어와 카테고리를 포함한 데이터셋 부족.

- **일반적인 응답 생성 경향**: 
  - 실험에서 기존 모델들이 특히 복잡한 샘플에 대해 일반적인 응답을 생성하는 경향이 관찰됨.
  - 따라서, 어려운 샘플의 학습이 공감 대화 생성 작업의 발전 방향임.

---

# 8 Ethics Considerations

- 본 논문에서 사용된 공감 대화 데이터셋(EMPATHETIC DIALOGUES, Rashkin et al., 2019)은 공개적으로 이용 가능하며, Amazon Mechanical Turk를 통해 주석이 달렸음.
- 이 데이터셋은 실제 사용자의 개인정보를 보호하며, 인적 평가 과정에서 익명화를 보장함.
- 연구진은 연구가 EMNLP의 윤리 기준을 충족한다고 믿고 있음.