---
title: "[논문리뷰] MORPHEUS- Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space (EMNLP 2024)"
date: 2025-04-07 23:00:00 +0900
categories:
  - Paper Review
tags:
  - EMNLP 2024
---

개인화된 대화 생성(PDG)은 역할이나 페르소나에 따라 일관된 응답을 생성하는 것을 목표로 하며, 기존 방법은 외부 역할 데이터에 의존해 민감한 문제를 일으킬 수 있습니다. 이를 해결하기 위해 우리는 대화 이력에서 역할 정보를 추출하고, 잠재 공간에서 역할을 효과적으로 모델링하는 새로운 프레임워크 MORPHEUS를 제안합니다. MORPHEUS는 역할 정보를 일반화하고, 외부 데이터 없이도 개인화된 대화를 생성할 수 있도록 개선된 성능을 보여줍니다.

---

# 1 Introduction

- **개인화된 대화 생성(PDG)** 
  - 사용자 감정 및 기호를 포착하고 응답하기 위한 중요한 방법
  - 역할기반 모델링을 통해 개인의 필요에 맞는 역할 관련 응답 생성

- **기존 방법론**
  - 외부 역할 데이터를 명시적으로 포함하여 성과를 달성
  - 정보 추출에 의존하지만, 외부 데이터 부족 및 개인정보 보호 문제 발생

- **모델 비교**
  - MSP: 토큰 수준의 검색-생성 시스템을 통해 개인화된 대화 검색
    - 역할 간의 고립된 처리를 지적받음
  - CLV: 잠재 공간에서 역할을 모델링
  - PersonaPKL: 역할 인식을 수행하지만 지역적 역할 특징 간의 연관성만 집중

- **MORPHEUS의 제안**
  - 대화 역사에서 역할 모델링
  - **세 단계 훈련 방법**:
    1. 역할 인식 훈련
    2. 역할을 잠재 공간으로 압축하는 persona 코드북 생성
    3. 대화 역사에 기반한 코드 예측 및 생성
    
- **MORPHEUS의 기여**
  1. **역할 일반화와 개인화된 대화 생성을 위한 최초의 체계적인 연구**
  2. **잠재 공간에서 역할을 전역적으로 모델링하여 개인화된 역할 생성 향상**
  3. **대화 생성에서 개인화 향상 및 대규모 언어 모델의 효율적인 파라미터 미세조정 가능**

---

# 2 Related Work

- **개인화 대화 생성의 중요성**
  - 성격 특성을 대화 생성에 포함하는 것이 필수적임 (Chen et al., 2024a).
  - 명시적인 페르소나 데이터를 최대한 활용하는 방법이 주요 연구 질문.

- **페르소나 데이터 종류**
  - 사실적 역할 설명 (Qian et al., 2018; Zheng et al., 2020; Song et al., 2021): 예) "나는 수영을 즐깁니다."
  - 성격 특성: 예) 내향적
  - 지식 기반 (Zhang et al., 2018a; Song et al., 2019a; Wolf et al., 2019; Liu et al., 2020; Song et al., 2021): 예) 성별: 남성
  - 발화 스타일 (Lu et al., 2023): 예) 흥분된

- **목표 및 도전 과제**
  - 연구의 목표: 성격을 바탕으로 역할 프로필 모델링, 사용자와 지속 가능한 개인화 대화.
  - 대화 이력에 기반한 성격 모델링: 명시적 데이터에 비해 수집이 용이하고 정보가 풍부.

- **모델링 접근법**
  - 특정 연구, DHAP (Ma et al., 2021) 및 MSP (Zhong et al., 2022): 대화 이력에서 관련 대화를 명시적으로 검색하여 대화 생성 향상.
  - Retrieve-based 방법의 한계: 코퍼스 크기 및 비효율성.

- **다양한 모델과 기법**
  - PersonaWAE (Chan et al., 2019): 응답자의 성격 고려 없이 잠재 공간에서 사용자 측의 개인화.
  - PersonalPKT (Han et al., 2023): 명시적 데이터를 사용해 두 단계에서 효율적으로 모델 세부 조정.
  - CLV (Tang et al., 2023): 명시적 페르소나 설명은 특정 정보 각도를 감출 수 있음.

- **제안된 모델 - MORPHEUS**
  - 대화 이력에서 정보를 얻기 위해 잠재 변수 공간에서 페르소나 정보를 클러스터링.
  - $$\text{CA VE}$$ (Zhao et al., 2017)를 통해 정보 활용.
  - 모든 페르소나 정보는 더 큰 잠재 공간에서 압축되어 일반화 가능.

---

# 3.1 Overview

- **개인화된 대화 생성** 
  - 마스킹된 명시적 인물 데이터를 사용하여 정의
  - 역할 집합 U가 존재하고, 각 역할 $u_i$에 대해 텍스트적 인물 데이터 P가 제공됨

- **대화 역사** 
  - 다중 턴 대화 기록 C는 $u_i$와 $u_j$ 간의 상호작용으로 구성되며, 현재 턴은 $u_i$의 응답을 기다림

- **목표** 
  - 대화 역사 C에 따라 $u_i$와 밀접하게 일치하는 개인화된 응답 R 생성
  
- **모델링** 
  - 인퍼런스 시, 모델은 외부 데이터 $P_{u_i}$를 요구하지 않고, 대화 역사 C 내에 개인 정보 P가 암시되어 있음을 활용
  - 수식: 
    $$ P(R|C) = \sum P P(R|C,P) \cdot P(P|C) $$ 

- **프레임워크 개요**
  - 세 가지 주요 훈련 단계로 나뉨:
    1. **역할 인식** 
       - 무조건 디코더가 광범위한 말뭉치에서 훈련되고, 대화 및 인물 정보에 대한 인식 능력이 부족함
       - 역할 특성과 맞물린 대화 생성을 위해 모델의 인식 향상 목표
       
    2. **인물 코드북(PC) 초기화** 
       - 모델이 대화 역사와 PC에서 역할을 직접 모델링하므로, 기존 코드북이 인코딩 표현과 일치하지 않을 수 있음
       - 특정 인물 인코딩 표현에서 일반화된 PC는 무작위 초기화보다 효과적으로 성능을 향상시킴
       
    3. **통합 훈련** 
       - 대화 역사 C를 입력으로 사용하고, 대화 내 암시적 인물 정보 기반으로 PC에서 PC 표현 샘플링
       - 이를 통해 개인화된 응답 생성

---

# 3.2 Role Awareness

- 디코더 전용 아키텍처 모델에서:
  - 페르소나와 대화 이력을 연결하여 답변을 생성함.
  - 과거의 키와 값 형태로 역할 데이터의 숨겨진 표현을 모델의 시작 부분에 직접 연결 가능.

- Han et al. (2023)의 연구에 따르면:
  - 대화 이력을 기반으로 답변을 생성하도록 모델을 강제하면, 
  - 역할 데이터의 숨겨진 상태에 조건화 된 경우, 
  - 페르소나 정보와 대화 이력의 결합 지각 능력을 향상할 수 있음.

- 페르소나 세그먼트 인코딩:
  - 역할에 대한 인코딩 표현을 정의하며, 이를 $\pi$로 표시함.
  - 모델의 앞부분에 키와 값만 연결됨.

- 모델을 미세 조정하는 방법:
  - 수식: $$LR = l \sum_{j} \log P(\hat{R}_i | P, C, R_{<j})$$ (2)

---

# 3.3 Initialization of the Persona Codebook

- Persona Codebook (PC) 생성: 
  - $e \in \mathbb{R}^{N \times d}$, 여기서 $N$은 이산 잠재 공간의 크기, $d$는 숨겨진 크기입니다.
  - $e$는 $N$개의 PC 표현 $e_k$를 포함.

- 목적: 
  - PC를 통해 다양한 페르소나 정보를 압축적으로 표현.

- 모델의 역할 인식:
  - $e_k$가 텍스트 페르소나 데이터의 표현 $p_i$와 정렬될 수 있는지가 중요한 문제.
  - $P_0, P_2, \ldots, P_{M-1} = \text{Split}(P)$, 
  - $p_i = \text{Encoder}(P_i)$, $p_i \in \mathbb{R}^d$.
  - Split은 문자열 수준에서의 명시적 분리를 의미하며, M은 페르소나 데이터의 설명 각도를 M개 카테고리로 나눌 수 있음을 나타냅니다.

- 초기화의 중요성:
  - PC의 초기화는 디코딩 중 효과성을 위해 중요.
  - 무작위 균등 분포로 초기화하면 후속 매개변수 업데이트에서 어려움이 발생할 수 있음.

- 세 가지 초기화 방법 설계:
  1. **순차 페르소나 초기화**: 
     - 현재 배치의 페르소나 데이터에서 $p_i$를 순서대로 사용하여 PC의 초기화되지 않은 부분을 채움.
  2. **평균 페르소나 초기화**: 
     - 배치의 $p_i$에 대해 평균 연산 수행.
  3. **EM 초기화**:
     - 가장 효과적이며, 공동 학습 과정과 독립적으로 작동.
     - $p_i$가 각 $e_k$ 중심의 여러 정규 분포 중 하나에서 샘플링되었다고 가정.

- **기대 단계 (Expectation Step)**:
  - 크기 $N$의 PC에 대해 $N$개의 정규 분포 설정.
  - 모든 페르소나 데이터 인코딩 표현을 샘플로 사용.
  - 각 $p_i$에 대해 사후 확률 $P(z_i = k \vert p_i)$ 계산.

- **최대화 단계 (Maximization Step)**:
  - 현재 단계에서 계산된 사후 확률로 매개변수를 갱신.
  - 평균 $\mu_k$ 및 분산 $\sigma^2_k$ 업데이트:
    - $$\mu_k = \frac{\sum_{|D|} P(z_i = k \vert p_i)p_i}{\sum_{|D|} P(z_i = k \vert p_i}$$
    - $$\sigma^2_k = \frac{\sum_{|D|} P(z_i = k \vert p_i)(p_i - \mu_k)^2}{\sum_{|D|} P(z_i = k \vert p_i)}$$

- 결론:
  - 이러한 방법을 통해 정규 분포의 정확한 매개변수를 얻고, 유도된 평균 $\mu_k$를 $z_k$의 초기 값으로 사용.

---

# 3.4 Joint Training

- **모델 학습 시작**: 
  - 대화 이력의 암묵적인 인물 정보를 기반으로 코드를 예측하는 방법 학습.
  - Persona Codebook (PC)에서 개인화된 응답 생성을 위한 PC 표현 $$e_k$$ 추출.

- **훈련 방식**:
  - 두 개의 동시 단계로 나뉘어 있음:
    1. 코드 인덱스 예측
    2. PC 훈련

- **PC 훈련**:
  - VQ-VAE(2017) 접근 방식을 따름.
  - 인물 인코딩 표현 $$p_i$$와 가장 잘 맞는 $$e_k$$ 찾기:
    $$k = \arg\min_k \|p_i - e_k\|^2$$
  - 거리 최소화를 위한 손실 함수 최적화:
    $$L_V = \|sg[p_i] - e_k\|_2^2 + \beta \|sg[e_k] - p_i\|_2^2$$
  - 여기서 **sg**는 통과에서의 정체성 연산이며, 0의 부분 도함수를 가진다.
  
- **손실 함수 최적화**:
  - 인코더는 마지막 손실 항을 최적화.
  - 임베딩은 첫 번째 손실 항을 최적화.
  - 실험을 통해 $\beta$에 대한 민감도를 확인하며, 일반적으로 $\beta = 0.05$ 사용.

- **대화 생성**:
  - 인코딩된 표현은 이전 키와 값으로 사용되며 손실 함수는:
    $$L_G = -\sum_{j=1}^{l} \log P(R_j | p_G, C, R_{<j})$$

- **코드 인덱스 예측**:
  - 인물 표현 $$p_i$$에 가장 가까운 코드 인덱스 $$k$$를 레이블로 사용.
  - 다층 MLP를 분류기로 사용하여 대화 이력의 숨겨진 상태 입력.
    $$c = Decoder(C)$$
    $$L_D = -\log P(y = k | c)$$

- **PC 다양성 및 일반화**:
  - 각 잠재 변수에 대한 추가 대조 학습 손실 기능 도입:
    $$L_C = -\log \frac{esim(p_i, e_k)}{\tau} \sum_{j=1}^{N} \frac{esim(p_i, e_j)}{\tau}$$
  - 여기서 $$\tau$$는 온도 하이퍼파라미터이며, $$sim(p_i, e_i)$$는 코사인 유사도.

- **데이터셋 통계**:
  - ConvAI2: 43,410 훈련, 4,213 검증, 2,138 테스트
  - Baidu PersonaChat: 376,016 훈련, 19,923 검증, 4,456 테스트

---

# 4.1 Datasets

- **ConvAI2**
  - 저자: Dinan et al., 2019
  - 영어 중심의 데이터셋
  - 개인화된 대화에 초점
  - 특정 역할 프로필에서 파생됨
  - PersonaChat (Zhang et al., 2018b)의 확장판
  - 크라우드 워커들에 의해 세심하게 편집되어 품질과 관련성이 향상됨

- **Baidu PersonaChat**
  - 중국어 데이터셋
  - ConvAI2의 구조를 그대로 반영
  - 개인화를 강조하고 개별 세부 정보를 활용하여 흥미로운 대화 유도

- **데이터셋 활용**
  - 역할 설명은 훈련 단계에서만 사용
  - Tang et al. (2023)에서 편집한 데이터셋 사용
  - 훈련, 검증, 테스트 데이터에서 역할 유출 방지

---

# 4.2 Baselines

- 개인화된 대화 생성 모델 연구는 주로 두 가지 유형으로 나눌 수 있음:
  - **명시적 검색 접근법**: 현재 대화 이력에 따라 미리 정의되거나 동적으로 생성된 응답 풀에서 가장 관련 있는 응답 또는 토큰을 검색함.
  - **암묵적 모델링 접근법**: 개인화나 역할이 명시적으로 정의된 응답 없이 모델 내에서 직접 학습되고 생성됨.

- 비개인화된 대화 생성 모델의 기준선은 세 가지 주요 클래스으로 나눌 수 있음:
  1. **비개인화 접근법**
     - Seq2Seq (Sutskever et al., 2014): 주의 메커니즘(Luong et al., 2015)으로 향상된 주요 시퀀스 모델링.
     - 사전 훈련된 GPT-2 (Radford et al., 2019): 대화 특정 데이터셋으로 파인튜닝하여 대화 생성의 기초가 됨.

  2. **명시적 검색 기반 접근법**
     - DHAP (Ma et al., 2021): 역사적 상호작용 데이터를 활용하여 쿼리 민감 사용자 프로필을 동적으로 생성함.
     - MSP (Zhong et al., 2022): 비슷한 프로필을 가진 사용자들의 대화를 식별하여 개인화된 대화를 생성함.

  3. **암묵적 모델링 기반 접근법**
     - PersonaPKT (Han et al., 2023): 최소한의 추가 매개변수를 사용하여 페르소나 특정 특성을 포함함.
     - CLV (Tang et al., 2023): 잠재 공간에서 페르소나 정보를 범주화하여 대화 이력을 기반으로 개인화된 응답 생성을 향상시킴.

- 자동 평가 결과는 다음과 같음:

| Dataset       | Model         | **Coherence** |             |             | **Diversity** |        |        | **Consistency** |             |
|---------------|---------------|---------------|-------------|-------------|---------------|--------|--------|------------------|-------------|
|               |               | BLEU-1        | ROUGE-L     | Coh.Score   | Dist-1        | Dist-2 | sBLEU ↓ | Coh-Con.Score    | P-Co        |
| **ConvAI2**   | Seq2Seq       | 3.41          | 5.48        | 35.89       | 2.04          | 3.98   | 13.22   | 10.85             | 3.13        |
|               | GPT-2         | 6.50          | 10.91       | 58.79       | 4.71          | 25.28  | 10.51   | 13.29             | 4.59        |
|               | DHAP          | 7.37          | 9.97        | 63.21       | 5.60          | **29.81**  | 9.85    | 16.04             | 9.27        |
|               | MSP           | 8.55          | 10.96       | 64.19       | 5.11          | 28.60  | 9.93    | 15.45             | 8.92        |
|               | PersonaPKT    | 8.70          | 11.08       | 60.58       | **6.30**          | 26.72  | 9.34    | 24.87             | 9.26        |
|               | CLV           | 11.16         | 15.04       | 70.83       | 4.31          | 26.17  | 10.14   | 23.01             | 9.38        |
|               | **MORPHEUS (Ours)** | **12.67** | **16.18** | **73.19**   | 5.89          | 28.74  | **8.97**  | **31.57**         | **11.64**   |
| **Baidu PersonaChat** | Seq2Seq   | 7.98          | 8.24        | 40.11       | 0.97          | 5.19   | 16.79   | 8.96              | 3.11        |
|               | GPT-2         | 10.16         | 12.29       | 49.72       | 3.08          | 20.98  | 13.32   | 12.14             | 5.30        |
|               | DHAP          | 11.23         | 11.58       | 53.89       | 3.11          | 22.10  | 13.42   | 12.30             | 7.95        |
|               | MSP           | 14.44         | 13.24       | 58.59       | **3.37**          | 22.41  | 13.95   | 14.37             | 8.23        |
|               | PersonaPKT    | 13.82         | 15.57       | 53.95       | 2.98          | 21.83  | 13.10   | 19.86             | 8.17        |
|               | CLV           | 18.77         | 21.82       | 59.74       | 2.42          | 21.17  | 14.57   | 18.15             | 8.39        |
|               | **MORPHEUS (Ours)** | **19.70** | **24.64** | **62.45**   | 3.07          | **23.05**  | **12.56**  | **29.93**         | **10.96**   |

---

- 구현 세부 사항은 부록 A.1에 있음.

---

# 4.3 Evaluation Metrics

- **목적**: 정확한 비교를 위해 자동 평가와 인간 평가를 모두 사용함.
  
## 자동 평가
- **세 가지 범주**로 나누어 생성된 대화의 다양성, 일관성, 그리고 응집력을 평가함.
  
  1. **응집력**:
     - BLEU-1/2 (Papineni et al., 2002) 및 ROUGE-L (Lin and Och, 2004): 생성된 응답과 실질적인 응답 간의 유사성을 측정하는 전통적인 단어 중첩 기반 메트릭.
     - Tang et al. (2023)에 따르면 BLEU-3/4는 지나치게 엄격한 기준을 적용하여 대화 역사와 응답 간의 응집력을 반영하지 못함.
  
  2. **다양성**:
     - Dist-1/2 (Li et al., 2016a): 생성된 응답 내의 고유 단어(uni-gram 또는 bi-gram)의 존재를 평가하여 코퍼스 수준의 다양성을 평가.
     - self-BLEU (sBLEU) (Liu et al., 2022): 응답 간의 유사성으로부터 다양성을 산출.
  
  3. **일관성**:
     - 생성된 응답과 역할 간의 일관성 유지가 중요.
     - Con.Score 및 Coh-Con.Score 모델을 도입하여 응답과 인물 정보 간의 일관성 측정.
     - P-Co (Persona Cosine Comparison) (Song et al., 2019b): 모델 응답과 인물 간의 의미적 유사성을 평가하는 보조 메트릭.
  
## 인간 평가
- 자동 평가 기준의 불확실성을 고려하여 모든 모델에 대해 인간 평가 수행.
- 100개의 데이터 포인트(이력, 응답, 역할 데이터)를 추출하고, 교육받은 3명의 평가자가 여러 모델의 응답을 순위 매김.
- 평가 기준은 가독성, 다양성, 일관성, 응집력 중심으로 설정됨.
- 각 응답을 0에서 1 사이의 점수로 정규화하여 비용 절감.
- 평가자는 모델 생성 응답 5개와 사실 응답에 대해 6개의 옵션을 순위 매김.

| 모델      | 가독성 | 다양성 | 일관성 | 응집력 |
|-----------|--------|--------|--------|--------|
| DHAP      | 0.71   | 0.72   | 0.69   | 0.71   |
| MSP       | 0.70   | 0.73   | 0.69   | 0.80   |
| PersonaPKT| 0.63   | 0.65   | 0.61   | 0.69   |
| CLV       | 0.79   | 0.76   | 0.73   | 0.76   |
| MORPHEUS(우리 모델) | **0.82**   | **0.84**   | **0.77**   | **0.85**   |
| Ground-Truth| 0.92 | 0.89   | 0.93   | 0.91   |

- **표 3**: ConvAI2에 대한 인간 평가 결과.

---

# 4.4 Experimental Results

- **자동 평가 결과**
  - **표 2**: 모든 모델의 성능을 자동 메트릭으로 평가
    - 중국어 및 영어 데이터셋에서 세 개의 무작위 시드의 평균값 제공
  - **주요 메트릭 향상**:
    1. **일관성 (Coherence)**:
       - MORPHEUS는 BLEU-1, Rouge-L 등의 커버리지 메트릭 및 Coh-Con.Score와 같은 학습 지표에서 특히 뛰어난 성능
    2. **다양성 (Diversity)**:
       - MORPHEUS는 타 모델에 비해 더 다양한 응답 생성
       - CLV 모델과 같은 잠재 변수 모델의 단점을 극복하여 다른 성능 지표 개선을 위한 다양성 희생 방지
       - MORPHEUS가 보다 정확한 모델링 목표에 근접하게 함
    3. **일관성 (Consistency)**:
       - Con.Score의 지도가 개인 정보를 생성에 통합할 수 있는 능력을 나타냄
       - 외부 개인 데이터 없이도 MORPHEUS의 우수성 강조

- **인간 평가 결과**
  - **표 3**: ConvAI2에 대한 인간 평가 결과
    - 세 명의 주석자 간 Fleiss Kappa 계수 계산 (Kappa 값: 0.65, 상당한 합의)
  - 인간 주석 결과는 자동 평가 결과와 일치
    - MORPHEUS의 개인화된 대화 생성 및 기본 가독성의 강점 강조

- **모델 성능 비교 (표 4)**:
  - MORPHEUS(Ours): BLEU-1: 12.67, Dist-1/2: 5.89/28.74, Coh-Con.Score: 31.57, P-Co: 11.64
  - w/oPC: 6.41, w/oCL: 9.24, w/oRA: 8.56 등 다양한 설정에 따른 성능 비교

- **다양한 N에 대한 실험 (그림 3)**:
  - BLEU-1, ROUGE-L, P-Co는 3배 확대, Dist-1은 10배 확대하여 표시

---

# 5 Further Analysis

- 추가 분석은 ConvAI2 데이터셋을 기반으로 수행됨.
- Baidu PersonaChat에서도 유사한 현상이 관찰됨.

---

# 5.1 Ablation Study

- MORPHEUS 모델의 특정 모듈 제거를 통한 실험 수행 (표 4 참조).
- **주요 메커니즘 (Persona codebook, PC)**:
  - PC 제거 시 모델이 기본 GPT-2로 회귀.
  - 성능은 GPT-2와 동일하게 나타남.

- **대조 학습 제거**:
  - 공동 훈련에서 대조 학습을 제거하면 성능 저하 및 다양성 감소 발생.
  - 대조 학습이 인코딩 표현을 PC 표현에 가깝게 만드는 데 효과적임을 강조.

- **PC 초기화 방법**:
  - EM(Ours) 기술이 랜덤 초기화, 순차적 채우기, 평균 채우기보다 우수한 성능.
  - 역할에 대한 전반적인 관점이 PC 최적화에 기여함.

- **역할 인식 훈련 제거**:
  - 역할 인식 훈련 제거 시 특정 메트릭에서 성능 저하.
  - 7670 Role Data와의 일치를 통해 역할 정렬의 중요성이 나타남.

---

# 5.2 Effects of size of the persona codebook

- MORPHEUS에서 persona 정보는 persona codebook (PC)로 압축됨.
- PC의 크기 $N$은 성능에 중요한 영향을 미침.
  - $N$이 작을 경우:
    - PC에 압축된 정보는 개인화된 대화 생성에 필요한 일반적인 정보와 더 밀접하게 연관됨.
    - 특정 역할보다는 일반 정보에 맞춰짐.
  - $N$이 너무 클 경우:
    - 압축의 효과가 감소함.
    - 이는 뚜렷한 persona의 수가 부족하여 잡음이 증가하는 데 기인함.
    - persona 정보의 분산이 발생, PC 최적화가 어려워짐.
- 최적의 성능은 $N = 100$일 때 관찰됨.

---

# 5.3 PEFT

- 우리 접근 방식은 퍼소나 코드북(PC) 표현 벡터를 모델의 최전선에 연결하는 것으로, 이는 프롬프트 튜닝 및 P-튜닝과 유사함.
- 이는 효율적인 파인튜닝 방법으로 간주됨.
- 텍스트 생성을 담당하는 디코더(LLaMA-2 (Touvron et al., 2023))의 파라미터를 고정하고 훈련 동안 PC 내의 파라미터만 최적화함.
- 성능 비교:
  - LoRA, MORPHEUS, 전체 파라미터 파인튜닝(Mistral-7Bv0.1) 성능 비교:
    - 메트릭스: BLEU-1, ROUGE-L, Dist-1, Dist-2, sBLEU
    - 결과:
      - LoRA: BLEU-1: 15.17, ROUGE-L: 17.88, Dist-1: 6.99, Dist-2: 26.28, sBLEU: 9.12
      - MORPHEUS: BLEU-1: 17.60, ROUGE-L: 21.55, Dist-1: 7.17, Dist-2: 33.81, sBLEU: 7.54
      - Mistral (전체): BLEU-1: 29.24, ROUGE-L: 24.49, Dist-1: 7.48, Dist-2: 36.74, sBLEU: 7.17
- MORPHEUS의 효과는 Mistral 모델에서도 강력함을 보여줌.
- BLEU, ROUGE 및 Distinct 메트릭스 결과는 Mistral의 아키텍처가 LLaMA에 비해 대화 개인화에서 성능을 향상시킴을 나타냄.
- 그러나, 퍼소나 정보를 LLM에 통합하는 것은 여전히 큰 도전임.
- 이는 최첨단 모델을 사용하더라도 진정으로 개인화된 맥락 관련 대화를 생성하는 복잡성을 강조함.

---

# 5.4 Case Study

- MORPHEUS는 다양한 사례를 통해 일관된 성능을 보여줌.
- 표 5의 결과는 MORPHEUS가 대화 이력과 역할을 효과적으로 정렬함을 시사.
  
  - **사례 1:**
    - 질문자는 여행 중.
    - MSP와 CLV는 여행 관련 콘텐츠 언급, 그러나 응답자의 취미를 추론하지 못함.
    - MORPHEUS는 응답자가 나가려고 준비 중임을 정확히 파악, "하이킹을 즐긴다"는 역할 설정과 밀접한 응답 생성.
  
  - **사례 2:**
    - 질문자가 직업에 대해 질문.
    - MSP와 CLV는 대화 이력에 언급된 응답자의 나이를 간과함.
    - MORPHEUS는 대화 이력에 부합하고 진실된 응답과 근접한 응답 생성.
  
  - **사례 3:**
    - 혼란스러운 이력으로 인해 MSP와 CLV는 관련 응답 생성에 어려움.
    - MORPHEUS의 응답은 역할에 더 가까움.
  
- 전반적으로, MSP와 CLV는 혼란스러운 이력에 의해 잘못된 방향으로 이끌리며 일관된 응답을 생성하지 못함.
- MORPHEUS는 대화 이력을 정확히 활용하여 역할에 대한 합리적인 추론을 가능하게 함.

---

# 6 Conclusion

- MORPHEUS 프레임워크 소개
  - 개인화된 응답 생성을 위한 새로운 접근 방식
- 모델링 방식
  - 대화 역사에서 역할을 일반화된 방식으로 모델링
  - 다단계 훈련 과정을 통해 역할과 대화 정렬
- 성능 향상
  - 개인화된 대화 생성 능력 증대
  - 미리 보지 못한 역할에 대해서도 효과적으로 응답 생성
- 효율성
  - 페르소나 정보를 효율적으로 활용
  - 개인 정보 유출 위험 완화

---

# Limitations

- MORPHEUS 프레임워크는 개인화된 대화 생성(PDG) 분야에서 중요한 발전을 이루었음.
- 대화 이력에서 역할을 모델링하기 위해 잠재 공간을 혁신적으로 사용함.
- 현재 조사 범위를 벗어난 몇 가지 제한사항이 존재함.
  - MORPHEUS는 중국어 및 영어 데이터셋에서 철저히 테스트됨.
  - 다른 언어 및 방언에 대한 적응 가능성은 향후 탐색할 분야임.
- 이러한 제한은 모델의 효과성을 반영하지 않으며, 다양한 언어적 맥락에서의 유연성을 검증할 기회를 제공함.
- 현재 페르소나 코드북 구현은 역할을 간결하게 표현하는 데 효과적이지만, 표현 능력을 향상시킬 추가 정제 가능성이 있음.
- 이러한 고려 사항들은 모델의 현재 성과를 감소시키지 않으며, 지속적인 연구와 개발의 경로를 강조함.
- MORPHEUS 기술의 기술 개발 및 응용에 초점이 맞춰져 있어 PDG 기술의 사회적 함의에 대한 깊이 있는 탐구는 즉각적인 범위에서 제외됨.
- 이 분야가 발전함에 따라 이러한 고려 사항은 점점 더 중요해질 것임.

---

# Ethics Statement

- 연구는 개인화된 대화 생성 기술의 개발 및 적용에 내재된 윤리적 고려를 인식함.
- MORPHEUS는 외부 역할 데이터 없이 대화 생성의 개인화를 향상시키고, 개인정보 보호 문제를 줄이는 것을 목표로 함.
- 그러나 개인화의 명목 하에 오도되거나 해로운 콘텐츠가 생성될 가능성을 고려해야 함.
- 이 연구는 윤리적 가이드라인을 엄격히 준수하며, 모든 훈련 및 평가 데이터는 비윤리적 콘텐츠가 없는 공개 데이터셋에서 수집됨.
- 인간 평가에서 개인의 프라이버시를 보호하기 위해 익명화 기술을 적용함.
- 이러한 예방 조치에도 불구하고, 개인화된 대화 기술의 오용을 방지하기 위한 지속적인 윤리적 검토와 견고한 프레임워크의 개발이 중요하다는 점을 인정함.
- 특히 기술이 점점 더 정교하고 널리 채택됨에 따라 이의 중요성은 더욱 증가함.
