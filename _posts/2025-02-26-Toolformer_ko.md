---
title: "[논문리뷰] Toolformer: Language models can teach themselves to use tools (NeurIPS 2023)"
date: 2025-02-26 00:00:00 +0900
categories:
  - Paper Review
tags:
  - LLM
  - NLP
  - NeurIPS
---

## **요약:**

이 논문은 **Toolformer**라는 모델을 소개하며, **자기 지도 학습 방식(self-supervised approach)**을 통해 외부 도구를 활용하여 작업 성능을 향상하는 방법을 배운다. Toolformer는 **제로샷 성능(zero-shot performance)**을 크게 개선하며, 다양한 API를 활용하여 더 큰 모델과 경쟁할 수 있는 능력을 보여준다.

---

# **1. 서론**

<img alt="image" src="https://github.com/user-attachments/assets/a77d68a7-6dd7-41a1-832b-620d93d49d54" />

Brown et al. (2020) 및 Chowdhery et al. (2022)에서 논의된 **대규모 언어 모델(LLM, Large Language Model)**은 제로샷 및 소수샷(few-shot) 자연어 처리 작업에서 인상적인 성능을 보여주었다. 그러나 이러한 모델에는 여러 가지 한계가 존재한다.

- 실시간 정보에 접근할 수 없음
- 사실을 환각(hallucinate)하는 경향
- 저자원(low-resource) 언어에서 어려움
- 수학적 연산 능력 부족
- 시간적 흐름을 인식하는 능력 부족

이러한 문제를 해결하기 위해 **검색 엔진이나 계산기 같은 외부 도구를 활용하는 방법**이 제안되었다. 하지만 기존 접근법들은 **대량의 인간 주석(human annotations)**을 요구하거나 **도구 사용을 특정 작업에 제한**하여 일반적인 적용이 어렵다.

이를 극복하기 위해 우리는 **Toolformer**를 제안한다. Toolformer는 대규모 인간 주석 없이 **자기 지도 학습 방식**을 통해 도구 사용법을 학습하는 새로운 모델이다. 이 모델은 도구 사용 여부와 사용 방식을 **자율적으로 결정**하면서도 일반성을 유지하는 것을 목표로 한다.

우리의 접근 방식은 **컨텍스트 내 학습(in-context learning)**을 활용하여, 도구 사용의 몇 가지 예제를 통해 광범위한 데이터셋을 생성하는 것이다. 이를 위해 **언어 모델링 데이터셋에 API 호출을 주석 처리**하고, **자기 지도 학습 손실(self-supervised loss)**을 이용해 그 효과를 평가한다. 이를 통해 Toolformer는 **자율적으로 도구를 제어하는 법을 학습**할 수 있다.

실험 결과, **사전 학습된 67억(6.7B) 개의 매개변수를 가진 GPT-J 모델**을 기반으로 한 Toolformer는 다양한 다운스트림 작업에서 **제로샷 성능을 크게 향상**시켰으며, GPT-3 및 기타 대형 모델보다 우수한 성능을 보였다.

---

# **2. 접근 방식**

<img alt="image" src="https://github.com/user-attachments/assets/d7219761-1d25-4cdf-b0b2-20ed25a5dbe7" />

우리는 언어 모델 **M**이 API 호출을 통해 다양한 도구를 활용할 수 있도록 개선하는 것을 목표로 한다. 각 API의 입력 및 출력이 **텍스트 시퀀스로 표현**될 수 있도록 설정하여, 특정 토큰을 사용해 API 호출을 텍스트에 자연스럽게 통합할 수 있도록 한다.

API 호출은 다음과 같은 튜플 형태로 표현된다:  
\[
c = (a_c, i_c)
\]
여기서,

- $$a_c$$는 API의 이름
- $$i_c$$는 API의 입력 값

## **API 호출의 선형화(linearization)**

<img alt="image" src="https://github.com/user-attachments/assets/5dd2cfa0-e7f7-438f-9586-d83076ca33c9" />

우리의 접근 방식은 **기본 데이터셋 C를 API 호출이 포함된 증강 데이터셋 $$C^*$$로 변환하는 3단계 과정**으로 구성된다:

<img alt="image" src="https://github.com/user-attachments/assets/1c3ea2e6-3435-4638-b6d3-bbc664195b41" />

1. **API 호출 샘플링**

   - 언어 모델 $$M$$이 특정 텍스트 예제에 대해 API 호출을 제안하도록 유도하는 프롬프트를 생성한다.
   - API 호출이 삽입될 가능성이 높은 위치를 샘플링하고, 사전 정의된 임계값을 사용해 필터링한다.

2. **API 호출 실행**

   - 생성된 API 호출을 실제로 실행하여 결과를 얻는다. 결과는 텍스트 시퀀스로 변환된다.

3. **API 호출 필터링**
   - API 호출과 그 결과가 모델의 예측 손실을 줄이는지 평가한다.
   - API 호출이 유용한 경우에만 유지하고, 그렇지 않은 경우 제거한다.

최종적으로 필터링된 API 호출이 원본 텍스트와 결합되며, 이 데이터셋 $$C^*$$를 사용해 모델 **M**을 미세 조정한다. 이를 통해 모델은 피드백을 통해 **도구를 효과적으로 사용하는 법을 학습**한다.

추론 시, 모델 **M**은 일반적인 텍스트를 디코딩하다가 API 호출 응답이 필요한 토큰을 생성하면, 디코딩을 일시 중단하고 응답을 받아서 계속 진행한다.

---

# **3. 도구**

우리는 일반적인 언어 모델이 가진 한계를 극복하기 위해 다양한 도구를 탐색한다. 각 도구는 다음 두 가지 조건을 만족해야 한다:

1. 입력과 출력이 **텍스트 시퀀스로 표현 가능**해야 한다.
2. 사용 예시를 **소량 확보**할 수 있어야 한다.

다섯 가지 도구를 사용한다:

1. **질문 응답 시스템(Question Answering System)**

   - Atlas 모델을 활용한 검색 기반 QA 시스템
   - 간단한 사실 기반 질문에 대한 답을 제공

2. **계산기(Calculator)**

   - 사칙연산(덧셈, 뺄셈, 곱셈, 나눗셈) 수행
   - 소수점 둘째 자리까지 반올림하여 결과 제공

3. **위키백과 검색 엔진(Wikipedia Search Engine)**

   - 특정 검색어에 대해 위키백과의 짧은 텍스트 조각 반환
   - BM25 검색 모델 사용

4. **기계 번역 시스템(Machine Translation System)**

   - NLLB 모델을 활용하여 다국어 번역 수행
   - 200개 이상의 언어 지원, 저자원 언어 포함

5. **캘린더 API(Calendar API)**
   - 현재 날짜 반환

각 도구에 대한 추가 세부 사항은 부록 A에 제공된다.

---

# **4. 실험**

우리는 추가적인 감독 없이 다양한 작업에서 모델이 **자율적으로 도구를 활용할 수 있는지**를 평가한다. 실험은 다음과 같이 구성된다.

## **4.1 실험 설정**

- **데이터셋 생성**:

  - CCNet의 하위 데이터셋 사용
  - 특정 API를 위한 텍스트 필터링 적용

- **모델 미세 조정**:

  - 배치 크기 및 학습률 설정

- **기준 모델** 비교:
  - 표준 GPT-J 모델
  - API 호출 없이 미세 조정된 모델
  - API 호출을 포함하여 미세 조정된 모델

## **4.2 다운스트림 작업 평가**

- **LAMA**: Toolformer는 사실 기반 문장을 완성하는 성능에서 다른 모델을 능가함
- **수학 데이터셋**: 계산기 도구를 적극 활용하여 수학적 추론 능력이 향상됨
- **질문 응답**: 위키백과 검색 도구를 활용하지만, GPT-3보다는 성능이 낮음
- **다국어 QA**: 다국어 처리 능력 향상, 하지만 언어별 성능 차이 큼
- **시간 관련 데이터셋**: 캘린더 API를 활용하여 시간 기반 작업 성능이 향상됨

## **4.3 언어 모델링 성능**

API 호출을 포함한 미세 조정이 언어 모델 성능에 미치는 영향을 평가한 결과, 기본적인 언어 모델 성능 저하는 미미했다.

## **4.4 스케일링 법칙**

모델 크기가 7.75억(775M) 개의 매개변수를 넘어설 때 외부 도구 사용 능력이 향상됨을 확인했다. 모델 크기가 커질수록 도구를 더 효과적으로 활용할 수 있었다.

---

# **5. 분석 (Analysis)**

## **디코딩 전략 (Decoding Strategy)**

이 섹션에서는 앞서 소개한 **수정된 디코딩 전략**을 분석한다. 기존 방식과 달리, 가장 가능성이 높은 토큰을 일관되게 생성하는 대신, **상위 k개 후보 토큰 내에 포함될 경우** `<API>` 토큰을 생성할 수 있도록 허용한다.

우리는 **LAMA의 T-REx 하위 데이터셋 및 WebQS**에서 k 값을 조정하며 성능을 평가하였다.

- k 값이 증가할수록 **모델이 API 호출을 더 자주 활용**하며, API 호출이 이루어지는 경우 성능이 향상되었다.
- 특히, API 호출이 이루어진 경우 모델의 **교정 능력(calibration)이 향상**되었으며, 낮은 성능을 보이는 경우에 API를 선택하는 경향이 있었다.
- 그러나 **k 값이 너무 커지면 교정 능력이 감소**하는 현상이 관찰되었다.

---

## **데이터 품질 (Data Quality)**

<img alt="image" src="https://github.com/user-attachments/assets/e98e78d1-0ee9-48fc-b0a9-9a25d6a329b5" />

우리는 모델이 생성한 **API 호출의 품질**을 분석하였다.

- 질적 분석 결과, **높은 점수를 받은 API 호출은 대체로 유용**한 것으로 나타났다.
- 반면, 낮은 점수를 받은 API 호출은 덜 유용할 가능성이 높았지만, 일부 경우에는 정보가 부족하더라도 **혼란도를 낮추는 역할을 수행**할 수 있었다.
- **비필터링된 API 호출의 노이즈**가 모델이 특정 API 호출 결과에 과도하게 의존하는 것을 방지하는 긍정적인 역할을 할 수도 있음이 관찰되었다.

---

# **6. 관련 연구 (Related Work)**

## **언어 모델 사전 훈련 (Language Model Pretraining)**

언어 모델 사전 훈련을 개선하는 다양한 전략이 존재한다. 대표적인 방법은 **추가적인 텍스트 정보를 통합하는 방식**이다.

- 메타데이터 추가 (Keskar et al., 2019)
- HTML 태그 활용 (Aghajanyan et al., 2021)
- 위키백과 마크업 사용 (Schick et al., 2022)
- 정보 검색 시스템을 통한 관련 텍스트 추가 (Guu et al., 2020; Borgeaud et al., 2021; Izacard et al., 2022)

기존 방법들은 **추가 정보를 무차별적으로 제공**하는 반면, Toolformer는 **언제 어떤 정보를 요청할지 자율적으로 결정**한다는 차별점을 가진다.

---

## **도구 활용 (Tool Use)**

언어 모델이 **외부 도구**(예: 검색 엔진, 웹 브라우저, 계산기, 번역 시스템, Python 인터프리터 등)를 사용할 수 있도록 하기 위한 연구가 진행되어 왔다.

이전 연구들은 일반적으로 두 가지 방식 중 하나를 따른다:

1. **광범위한 인간 감독(human supervision)에 의존**

   - Komeili et al. (2022), Nakano et al. (2021), Thoppilan et al. (2022)

2. **특정 작업을 위한 소수샷(few-shot) 설정 활용**
   - Gao et al. (2022), Lazaridou et al. (2022), Yao et al. (2022)

Toolformer는 **자기 지도 학습(self-supervised training)**을 통해 **특정 프롬프트 없이** 도구 사용법을 학습한다. 이는 TALM (Parisi et al., 2022)과 유사한 접근 방식이지만, TALM은 다운스트림 작업을 위한 미세 조정(fine-tuning)에 한정된다는 차이가 있다.

---

## **부트스트래핑 (Bootstrapping)**

자기 학습(self-training) 및 부트스트래핑(bootstrapping) 기법은 다양한 분야에서 연구되어 왔다.

- 단어 의미 분별 (Yarowsky, 1995)
- 관계 추출 (Brin, 1999; Agichtein and Gravano, 2000)
- 구문 분석 (McClosky et al., 2006; Reichart and Rappoport, 2007)
- 시퀀스 생성 (He et al., 2020)
- 소수샷 텍스트 분류 (Schick and Schütze, 2021a)
- 검색 (Izacard and Grave, 2021)
- 추론 (Zelikman et al., 2022)

Toolformer 역시 **혼란도(perplexity)-기반 필터링 단계를 사용하여 예측을 개선**한다는 점에서 이와 유사한 접근 방식을 따른다.

---

# **7. 한계 (Limitations)**

우리 방법은 언어 모델이 **자기 지도 학습 방식**으로 도구 사용을 학습할 수 있도록 하지만, 다음과 같은 한계가 존재한다.

1. **연쇄적 도구 사용(Chained Tool Use) 불가**

   - Toolformer는 **각 API 호출을 독립적으로 생성**하므로, **여러 도구를 연쇄적으로 활용하는 기능이 부족**하다.
   - 미세 조정 데이터셋에 이러한 사례가 포함되지 않았기 때문.

2. **대화형 도구 사용(Interactive Tool Usage) 미지원**

   - Toolformer는 검색 엔진과 같은 **대화형 도구**를 사용할 수 없다.
   - 검색 결과를 탐색하거나 쿼리를 수정하는 기능이 없기 때문에 활용이 제한적이다.

3. **입력 문구의 표현 방식에 민감함**

   - Toolformer는 API 호출을 결정할 때 **입력 문구의 세부 표현 방식에 영향을 받음**.
   - 이는 일반적인 언어 모델이 프롬프트(prompt)에 민감한 특성과 유사하다.

4. **샘플 비효율성(Sample Inefficiency)**

   - 매우 많은 문서를 처리해야 함에도 불구하고, **성공적인 API 호출 수는 적음**.
   - 예를 들어, **100만 개 이상의 문서를 처리해야 수천 개의 유용한 API 호출만 생성됨**.

5. **도구별 비용 문제 고려 부족**
   - Toolformer는 **API 호출의 계산 비용을 고려하지 않음**.
   - 특정 도구의 사용 비용이 높을 경우 비효율적일 수 있음.

이러한 한계를 해결하면 모델의 효율성과 활용도가 더욱 향상될 것이다.

---

# **8. 결론 (Conclusion)**

우리는 **Toolformer**를 소개하였다. Toolformer는 **검색 엔진, 계산기, 번역 시스템** 등의 다양한 도구를 API 호출을 통해 활용할 수 있는 **자기 지도 학습 언어 모델**이다.

- Toolformer는 **미래 토큰의 혼란도를 줄이는 API 호출을 필터링하여 미세 조정**된다.
- 이 접근 방식은 **제로샷 성능을 크게 향상**시키며, **6.7B 파라미터 규모의 GPT-J 모델이 GPT-3보다 우수한 성능을 발휘**할 수 있도록 한다.

Toolformer는 **대형 모델이 외부 도구를 활용하는 방법을 학습하는 새로운 패러다임**을 제시하며, 기존의 감독 학습 방식 없이도 성능을 크게 개선할 수 있음을 입증하였다.
