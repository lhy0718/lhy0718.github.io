---
title: "[논문리뷰] Controllable Neural Dialogue Summarization with Personal Named Entity Planning (EMNLP 2021)"
date: 2025-03-06 15:00:00 +0900
categories:
  - Paper Review
tags:
  - NLP
  - EMNLP 2021
  - Dialogue Summarization
---

Abstract: 본 논문에서는 개인 이름 항목 계획을 통해 대화 요약을 유연하게 안내할 수 있는 제어 가능한 신경 생성 프레임워크를 제안하며, 요약 작업의 제약 문제를 해결하기 위한 정보 유형 및 초점을 조절합니다. 이 프레임워크는 일반적인 종합적 관점과 사용자 지정된 개인 이름 항목에 기반한 집중적 관점을 지원합니다.

---

# 1 Introduction

<img width="397" alt="image" src="https://github.com/user-attachments/assets/2d366e4f-e176-4681-bf43-4706bb4213df" />

- 자동 요약은 긴 텍스트를 압축하여 정보를 보존하면서 간결한 버전으로 만드는 작업임.
- 요약 접근 방식:
  - **추출적 접근법**: 중요한 단어, 구문, 문장을 선택하여 요약 생성 (Lin and Bilmes, 2011).
  - **추상적 접근법**: 원본 텍스트의 중요 부분을 패러프레이징하거나 새롭게 생성하여 요약 (Jing and McKeown, 2000).
- 추상적 요약은 더 깊은 이해, 일반화, 추론, 실제 지식 통합을 요구함.
- 대화 요약에서는 추출적 접근법이 아닌 추상적 접근법이 더 유용함.
- 대부분의 요약 데이터 세트는 뉴스를 중심으로 구성되어 있음 (예: NYT, CNN/Daily Mail).
- 신경망 접근법은 추출적 및 추상적 패러다임에서 개선을 보여줌.
- 신경 대화 요약은 신흥 연구 분야로, 상대적으로 작은 데이터 세트에서 진행되고 있음.
- 신경 모델은 대규모 맥락화 언어 모델을 미세 조정하여 유창한 문장을 생성할 잠재력이 있음.
- 그러나 많은 요약 생성 작업이 단일 참조 요약으로 구축되어 일반적인 요약만 제공하게 되어 특정 응용에 최적화되지 않음.
- 대화는 정보 교환이 동적이고 비공식적이며 반복적인 특성을 가짐.
- 중요한 정보가 스피커 전체에 걸쳐 분산되어 있어 불완전한 문장으로 이루어짐.
- 유창한 요약 생성을 위한 발화 추출의 비현실성으로 인해 추상적 요약 모델의 필요성이 점점 커지고 있음.
- 신경 추상적 모델은 사실 실성 문제로 신뢰성에 영향을 받음 (예: 성별 대명사 및 화자 잘못 지정).
- 본 연구에서는 조절 가능한 대화 요약 프레임워크를 제안함.
  - "누가 무엇을 했는가"에 초점이 맞춰져 있으며, 개인 이름 엔티티 계획으로 생성 과정을 조절함.
- 제안된 모델은 다양한 개인 이름 엔티티 계획에 기반하여 유창하고 정확한 요약을 생성할 수 있음. 
- 모델의 출력은 사실 정확도 평가에서 개선된 성능을 보여줌.

---

# 2 Related Work

- **텍스트 요약 연구 배경**
  - 텍스트 요약 분야는 추상적 요약과 추출적 요약 패러다임으로 나뉜다.
  - 추출적 요약은 비신경 접근법에서 다양한 언어와 통계적 특성을 연구한다. 
  - 최근 신경 접근법이 큰 발전을 이루었다.

- **추상적 요약**
  - 추상적 요약은 더 간결하고 유창한 요약 생성을 기대한다.
  - 대규모 데이터셋과 정교한 신경 구조를 통해 뉴스 도메인에서 성능이 크게 향상됨.
  - 시퀀스-투-시퀀스 모델, 포인터-생성 네트워크, 문장 재작성 기법 등이 주요 기술로 사용됨.
  - 대규모 사전 훈련된 언어 모델이 요약 성능을 더욱 향상시킴.

- **대화 요약 연구**
  - 최근 대화 요약을 위한 신경 요약 연구가 대두됨.
  - 회의 및 일상 대화로부터 관련 데이터가 구축됨.
  - 대화 분석을 통한 요약 기법이 연구 중이며(대화 행동 활용, 다중 모달 특성, 주제 정보 등) 계층 모델링을 통한 세분화된 뷰 세분화 등이 포함됨.

- **제어 가능한 텍스트 생성**
  - 제어 가능한 텍스트 생성은 다양한 출력을 얻기 위해 보조 신호를 사용하는 연구를 포함함.
  - 이러한 연구는 스타일 전송, 패러프레이징 등 다양한 도메인에서 진행됨.
  - 최근에는 길이 조절 및 질문/개체 유도 문서 요약을 위한 일반적인 프레임워크가 제안됨. 

- **개인 이름체 계획**
  - 개인 이름체는 요약 생성 시 어떤 내용을 포함할지 계획하는 데 사용됨.
  - 요약에 포함될 특정 개인 이름체를 명시하는 맞춤형 계획을 통해 요약 생성이 진행됨. 

해당 섹션은 텍스트 요약의 기초 연구, 주요 기술 및 최근 연구 방향에 대한 개요를 제공하고, 특히 대화 요약과 제어 가능한 텍스트 생성에 초점을 맞추고 있습니다.

---

# 3 Controllable Generation with Personal Named Entity Planning

<img width="813" alt="image" src="https://github.com/user-attachments/assets/c26d482e-6657-4b35-8781-5acafc3c324a" />

- **개요**:
  - 개인 명칭 엔터티 계획을 통한 대화 요약 생성 방법론 소개.
  - 목표: 다양한 선호와 요구에 맞는 요약 생성.

- **작업 정의**:
  - **입력**: 
    - 다중 회전 대화 내용(D).
    - 개인 명칭 계획(C).
  - **출력**: 대화 내용으로부터 요약 정보 Y 생성.

- **개인 명칭 엔터티 계획**:
  - 개인 명칭 엔터티를 포함해 요약의 계획을 수립.
  - 대화에서 언급된 특정 개인 명칭 포함.

- **훈련 방법**:
  - **Occurrence Planning**:
    - 실제 요약을 기반으로 조건부 훈련 샘플 생성.
    - 두 개의 개인 명칭 집합을 취합하여 교차점 계산.
    - 실제 요약의 엔터티 발생 순서에 따라 재정렬하여 조건부 시퀀스 작성.

- **추론**: 
  - 두 가지 계획 옵션:
    - **Comprehensive Planning**: 모든 개인 명칭 포함, 정보 커버리지 최대화.
    - **Focus Planning**: 특정 개인 명칭에 초점, 더욱 타겟화된 요약 생성.

- **신경망 생성**:
  - Transformer 기반의 시퀀스-투-시퀀스 네트워크 사용.
  - 인코더와 디코더의 구조 설명.
  - 훈련 시 조건부 시퀀스 C와 대화 내용 D를 입력으로 합쳐 사용.

- **결론**:
  - 새로운 대화 요약 생성 방법론이 개인 명칭 엔터티 계획을 통해 성능 향상.
  - 다양한 조건부 입력을 통해 요약의 일관성과 정보 커버리지 개선 가능.

---

# 4 Improving Factual Correctness

- 현재 신경망 요약 시스템은 유창한 요약을 생성할 수 있지만, 사실적 일관성 문제는 여전히 해결되지 않음.
  - 신경망 모델은 종종 출처 콘텐츠에 의해 뒷받침되지 않는 진술을 생성함.
  - 이로 인해 생성된 요약의 유용성과 신뢰성에 대한 우려가 제기됨.
  
## 4.1 Factual Inconsistency Detection

<img width="398" alt="image" src="https://github.com/user-attachments/assets/e602bdd7-bfd2-41ab-a9ec-33bada7b5355" />

- 요약 품질을 사실적 정확성 측면에서 평가하고 최적화하기 위해 모델 구축.
  - 부정 샘플은 텍스트 조작을 통해 생성됨.
- 사람 이름과 관련된 불일치를 감지하는 것을 목표로 함.
  - 이진 분류기를 사용하여 대화와 요약의 사실적 일관성을 평가함.
- 부정 샘플 생성 전략:
  1. 개인 이름의 위치를 서로 바꿈.
  2. 특정 이름을 무작위로 선정한 다른 이름으로 교체.
  3. 훈련 데이터에서 수집된 다른 이름으로 교체.
- ‘BERT-base-uncased’ 모델을 미세 조정하여 요약의 변경 여부를 분류했으며, 91% F1 점수를 기록함.

## 4.2 Exploiting Coreference Information
- 대화 중 참조 정보(코어퍼런스)를 활용하여 모델 성능을 향상시킴.
  - 대화의 코어퍼런스 해소를 위해 AllenNLP 툴킷 사용.
- 코어퍼런스 링크와 클러스터를 분석하여 그래프 구축.
  - 그래프 구조에 연결된 정보를 모델링하기 위해 다층 그래프 컨볼루션 네트워크(GCN) 적용.
  - 문맥화된 표현에 코어퍼런스 정보를 통합함.

## 4.3 Data Augmentation via Entity Exchange
- 데이터 불균형 및 희소성 문제 해결을 위해 엔티티 기반 데이터 증강 제안.
  - (1) 동일 성별의 개인 이름 쌍 추출.
  - (2) 출처 콘텐츠와 참조 요약에서 이름 교환으로 새로운 샘플 생성.
- 데이터 증강 실시로 모델의 잘못된 연관성을 줄이고, 훈련 데이터를 통한 불필요한 귀납적 편향을 감소시킴. 
- 실험에서 데이터 증강 샘플 수는 4,000개임.

---

# 5 Experimental Results and Analysis

- **데이터셋 설명**
  - SAMSum 대화 요약 데이터셋을 사용하여 실험 진행
  - 데이터 통계:
    - 훈련 세트: 14,732 샘플, 평균 대화 턴수 11.7, 평균 요약 길이 23.44
    - 검증 세트: 818 샘플, 평균 대화 턴수 10.83, 평균 요약 길이 23.42
    - 테스트 세트: 819 샘플, 평균 대화 턴수 11.25, 평균 요약 길이 23.12
  - 대화 내용의 원본을 유지하고 서브-워드 토큰화로 전처리
  - Transformer 기반 모델은 1,024 입력 길이를 지원

- **모델 구성**
  - BART 모델 사용, 특히 시퀀스-투-시퀀스 언어 생성에 특화된 사전 훈련 버전
  - 파라미터: BART-Base(6/6/2/768), BART-Large(12/12/3/1024)
  - 최적화 기법: AdamW, 배치 크기 8, 드롭아웃 비율 0.1
  - 데이터 증강: 요약에 두 개 이상의 개인 명명된 개체가 포함된 샘플 제외

- **정량적 평가**

  <img width="812" alt="image" src="https://github.com/user-attachments/assets/c5a5e501-9fa5-4b2d-bd2d-fde1fb1c98e1" />

  <img width="812" alt="image" src="https://github.com/user-attachments/assets/d0f6f324-61d3-4341-bf33-a76d3d83ce55" />

  - ROUGE 지표를 사용하여 자동화된 요약 평가
  - 훈련 및 테스트 조건이 일치하는 경우:
  
    <img width="399" alt="image" src="https://github.com/user-attachments/assets/b47df35b-3469-4cac-b1fa-35c58b61ac34" />

    - 조건부 훈련이 효과적임을 보여줌
    - BART-Large가 BART-Base보다 성능이 높음
  - 훈련 및 테스트 조건 불일치:
    - 포괄적 계획에서 개인 엔티티의 정보 커버리지가 요약 성능 개선을 확인
    - 코레퍼런스 정보와 데이터 증강이 성능을 지속적으로 향상

- **사실적 정확도 평가**
  - 생성된 요약의 정확도를 평가하기 위해 사실적 일관성 분류기 사용
  - 코레퍼런스 정보를 추가하면 정확도가 개선되며 데이터 증강도 향상

- **인간 평가**
  - 50개의 대화 샘플을 무작위 선택하여 두 명의 언어 평가자가 품질 점수를 매김
  - 진실성과 유용성 측정에 초점을 맞추어 점수 부여
  - 점수는 -1(일치하지 않음)에서 1(인간 작성 요약)까지의 범위로 평가

- **최종 평가**
  - 포괄적 계획과 집중 계획 각각에서 생성된 요약의 정보 손실 및 오류 비교
  - Ctrl-DiaSumm 및 Ctrl+Coref+DA가 특히 정보 손실이 적고 정확도가 높음
